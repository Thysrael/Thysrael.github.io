<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-wall.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-wall.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="baidu-site-verification" content="code-jsxllPgZAX">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic|Ma Shan Zheng:300,300italic,400,400italic,700,700italic|JetBrains Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"thysrael.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":false,"style":"flat"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="一、Hardware1.1 SM采用我两年半前写下的博文开篇：“GPU 是一个由多个 SIMD 处理器组成的 MIMD 处理器。” 这句话的意思是说，GPU 是一个多核系统，它这里说的“核”，指的是像多核 CPU 中的 core，它对应的不是 CUDA Core，而是 SM。而 SM 本身是一个 SIMD 处理器，也就是说，SM 是一个 SIMD 处理器。CUDA Core 其实对应的是一个 AL">
<meta property="og:type" content="article">
<meta property="og:title" content="Sys4AI-GPU">
<meta property="og:url" content="https://thysrael.github.io/posts/848ac0f9/index.html">
<meta property="og:site_name" content="钟鼓楼">
<meta property="og:description" content="一、Hardware1.1 SM采用我两年半前写下的博文开篇：“GPU 是一个由多个 SIMD 处理器组成的 MIMD 处理器。” 这句话的意思是说，GPU 是一个多核系统，它这里说的“核”，指的是像多核 CPU 中的 core，它对应的不是 CUDA Core，而是 SM。而 SM 本身是一个 SIMD 处理器，也就是说，SM 是一个 SIMD 处理器。CUDA Core 其实对应的是一个 AL">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://thysrael.github.io/posts/848ac0f9/image-20211104155056775.png">
<meta property="og:image" content="https://thysrael.github.io/posts/848ac0f9/image-20250913163324918.png">
<meta property="og:image" content="https://thysrael.github.io/posts/848ac0f9/nvidia-pascal-nvlink-power8.jpg">
<meta property="og:image" content="https://thysrael.github.io/posts/848ac0f9/memory-spaces-on-cuda-device.png">
<meta property="article:published_time" content="2025-09-13T01:38:10.000Z">
<meta property="article:modified_time" content="2026-01-08T11:39:07.647Z">
<meta property="article:author" content="Thysrael">
<meta property="article:tag" content="知识总结">
<meta property="article:tag" content="Sys4AI">
<meta property="article:tag" content="S10假期">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://thysrael.github.io/posts/848ac0f9/image-20211104155056775.png">

<link rel="canonical" href="https://thysrael.github.io/posts/848ac0f9/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Sys4AI-GPU | 钟鼓楼</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-1K2CH25PS7"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-1K2CH25PS7');
  </script>

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="钟鼓楼" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>
      <a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/thysrael" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">钟鼓楼</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">钟楼瘦，鼓楼胖</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">31</span></a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">70</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">200</span></a>

  </li>
        <li class="menu-item menu-item-resource">

    <a href="/resource/" rel="section"><i class="fa fa-book fa-fw"></i>Resource</a>

  </li>
        <li class="menu-item menu-item-links">

    <a href="/links/" rel="section"><i class="fa fa-link fa-fw"></i>Links</a>

  </li>
        <li class="menu-item menu-item-roam">

    <a href="/obsidian-quartz/" rel="section"><i class="fa fa-sitemap fa-fw"></i>Roam</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://thysrael.github.io/posts/848ac0f9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar2.png">
      <meta itemprop="name" content="Thysrael">
      <meta itemprop="description" content="Thysrael 的个人技术博客，专注于计算机科学基础与系统架构。内容涵盖操作系统(Linux/Unix)、计算机组成原理(MIPS/Verilog)、数据库(DBMS)、编译技术(LLVM)、并行计算(GPU/CUDA)及人工智能系统(Sys4AI)。同时分享算法设计、数学分析笔记以及生活随笔。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="钟鼓楼">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Sys4AI-GPU
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-09-13 09:38:10" itemprop="dateCreated datePublished" datetime="2025-09-13T09:38:10+08:00">2025-09-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2026-01-08 19:39:07" itemprop="dateModified" datetime="2026-01-08T19:39:07+08:00">2026-01-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Sys4AI/" itemprop="url" rel="index"><span itemprop="name">Sys4AI</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>9k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>8 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="一、Hardware"><a href="#一、Hardware" class="headerlink" title="一、Hardware"></a>一、Hardware</h2><h3 id="1-1-SM"><a href="#1-1-SM" class="headerlink" title="1.1 SM"></a>1.1 SM</h3><p>采用我两年半前写下的博文开篇：“<strong>GPU 是一个由多个 SIMD 处理器组成的 MIMD 处理器</strong>。”</p>
<p>这句话的意思是说，GPU 是一个多核系统，它这里说的“核”，指的是像多核 CPU 中的 core，它对应的不是 CUDA Core，而是 SM。而 SM 本身是一个 SIMD 处理器，也就是说，SM 是一个 SIMD 处理器。CUDA Core 其实对应的是一个 ALU 。一个 SM 中有多个 CUDA Core，所以它可以用一条指令进行多个标量的计算（送入不同的 CUDA Core）。</p>
<p>人们常常将 CPU 比作一个无所不知的教授，GPU 比喻成成百上千个小学生。而实际上，GPU 更像是一组长着很多只不协调的手的大学生。这个比喻中，SM 对应“大学生”，而 CUDA Core 等 SM 中的计算单元对应“手”。</p>
<p>SM 才是指令的执行者，而不是 CUDA Core 是指令的执行者。我之所以会产生 CUDA Core 才是执行者的错觉，我猜测是因为在 SIMT 模型中，thread 对应的往往是 CUDA Core 这样的计算单元（其实也不是一一对应），而在 CPU 体系中，thread 和与之对应的 CPU Core 是指令的执行者，这就很容易让人产生，CUDA Core 才是指令的执行者的误解。</p>
<p><img src="/posts/848ac0f9/image-20211104155056775.png" alt="image-20211104155056775"></p>
<p>每个 SM 核都有自己独立的寄存器文件，L1 Cache/Shared Memory，指令调度单元等。</p>
<h3 id="1-2-Schedule"><a href="#1-2-Schedule" class="headerlink" title="1.2 Schedule"></a>1.2 Schedule</h3><p>现在 CPU 也有两种趋势，一个是尽可能的增加 CPU Core 的数目，另一个是尽可能的增加 CPU 的向量指令集的能力。这就导致在某种意义上来说，CPU 系统就变成了“一组长着很多只手的教授们”，和 GPU 就非常类似了。那么到底 GPU 有什么其他独特的能力呢？</p>
<p>我觉得有一个方面就是两者在面对 <code>ld/st</code> 访存指令导致的延迟的处理思路不同。CPU 通过构建多级 cache，来尽量降低访存指令的延迟（其实还有乱序发射）。而 GPU 并没有构建多级 cache（我猜测是因为多个核心的 cache 的硬件开销过大了），一旦遇到访存指令阻塞的情况，GPU 会立刻切换“另一个指令”来执行，充分利用那些闲置的计算资源（也就是 schedule）。这种设计思路，是一种不降低指令延迟的前提下，提高系统吞吐的方法。</p>
<p>那么 GPU 是如何找到那条在访存阻塞时，可以被调度填充的指令呢？如果是 CPU，CPU 会在当前线程中的后续指令里，找一条与当前指令不存在数据依赖的指令，这依赖于 scoreboard 结构。我不确定 GPU 中能不能也实现相似的功能，毕竟 scoreboard 比较复杂。但是无论如何，CPU 和 GPU 都要面对，找不到一条不存在数据依赖的指令的情况，CPU 一般就选择阻塞等待了，反正在有多级 cache 的情况下，等待时间也不会太久。而 GPU 则不行，在没有 cache 的情况下，一旦等待，那时间可就长了。所以 GPU 选择切换“线程”，从另一个“线程”中找一条指令来执行。显然两条来自不同线程的指令，之间一定是不存在数据依赖的。在 GPU 中，我们称“线程”为 warp 。</p>
<p>这就又引入了一大堆问题。首先，难道切换 warp 本身是没有开销的吗？在 CPU 中，切换线程虽然不用更改地址空间，但是寄存器、PC 这些上下文状态还是要借助内存来保存和恢复的，那这样开销就大了（即使对于 CPU 来说，开销也很大）。那而 GPU 的 warp 切换按理说开销也不会小，甚至更大。这是因为 SM 是一个 SIMD 处理器，涉及到的寄存器数目非常庞大，而且 GPU 的访存延迟更高。</p>
<p>但是实际上，warp 切换基本上是零开销的。这是因为 GPU 根本不借助内存去保存和恢复上下文；而是为每个 warp 准备单独的寄存器文件，无论这个 warp 是否活跃。所以切换 warp，就是单纯的改一下指针就好了。也就是说，虽然 GPU 的 cache 资源非常少，但是寄存器资源非常多。</p>
<p>这种设计更理论的来说，被称作硬件多线程（Hardware Multithreading），每个 warp 相当于是一个 SM 的硬件线程。其实这种设计在 CPU 中也有出现，被称为同步多线程（Simultaneous Multithreading, SMT），在 Intel 中被称为超线程（Hyper-Threading, HT），也就是在一个 CPU Core 中，有多份独立的寄存器文件和 PC，但是只有一份 ALU 等执行单元。HT 的表现就是“逻辑核心”数目大于“物理核心”数目。</p>
<p>最后再介绍一下 SM 中的 Warp Scheduler 和 Dispatch Unit。其中 Warp Scheduler 负责挑选出特定 warp 的特定指令，而 Dispatch Unit 负责将这条指令，发送（issue）给执行单元执行，这主要有两个部分，一个是选择合适的执行单元（比如整数计算就发给 CUDA Core，访存就发给访存单元），另一个是对 warp 进行一定的拆分，这是因为 warp 的数目一般是 32 ，而有些计算资源只有 8 个，那么就需要分 4 次发射。</p>
<h3 id="1-3-SIMT"><a href="#1-3-SIMT" class="headerlink" title="1.3 SIMT"></a>1.3 SIMT</h3><p>GPU 又在 SIMD 的基础上，实现了更为灵活的 SIMT 的抽象，这同样需要硬件的支持。SIMT 这种灵活性的意味着每个线程都可以进行 <strong>独立访存</strong> 和 <strong>独立控制流</strong> ，这两点都是 SIMD 难以进行的。</p>
<p>独立访存意味着每个线程都可以随机化的访问地址，而不是必须访问一组连贯的地址，牺牲的是 SIMD 整体访存的效率。在实现上，需要为每个 thread 配置一个访存单元，而如果是普通的 SIMD，其实一个 warp 配置一个访存单元就够了。</p>
<p>独立控制流意味着不同 thread 可以执行不同的代码，牺牲的是执行效率。在实现上，采用的是指令掩码（Mask）。</p>
<p>这里我们最后讨论一下 SIMT 的范围。其实很容易就会发现，warp 就是 SIMT 的范围。因为 warp 里有 32 个 thread，也就是 warp 内的每个指令，都会同时对应 32 个线程进行处理。</p>
<p>而如果到了软件范畴，其实 SIMT 的范围扩大了，我们使用 <code>(ctaid, tid)</code> 来完成对于 thread 的索引，当 CTA（Cooperative Thread Array）数目和 CTA 内 thread 数目增多时，SIMT 的范围就会扩大。而在底层硬件上，这些扩大的范围，最终还是会被分割成多个 warp SIMT 去执行。</p>
<h3 id="1-4-Memory-Hierarchy"><a href="#1-4-Memory-Hierarchy" class="headerlink" title="1.4 Memory Hierarchy"></a>1.4 Memory Hierarchy</h3><p>GPU 的 Memory Hiearchy 如下所示：</p>
<p><img src="/posts/848ac0f9/image-20250913163324918.png" alt="image-20250913163324918"></p>
<p>GPU 的 L1 Cache 在 SM 内，L2 Cache 在 GPU 片上，由所有 SM 所共享，而显存则在 GPU 片下（围绕 GPU 芯片的一堆小正方形芯片）。</p>
<p>从图上数据可以看出，GPU 的 Reg File 的大小是大于 L1 Cache 的。GPU 的各级 Cache 都远小于 CPU 的各级 Cache。这些现象都反应了我们前面提到的不同的设计思想。</p>
<p>显存在实现上是 HBM（High Bandwidth Memory）。它的带宽大约是 1,000x GB/s 量级的，这比 CPU 使用的 DDR 带宽（一般是 100x GB/s）高一个量级，是无愧 HBM 这个名字的。但是考虑到 GPU 的计算能力是 10,000x GB/s 量级的，又比 HBM 的带宽高一个量级，因此 GPU 在 LLM 任务中，往往是内存瓶颈的。另外强调，这里的的带宽，指的是将数据从显存，搬运到 GPU 上的带宽。</p>
<h3 id="1-5-Interconnect"><a href="#1-5-Interconnect" class="headerlink" title="1.5 Interconnect"></a>1.5 Interconnect</h3><p>一个完整的 GPU 计算节点的互联图如下所示：</p>
<p><img src="/posts/848ac0f9/nvidia-pascal-nvlink-power8.jpg" alt="nvidia-pascal-nvlink-power8"></p>
<p>可以看到，如果想要搬运数据从 CPU Memory 搬运到 GPU Memory，需要走较为缓慢的 PCIe 通路（10x GB/s），而 GPU Memory 之间的数据搬运，则可以走 NVLink（100x GB/s）。</p>
<p>现在的 LLM 都非常庞大，而 GPU 显存只有 10x GB 大小，所以很有可能出现显存容纳不下数据的情况。而如果我们将其 offload 到 CPU Memory 上，我们就需要忍受 PCIe 的低带宽，这甚至比 HBM 的低带宽更难以接受。</p>
<p>如果是分布式场景，我们一般会把参数都加载到显存后再开始任务，而不同 GPU 中的数据交换，通过 NVLink 交换，而不是用 CPU Memory 做中转（走 PCIe 太慢了）；而如果是边缘设备，我们就要想办法解决 PCIe 的瓶颈了，比如说稀疏注意力机制。</p>
<h3 id="1-6-Terminology"><a href="#1-6-Terminology" class="headerlink" title="1.6 Terminology"></a>1.6 Terminology</h3><p>这里整理一下 NVIDIA 和 AMD GPU 的不同术语对比：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>实体</th>
<th>NVIDIA</th>
<th>AMD</th>
</tr>
</thead>
<tbody>
<tr>
<td>SIMD Processor</td>
<td>SM (Streaming Processor)</td>
<td>CU (Compute Unit)</td>
</tr>
<tr>
<td>Group of Threads</td>
<td>Warp</td>
<td>Wavefront (Wave)</td>
</tr>
<tr>
<td>ALU</td>
<td>CUDA Core</td>
<td>SP (Stream Processor)</td>
</tr>
<tr>
<td>On-chip Scratchpad</td>
<td>Shared Memory</td>
<td>LDS (Local Data Share)</td>
</tr>
<tr>
<td>CTA</td>
<td>Block Group</td>
<td>Work Group</td>
</tr>
<tr>
<td>Ecosystem</td>
<td>CUDA (Compute Unified Device Architecture)</td>
<td>ROCm (Radeon Open Compute platform)</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h2 id="二、CUDA"><a href="#二、CUDA" class="headerlink" title="二、CUDA"></a>二、CUDA</h2><h3 id="2-1-CTA"><a href="#2-1-CTA" class="headerlink" title="2.1 CTA"></a>2.1 CTA</h3><p>理解 CTA 的关键，在于理解软件编程模型与硬件之间的对应关系。</p>
<p>是不是有了 warp 这个概念，我们剩下的事情就是在软件层面设计 warp 内的指令就够了。其实并没有，首先，warp 是局限于一个 SM 内的，而且是没有办法在不同的 SM 之间迁移的。所以如果我们希望充分利用不同的 SM，那么就要引入 CTA（Collaborative Thread Array） 的概念，一个 CTA 必须在一个特定的 SM 上，不同的 CTA 可以在不同的 SM 上，一个 SM 上可以有多个 CTA。CTA 是非常像软件 thread 的概念，一个 thread 同时仅能在一个 CPU Core 上运行，不同 thread 可以在不同的 CPU Core 上运行。有了这个概念后，我们就可以利用 <code>ctaid</code> 来在软件中使用不同的 SM，当然这种使用，有一部分是依赖于 GPU 内部的硬件调度器，这就像我们没法简单指定某个 thread 一定要与某个 CPU Core 绑定一样。</p>
<p>那是不是 CTA 这个“软件线程”就直接用 warp 这个“硬件线程”来一一对应就好了呢？并不是，这是因为 warp 内的 thread 数目是静态的 32 ，是不可调整的。而在软件编程中，我们希望在一个 SM 中启动的 thread 数目（也就是 CTA 中 thread 的数目）是动态的。这是因为一个 SM 内的许多资源，都不是 warp 独占，而是 warp 共享的，比如说 shared memory，两个不同的 warp 是可以利用同一片资源的。也就是说，如果 CTA 内可以包含多个 warp，那么同一个 CTA 中的不同 warp 就是可以协作的。因此，CTA 中 thread 的数目往往是 32 的倍数。</p>
<p>正如前所述，还有 CTA 名字中的 Collaborative 的暗示，在同一个 CTA 中的 thread 具有很好的协作性，这主要体现在两点：</p>
<ul>
<li>共享内存：如前所述，同一个 CTA 中的 thread 可以读取相同的 shared memory。</li>
<li>同步：同一个 CTA 内的线程可以通过 <code>__syncthreads()</code> 这样的同步指令（Barrier）来协调彼此的执行进度。不过这点有些多余，因为不同 CTA 往往是在不同 SM 上，资源竞争的可能性小了很多。</li>
</ul>
<p>在 CUDA 中，CTA 也被称作 Block，而 CTA 组被称为 Grid。如果我们希望定位到一个 thread，我们可以使用如下代码：</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">int idx = blockIdx.x * blockDim.x + threadIdx.x;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>而这段代码如果对应成 PTX 代码，如下所示：</p>
<pre class="line-numbers language-assembly" data-language="assembly"><code class="language-assembly">mov.u32 %idx, %tid.x;          // idx = threadIdx.x
mov.u32 %r2, %ntid.x;          // r2 = blockDim.x
mov.u32 %r3, %ctaid.x;         // r3 = blockIdx.x
mad.lo.s32 %idx, %r3, %r2, %idx; // idx = r3 * r2 + idx<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>从这点也可以看出，SIMT 模型是从硬件层面支持的，而不是用编译器，从汇编层面支持的。</p>
<p>我们也可以看出，我们在写 kernel 的时候，用 <code>&lt;&lt;&lt;grid, block&gt;&gt;&gt;</code> 二元组来描述并行，是非常必要的，不能只用一个一元组去描述。</p>
<h3 id="2-2-Grid-and-Block"><a href="#2-2-Grid-and-Block" class="headerlink" title="2.2 Grid and Block"></a>2.2 Grid and Block</h3><p>虽然已经在上一个 section 从线程协作的角度介绍过了 CTA，但是我还是希望在从编程实践的角度介绍一下 <code>grid</code> 和 <code>block</code>。</p>
<p>我们可以这样理解，我们为了让 GPU 的利用率变高，我们有两种思路：</p>
<ul>
<li>inter-SM：也就是要利用每一个 SM，不能有 SM 的闲置。</li>
<li>intra-SM：也就是要用好每一个 SM，SM 不能有闲置的资源。</li>
</ul>
<p>我们要保证这两种利用率都提高，直接说结论：Grid 越大，inter-SM 的利用率越容易高，Block 越大，intra-SM 的利用率越容易高。</p>
<p>考虑到并行任务的数目固定，那么 Grid 越大，则 Block 越小，inter-SM 利用率越高，intra-SM 利用率越低，反之也成立。所以我们要在 Grid 和 Block 之间做 tradeoff。</p>
<p>之所以有上面的结论，是因为 Block 只能在一个 SM 上运行，并且由多个 Warp 组成。所以为了提高 intra-SM 的利用率，Block 就要提高其中的 Warp 数量，这样才能在某个 warp 阻塞等待时，及时切换其他的 Warp。而为了提高 inter-SM 的利用率，Grid 里的 Block 就要足够多，才能占据全部的 SM（一个 Block 只能固定在一个 SM 上）。</p>
<p>至于为什么 Grid 和 Block 都是 <code>(uint, uint, uint)</code> 的三元组，这跟利用率无关，只是为了方便编程，比如在处理向量的时候，我们可以在只使用 1 个维度，而在处理视频的时候，就需要 3 个维度了。</p>
<h3 id="2-3-Memory-Type"><a href="#2-3-Memory-Type" class="headerlink" title="2.3 Memory Type"></a>2.3 Memory Type</h3><p>不同于简单的 CPU 编程，只用操作一种内存。当我们使用 CUDA 的时候，可以操纵多种不同类型的内存。</p>
<p>CUDA 中的类型如下所示：</p>
<p><img src="/posts/848ac0f9/memory-spaces-on-cuda-device.png" alt="Memory spaces on a CUDA device"></p>
<p>CUDA 使用 <code>__device__</code> 来声明一个全局变量，可以被所有 kernel 访问。如下所示：</p>
<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">__device__ <span class="token keyword">unsigned</span> <span class="token keyword">long</span> <span class="token keyword">long</span> g_total_sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>而局部变量的使用更为复杂。我们在 kernel 中声明的局部变量，优先存放在寄存器中。而如果局部变量如果过多，就会存放到 local memory 中，这种 local memory 也是 thread 独享的。那是不是很快呢？并不是，local memory 是在显存上的一片区域，考虑到 GPU 那孱弱的 cache，local memory 的访问时延非常高。</p>
<p>那有没有什么时延更低的方案呢？有的，就是 Shared Memory，我们可以在局部变量前增加 <code>__shared__</code> 来表示放在共享内存中的变量：</p>
<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">__global__ <span class="token keyword">void</span> <span class="token function">myKernel</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    __shared__ <span class="token keyword">float</span> shared_data<span class="token punctuation">[</span>BLOCK_SIZE<span class="token punctuation">]</span><span class="token punctuation">;</span>
    <span class="token comment">// ...</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>在对共享内存进行计算之前，必须确保所有线程都已经完成了上一步的数据加载。否则，一些线程可能会读到旧的、无效的数据（竞态条件 Race Condition）。使用 <code>__syncthreads()</code> 来实现同步。</p>
<p>总结如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Memory</th>
<th>Location on/off chip</th>
<th>Cached</th>
<th>Access</th>
<th>Scope</th>
<th>Lifetime</th>
</tr>
</thead>
<tbody>
<tr>
<td>Register</td>
<td>On</td>
<td>n/a</td>
<td>R/W</td>
<td>1 thread</td>
<td>Thread</td>
</tr>
<tr>
<td>Local</td>
<td>Off</td>
<td>Yes</td>
<td>R/W</td>
<td>1 thread</td>
<td>Thread</td>
</tr>
<tr>
<td>Shared</td>
<td>On</td>
<td>n/a</td>
<td>R/W</td>
<td>All threads in block</td>
<td>Block</td>
</tr>
<tr>
<td>Global</td>
<td>Off</td>
<td>Yes</td>
<td>R/W</td>
<td>All threads + host</td>
<td>Host allocation</td>
</tr>
<tr>
<td>Constant</td>
<td>Off</td>
<td>Yes</td>
<td>R</td>
<td>All threads + host</td>
<td>Host allocation</td>
</tr>
<tr>
<td>Texture</td>
<td>Off</td>
<td>Yes</td>
<td>R</td>
<td>All threads + host</td>
<td>Host allocation</td>
</tr>
</tbody>
</table>
</div>
<h3 id="2-4-Sync-and-Stream"><a href="#2-4-Sync-and-Stream" class="headerlink" title="2.4 Sync and Stream"></a>2.4 Sync and Stream</h3><p>CPU 和 GPU 协作的方式是异步的，也就是说，CPU 在向 GPU 发送指令后，是不会等待指令返回的，它就会自己往下运行了，所以如果 CPU 想要获得 GPU 的运行结果，需要先执行同步操作：</p>
<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token function">cudaDeviceSynchronize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>不过 GPU 本身，默认是串行执行指令的，这就导致 kernel 是没有办法并行执行的，也就没有办法进行一些访存延迟隐藏之类的优化。为了改善这一点，CUDA 提出了 Stream 的概念。</p>
<p>在你不使用 Stream 的情况下，所有 CUDA 操作（比如在 GPU 上计算、在 CPU 和 GPU 之间拷贝数据）都默认放入一个叫做 “默认流”（Default Stream） 的大队列里。我们只需要声明多个 Stream，就可以实现并发。同一个 Stream 内的指令是顺序执行的，而不同 Stream 中的指令是可以并发执行的。</p>
<hr>
<h2 id="三、Triton"><a href="#三、Triton" class="headerlink" title="三、Triton"></a>三、Triton</h2><h3 id="3-1-Tiled-Based"><a href="#3-1-Tiled-Based" class="headerlink" title="3.1 Tiled-Based"></a>3.1 Tiled-Based</h3><p>与 CUDA 不同，Triton 并不是 SIMT 编程模型，而是 Tiled-Based 编程模型，或者换种说法，是一种 SIMD 模型。我们没有办法像在 CUDA 编程一样，操纵每个线程（或者说每个标量），我们只能操纵一个向量或者一个张量，当然了，此时他们被叫作 Tile。</p>
<p>在 Triton 中我们也有 grid 的概念，我们用 grid 来组织“Program Instance”，每个 Program Instance 负责一个 Tile。需要强调的是，此时的组织，不再是真的硬件映射关系了，往往只是一种算法逻辑上的分块。</p>
<p>（如果要深究的话，一个 Triton 的 PI，对应一到多个 CTA）。</p>
<p>当我们计算一个矩阵加法 $C = A + B$ 时，第 $(m, n)$ 个 PI，负责的就是第 $(m, n)$ 个 Tile 的计算。在启动核函数时，我们指定 grid 参数：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 定义块大小 (Tile size)</span>
<span class="token comment"># 可以根据具体硬件和矩阵形状进行调整以获得最佳性能</span>
BLOCK_SIZE_M <span class="token operator">=</span> <span class="token number">32</span>
BLOCK_SIZE_N <span class="token operator">=</span> <span class="token number">32</span>
    
<span class="token comment"># 定义 grid，这里是关键！</span>
<span class="token comment"># 使用 triton.cdiv (ceiling division) 来确保所有元素都被覆盖</span>
grid_m <span class="token operator">=</span> triton<span class="token punctuation">.</span>cdiv<span class="token punctuation">(</span>M<span class="token punctuation">,</span> BLOCK_SIZE_M<span class="token punctuation">)</span>
grid_n <span class="token operator">=</span> triton<span class="token punctuation">.</span>cdiv<span class="token punctuation">(</span>N<span class="token punctuation">,</span> BLOCK_SIZE_N<span class="token punctuation">)</span>
<span class="token comment"># 将 grid 定义为一个二元组</span>
grid <span class="token operator">=</span> <span class="token punctuation">(</span>grid_m<span class="token punctuation">,</span> grid_n<span class="token punctuation">)</span>
    
<span class="token comment"># 启动核函数</span>
add_kernel<span class="token punctuation">[</span>grid<span class="token punctuation">]</span><span class="token punctuation">(</span>
    a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> c<span class="token punctuation">,</span>                       <span class="token comment"># 指针</span>
    M<span class="token punctuation">,</span> N<span class="token punctuation">,</span>                          <span class="token comment"># 维度</span>
    a<span class="token punctuation">.</span>stride<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> a<span class="token punctuation">.</span>stride<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      <span class="token comment"># 矩阵 A 的步长</span>
    b<span class="token punctuation">.</span>stride<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> b<span class="token punctuation">.</span>stride<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      <span class="token comment"># 矩阵 B 的步长</span>
    c<span class="token punctuation">.</span>stride<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> c<span class="token punctuation">.</span>stride<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      <span class="token comment"># 矩阵 C 的步长</span>
    BLOCK_SIZE_M<span class="token operator">=</span>BLOCK_SIZE_M<span class="token punctuation">,</span>     <span class="token comment"># constexpr 参数</span>
    BLOCK_SIZE_N<span class="token operator">=</span>BLOCK_SIZE_N<span class="token punctuation">,</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>而在算子内部，我们使用 <code>program_id</code> 获得 grid 参数：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 1. 使用二维 program_id 获取当前程序实例负责的块的索引</span>
<span class="token comment"># axis=0 对应 grid 的第一个维度 (行方向)</span>
pid_m <span class="token operator">=</span> tl<span class="token punctuation">.</span>program_id<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment"># axis=1 对应 grid 的第二个维度 (列方向)</span>
pid_n <span class="token operator">=</span> tl<span class="token punctuation">.</span>program_id<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>那么在 Tiled-Based 的编程模型下，我们是如何操作数据的呢？答案是我们使用“offsets 张量”。offset 可以理解为一个标量数据的地址，而一个 offsets 张量，就可以理解为一组数据的地址。我们用一个 numpy-like 的方法表示这组 offset，如下所示：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 2. 计算当前块的二维偏移量</span>
<span class="token comment"># 首先，计算 M 维度 (行) 的偏移量向量</span>
<span class="token comment"># tl.arange 生成 [0, 1, 2, ..., BLOCK_SIZE_M-1]</span>
offs_m <span class="token operator">=</span> pid_m <span class="token operator">*</span> BLOCK_SIZE_M <span class="token operator">+</span> tl<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> BLOCK_SIZE_M<span class="token punctuation">)</span>
<span class="token comment"># 然后，计算 N 维度 (列) 的偏移量向量</span>
offs_n <span class="token operator">=</span> pid_n <span class="token operator">*</span> BLOCK_SIZE_N <span class="token operator">+</span> tl<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> BLOCK_SIZE_N<span class="token punctuation">)</span>

<span class="token comment"># 3. 计算加载/存储数据的完整二维指针偏移量</span>
<span class="token comment">#    利用广播机制 (broadcasting) 将一维的行、列偏移量扩展成二维</span>
<span class="token comment">#    offs_m[:, None] -&gt; [BLOCK_SIZE_M, 1]</span>
<span class="token comment">#    offs_n[None, :] -&gt; [1, BLOCK_SIZE_N]</span>
<span class="token comment">#    相加后得到一个 [BLOCK_SIZE_M, BLOCK_SIZE_N] 的偏移矩阵</span>
a_offsets <span class="token operator">=</span> a_ptr <span class="token operator">+</span> <span class="token punctuation">(</span>offs_m<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> stride_am <span class="token operator">+</span> offs_n<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">*</span> stride_an<span class="token punctuation">)</span>
b_offsets <span class="token operator">=</span> b_ptr <span class="token operator">+</span> <span class="token punctuation">(</span>offs_m<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> stride_bm <span class="token operator">+</span> offs_n<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">*</span> stride_bn<span class="token punctuation">)</span>
c_offsets <span class="token operator">=</span> c_ptr <span class="token operator">+</span> <span class="token punctuation">(</span>offs_m<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> stride_cm <span class="token operator">+</span> offs_n<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">*</span> stride_cn<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以看到在上面式子中，我们得到了最终我们分别得到了 a_tile, b_tile, c_tile 对应的 offsets 张量，他们的形状都是 tile 的形状，也就是 <code>[BLOCK_SIZE_M, BLOCK_SIZE_N]</code> 。</p>
<p>当然，在编程中，我们也有一些边界情况，或者控制分支需要处理。在 CUDA 中，我们可以随意使用 <code>if-else</code> 这种条件判断，毕竟我们提供的是 SIMT 抽象，但是在 Triton 中，我们并不能进行分支判断，所以我们利用了 mask 张量，如下所示：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 4. 创建二维掩码 (mask) 以处理边界情况</span>
<span class="token comment">#    防止因矩阵尺寸不是块大小的整数倍而导致的越界访存</span>
mask_m <span class="token operator">=</span> offs_m <span class="token operator">&lt;</span> M
mask_n <span class="token operator">=</span> offs_n <span class="token operator">&lt;</span> N
<span class="token comment"># 使用广播和逻辑与操作合并成二维掩码</span>
mask <span class="token operator">=</span> mask_m<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">&amp;</span> mask_n<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>当我们拿到这些 offsets 张量和 mask 张量后，我们就可以在上面应用算子了，比如说 <code>load, store, dot, +</code> 等：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 5. 安全地加载数据块</span>
<span class="token comment">#    mask=mask 确保只加载有效区域的数据</span>
<span class="token comment">#    other=0.0 指定在掩码为 False 的位置加载 0.0，避免计算错误</span>
a_tile <span class="token operator">=</span> tl<span class="token punctuation">.</span>load<span class="token punctuation">(</span>a_offsets<span class="token punctuation">,</span> mask<span class="token operator">=</span>mask<span class="token punctuation">,</span> other<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>
b_tile <span class="token operator">=</span> tl<span class="token punctuation">.</span>load<span class="token punctuation">(</span>b_offsets<span class="token punctuation">,</span> mask<span class="token operator">=</span>mask<span class="token punctuation">,</span> other<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>

<span class="token comment"># 6. 执行核心计算</span>
c_tile <span class="token operator">=</span> a_tile <span class="token operator">+</span> b_tile

<span class="token comment"># 7. 将结果安全地写回</span>
tl<span class="token punctuation">.</span>store<span class="token punctuation">(</span>c_offsets<span class="token punctuation">,</span> c_tile<span class="token punctuation">,</span> mask<span class="token operator">=</span>mask<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<hr>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/" rel="tag"><i class="fa fa-tag"></i> 知识总结</a>
              <a href="/tags/Sys4AI/" rel="tag"><i class="fa fa-tag"></i> Sys4AI</a>
              <a href="/tags/S10%E5%81%87%E6%9C%9F/" rel="tag"><i class="fa fa-tag"></i> S10假期</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/posts/7e0ffd77/" rel="prev" title="计算机系统-指标">
      <i class="fa fa-chevron-left"></i> 计算机系统-指标
    </a></div>
      <div class="post-nav-item">
    <a href="/posts/51a455b3/" rel="next" title="吃喝玩乐-认识自我">
      吃喝玩乐-认识自我 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
<script src="https://utteranc.es/client.js"
        repo="Thysrael/blog-comment"
        issue-term="title"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E3%80%81Hardware"><span class="nav-text">一、Hardware</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-SM"><span class="nav-text">1.1 SM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-Schedule"><span class="nav-text">1.2 Schedule</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-SIMT"><span class="nav-text">1.3 SIMT</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-Memory-Hierarchy"><span class="nav-text">1.4 Memory Hierarchy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-5-Interconnect"><span class="nav-text">1.5 Interconnect</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-6-Terminology"><span class="nav-text">1.6 Terminology</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E3%80%81CUDA"><span class="nav-text">二、CUDA</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-CTA"><span class="nav-text">2.1 CTA</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-Grid-and-Block"><span class="nav-text">2.2 Grid and Block</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-Memory-Type"><span class="nav-text">2.3 Memory Type</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-Sync-and-Stream"><span class="nav-text">2.4 Sync and Stream</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%89%E3%80%81Triton"><span class="nav-text">三、Triton</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-Tiled-Based"><span class="nav-text">3.1 Tiled-Based</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Thysrael"
      src="/images/avatar2.png">
  <p class="site-author-name" itemprop="name">Thysrael</p>
  <div class="site-description" itemprop="description">Thysrael 的个人技术博客，专注于计算机科学基础与系统架构。内容涵盖操作系统(Linux/Unix)、计算机组成原理(MIPS/Verilog)、数据库(DBMS)、编译技术(LLVM)、并行计算(GPU/CUDA)及人工智能系统(Sys4AI)。同时分享算法设计、数学分析笔记以及生活随笔。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">200</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">31</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">70</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="">
    <a target="_blank" class="social-link" href="/atom.xml" style="color: burlywood;">
      <span class="icon">
        <i class="fa fa-rss"></i>
      </span>
      <span class="label">RSS</span>
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/thysrael" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;thysrael" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:thysrael@163.com" title="E-Mail → mailto:thysrael@163.com" rel="noopener external nofollow noreferrer" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2021.12.18 – 
  <span itemprop="copyrightYear">2026</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Thysrael</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="Symbols count total">1.3m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">20:25</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  
  <script>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
