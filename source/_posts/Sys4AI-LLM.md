---
layout: post
title: Sys4AI-LLM
mathjax: true
abbrlink: 7dc4ea13
date: 2025-01-30 22:24:19
categories: Sys4AI
tags: ["S9假期", "Sys4AI", "直观理解"]
---

## 一、总论

当我们提到大模型 LLM 的时候，总是和 Transformer 这种架构联系在一起，似乎只有使用了 Transformer 架构的深度学习模型才配叫作大模型。

不过以我目前浅薄的认知，我倒觉得 Transformer 并不是 LLM 的核心特征，因为 LLM 的算法变化很快，Transformer 从 2017 年到现在有了多种变体，也有完全不采用 Transformer 架构的 AI。我个人感觉 LLM 的核心有两点：

- 模型参数极大：我们认为模型参数越多，模型就越智能。这是“涌现”的一种具体体现。
- 采用“预训练-微调-推理”范式：这种范式使得模型的通用性得到了增强，划分了不同的生态位。

我希望在下文中记录一下关于 LLM 或者 Foundation Model 的基础知识，以避免被这个时代抛下太久。

---



## 二、数学基础

### 2.1 GEMM 时间复杂度

### 2.2 反向传播求导

### 2.3 IM2Col



## 三、Transformer

