---
abbrlink: 2173e956
categories: 概率统计
date: 2021-12-19 18:19:12
mathjax: true
tags: [S3复习, 概率统计, 直观理解]
title: 概率统计-概率论与客观世界的桥梁
---

之前章节介绍的概率论，只是一个数学的空中楼阁，我们要想办法让其与客观世界产生联系。

产生联系的方法就是通过一个新的概念**随机序列**，也就是对同一个试验的重复进行（这个挺显然的），随机序列会产生一组随机变量（也可以看做一个随机向量）。但是这是第一步，然后我们利用随机序列构造一个新的随机变量，构造方法就是我们对数据组的处理方法，比如我们对数据组求平均值，那么我们构造的这个随机变量就是所以随机变量的求平均。然后对这个新的随机变量的性质展开研究。

也就是说，我们通过**构造**这种数学方式，模拟了现实中的数据处理方式，为由**理论指导现实**奠定了基础。比如说**中心极限定理**，就是一个理论指导现实的例子。

但是另一方面，**现实需要为理论提供参照**，借助的就是大数定理，大数定律支持了将现实中获得的频率近似为概率的做法。

<!-- more -->

## 一、不等式

### 1.1 马尔科夫不等式

$$
P(\mid X \mid \geq \epsilon) \leq \frac{E\mid X\mid^k}{\epsilon^k}
$$

不等式的引入是为了大数定理服务的，大数定理最重要的是**做无穷次试验**的思想，这个定理提供了一个很好的放缩。	

这个不等式应该没啥用，其实是对 $X$ 进行变量代换以后产生的**切比雪夫不等式**比较有用。

### 1.2 切比雪夫不等式

对马尔科夫不等式中的 $X$ 替换为 $X - EX$ ，然后取 k = 2。可以得到切比雪夫不等式
$$
P(\mid X - EX\mid \geq \epsilon) \leq \frac{E\mid X -EX\mid^2}{\epsilon^2}
$$
整理的好看一些，有
$$
P(\mid X - EX \mid < \epsilon) \geq 1 - \frac{DX}{\epsilon^2}
$$
这个式子的用处就在于，我们可以度量 $X - EX$ 在某个范围时的概率，如果这个范围狭小到像一个缝一样，我们就可以认为它俩相等了。

---



## 二、大数定理

### 2.1 构造随机向量

正如摘要所述，通过重复试验，我们获得了一个随机变量序列 $X_1, X_2, \cdots, X_n,\cdots$。那么我们构造这样的随机变量（其实也是随机变量序列，不然没法对n取极限）
$$
Y_n = \frac{1}{n}\sum^{n}_{i = 1}X_i
$$
其实 $Y_n$ 就对应我们在客观世界求平均数的过程。

### 2.2 三个大数定律

**切比雪夫大数定律**是最基础的，也是对条件要求最弱的，也是完整推导的（其他的可以看成其推论），其推导过程蕴含了我们的处理 思想。

切比雪夫大数定理要求 $X_1, X_2, \cdots, X_n,\cdots$ 是相互独立的，而且每个 $X_i$ 方差有上界，设序列的方差的上界为 C，有如下推导
$$
EY_n = \frac{1}{n}\sum^n_{i=1}EX_i
$$

$$
DY_n = \frac{1}{n^2}\sum^n_{i=1}DX_i \leq  \frac{1}{n^2}\sum^n_{i=1}C \leq \frac{C}{n}
$$

由切比雪夫不等式知
$$
P(\mid Y_n - EY_n \mid < \epsilon) \geq 1 - \frac{DY_n}{\epsilon^2} \geq 1 - \frac{C}{n\epsilon^2}
$$
当n趋无穷的时候，可以看到概率为1。

但是这个还不是我们要的东西，我们是对一次试验重复操作，所以 $X_i$ 间是同分布的，如果限定了这个条件，我们可以获得一个更好的结论，即**辛钦大数定律**。

辛钦大数定律说的是 $X_i$ 具有相同的数学期望 $\mu$（他还说相同方差，但是我觉得有界方差就够了），那么就有
$$
EY_n = \frac{1}{n}\sum^n_{i=1}EX_i = \mu
$$
应用切比雪夫不等式，有
$$
P(\mid Y_n - \mu \mid < \epsilon) \geq 1 - \frac{DY_n}{\epsilon^2} \geq 1 - \frac{C}{n\epsilon^2}
$$
所以收敛于 $\mu$。

它提供了用样本均值估计总体均值的作为总体均值 $\mu$ 的理论依据。

但是这还跟我们想要的**用频率估计概率**有一定差距，**伯努利大数定律**解决了这个问题。伯努利构造的 $X_i$  是一个两点分布，表示在一次试验中需要求概率的事件的发生与否，设一共进行了n次试验，发生了 $n_A$ 次，发生的概率是 p，有
$$
Y_n = \frac{1}{n}\sum^{n}_{i = 1}X_i = \frac{n_A}{n}
$$

$$
EY_n = p
$$

带入辛钦大数定理，有
$$
\lim_{n \rightarrow \infty}P(\mid\frac{n_A}{n} - p \mid < \epsilon) = 1
$$
至此，所有大数定理介绍完毕。

---



## 三、中心极限定理

首先，我们先有一个直观认识，：如果一个量是由大量相互独立的随机因素（可以看做随机变量）造成的，而每个因素在总量中的所起的作用又较小，那么这种量通常服从正态分布。

那么这些随机变量如果恰好是随机序列中的变量，那么就符合上面描述的条件了（每个变量造成的影响较小）。那么是否说明我们只要对一个总体重复取样，最后得到的样品数据一定是正态分布呢？中心极限定理就在描述这个事情。

设 $X_1, X_2, \cdots, X_n,\cdots$ 独立且同分布，设
$$
EX_i = \mu,\quad \quad DX_i = \sigma^2
$$
构造随机变量 
$$
\bar{X} = \frac{1}{n}\sum^{n}_{i = 1}X_i
$$
则 $\bar{X} \sim N(\mu, \frac{\sigma^2}{n})$。

直观理解一下，就是说，取样的均值是 $\mu $，方差要比原来的方差要小，而且会随着n的增大逐渐减小，这些都是非常直观的性质。

需要强调的是，取样的总体不一定非得是服从正态分布的，哪怕是从一个不服从正态分布的整体中取样，取样数据组依然是符合正态分布的，这就是这个定理美妙的地方。

我们将其修改的更加偏应用一些，就有了**棣莫佛-拉普拉斯定理**：

设 $\mu_n$ 是 $n$ 次独立重复试验中事件 A 发生的次数，$p$ 是发生的概率，那么对任意区间 $[a, b]$ ，有
$$
\lim_{n\rightarrow\infty} P(a < \frac{\frac{\mu_n}{n} - p}{\sqrt{\frac{p(1-p)}{n}}}<b) = \Phi(a) - \Phi(b)
$$
