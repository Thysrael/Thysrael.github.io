---
abbrlink: 8ceebdaa
categories: 概率统计
date: 2021-12-21 19:24:26
mathjax: true
tags: [概率统计, 直观理解, S3复习, 知识总结]
title: 概率统计-数理统计
---


数理统计首先要做的，是分清两种随机变量，一个是总体的分布相关的数字特征，另一个是我们根据取样产生的**随机变量序列**构造出的特殊的随机变量**统计量**。

我们**用样本研究总体**，其理论依据来源于概率论，**当一个事件的概率大，那么我们就认为这件事情是真的。**

**标准分布**是一个重要的思想。

在这一章里，我会进行大量的我个人色彩浓重的不严谨规范和定义，是因为以我的能力，还不足以严谨的把事情说清楚。

<!-- more -->




## 一、总论

### 1.1 总体

有一种说法是，我们研究的对象的全体称为**全体**，比如说我想了解大学一年级学生的身高，那么全体就是大一年级学生。但是我不喜欢这种说法，因为它没有把我们到底要干什么说清楚，我喜欢的是另一种说法，我们关心的是研究对象的某个指标，也就是说是那个随机变量。在这个例子中，就是**大学一年级学生的身高分布**。但是这够精确了，但是跟我们的概率论还没有关系。因为身高不是随机变量，一个年级比如说有100个人，这100个人的身高是确定的，只要我挨个记录下了100个人的身高，那么这件事情就定死了，完全用不到概率论。之所以用到概率论，是因为我们放弃了**一个一个数**这种方法。转而采用抽样的方法。**抽样的本质是一个试验**，所以我们研究的就是这个试验。说到底，我们本质在研究抽样的试验结果这个**随机变量**。

这个随机变量的概率分布是等于总体的频度分布的（这个才是客观的），而总体的频度分布才是我们最想知道的，只是我们没法研究，所以只能退而求其次，研究抽样试验的结果。

总体随机变量会有分布特征和数字特征，这些都反映了总体的特征，这些指标我们会有一套符号体系，比如说 $\mu,\sigma$。但是需要注意的是，$\mu,\sigma$ 只是参数，是没有意义的，我们平时说“正态分布的期望等于 $\mu$ ”，不是说 $\mu$ 是正态分布的期望，而是 $\mu$ 恰好等于正态分布的期望。之所以强调这点，是因为“期望”这个词很容易让人想到**求均值**，而求均值就很容易让人想到 $\bar{x}$ ，而其实在这一章里，把他们区分开，就是最难的事情。

此外，为什么说 $\mu,\sigma$ ，而不提其他参数呢，是因为我们的研究对象只局限于**正态总体**，因为好研究。但是对于非正态总体，似乎也可以利用中心极限定理（棣莫佛-拉普拉斯定理）做一定的研究。到时再说。

### 1.2 统计量	

按理来说，我们就需要做一次试验就够了，比方说我们做了一次试验，那么就会得到一个随机变量 $X_1$ ，那么这个 $X_1$ 的分布其实就是总体的分布，但是这只是理论分析，因为一个试验做完以后，会有一个确定的结果（我们称其为观测值），比如叫 $x_1$ ，那么这个 $x_1$ 就不是随机变量了，所以我们才需要做多组试验，然后用一组观测值的频度分布，去推测总体的概率分布。

上面引入了**观测值**这个概念，我不满意教材的地方是，它构造统计量的时候，公式推导大量用的是观测值，虽然说观测值确实是我们构造统计量时所采用的数据，但是因为观测值不是随机变量，所以由此构造出来的统计量也不是随机变量，那么考察统计量的分布，就是一件错误的事情了。

为了解决上面提出的两个问题，我们采用的方法是引入**随机变量序列**的概念，也就是说，我们对其做很多次试验，每次试验的结果都看做一个随机变量，由这些随机变量组成的序列，我们称其为**随机变量序列**，也就是 $X_1, X_2, X_3, \cdots, X_n, \cdots$ 。这些随机变量是独立的、同分布的，而且分布是与总体分布相同的。

有一个不自然的地方就是，我总认为，一旦试验的次数提高了，那么我们用从观测值分布就一定能够看出总体分布，甚至认为他们就是一个分布，但是这是不正确的。按照中心极限定理的说法，无论是什么分布，取出的样品的分布一定是正态分布（这里我可能有理解问题）。

然后介绍**统计量**，统计量是由 $X_1, X_2, X_3, \cdots, X_n, \cdots$ 构造出的随机变量，那么为什么要构造他们呢？其实**只是为了好算**，好算指的是后面的计算**置信区间**的时候，可以直接查表。他们的构造，就跟为啥要构造标准正态分布是一个道理，所谓的卡方分布，或者是t分布，只是另一种形式意义上的标准正态分布而已，我们可以查表来算他们。如果不构造他们，其实也是可以算的，只不过算的时候，有一大堆没有办法用初等函数表示的积分，制造困难而已。统计量其实是**随机变量的函数**这一章的延伸。

更更有趣的是，上面讲的其实如果依照课本来说，是错误的，因为课本中要求统计量中是不能有总体分布的参数出现，比如不能出现$\mu,\sigma$，而服从各种标准分布的随机变量，都是含有参数的，所以严格的讲，他们不能叫做统计量。

所谓的标准分布，到底好在了哪里？好在了我们完全了解他们，我们知道他们的密度函数表达式是什么，虽然分布函数的表达式写不出来，但是我们有表，就等于知道了所有的概率分布。如果一个随机变量服从这些标准分布，我们就完全了解了这些随机变量，我们想求一个区间的概率密度，一查表，事情就解决了。

不管我们构造的随机变量，长得多没有意义，看上去就像随便堆出来的，不管我们的标准分布，写出来有多么复杂，多么在现实中找不到应用的例子，**我们只关注只要随机变量服从标准分布**，那么事情就在我们控制的范围内，这就是意义。

我不喜欢**样本矩**的说法，因为**矩**原本是用来形容**一个**随机变量的特征的，但是**样本矩**却是用来形容随机变量序列的特征的，所以这个概念有混淆的可能。所以我想取消这种说法。

比较常用的统计量和符号
$$
\bar{X} = \frac{1}{n}\sum^n_{i = 1}X_i
$$

$$
S^2 = \frac{1}{n - 1}\sum^n_{i = 1}(X_i - \bar{X})^2
$$

----



## 二、标准分布的应用

### 2.1 区间估计

采用区间估计的核心思路步骤：

- 构造出一个随机变量中既包括统计量，又包括未知参数，这个随机变量服从某标准分布。
- 给定一个置信概率 $\alpha$，查表获得该随机变量的一个区间
- 该随机变量的一个区间本质是这个随机变量的一个不等式方程或者方程组
- 通过解这个不等式组，获得未知参数的取值范围，即置信区间

在这一节里，所有的样品随机变量不在使用大写，而是使用小写，这标志着这是对一次观测值的构造。

#### 2.1.1 $\sigma$ 已知的情况，对 $\mu$ 的估计

原理：
$$
\frac{\bar{X} - \mu}{\sigma / \sqrt{n}} \sim N(0, 1)
$$
通过查表，可以得到 $ z_{ 1-\frac{\alpha}{2} }$ 
$$
P(\mid\frac{\bar{x} - \mu}{\sigma/\sqrt{n}}\mid \leq z_{ 1-\frac{\alpha}{2} }) = 1 - \alpha
$$
所以我们的问题就转化成了，解不等式
$$
- z_{ 1-\frac{\alpha}{2} } \leq \frac{\bar{x} - \mu}{\sigma/\sqrt{n}} \leq  z_{ 1-\frac{\alpha}{2} } 
$$
经过整理以后就可以得到
$$
[\bar{x} -  z_{ 1-\frac{\alpha}{2} } \frac{\sigma}{\sqrt{n}},\quad \bar{x} +  z_{ 1-\frac{\alpha}{2} }\frac{\sigma}{\sqrt{n}} ]
$$
这就是我们的所求。我们完成了一个由置信概率到置信区间的映射。

#### 2.1.2 $\sigma$ 未知的情况，对 $\mu$ 的估计

原理：

因为没有 $\sigma$ ，所以只能用样本方差来代替，但是相应的，构造出的变量也不再服从正态分布了，而是服从 $t$ 分布
$$
\frac{\bar{X} - \mu}{S / \sqrt{n}} \sim t(n - 1)
$$
结论：
$$
[\bar{x} -  t(n-1)_{ 1-\frac{\alpha}{2} } \frac{\sigma}{\sqrt{n}},\quad \bar{x} +  t(n-1)_{ 1-\frac{\alpha}{2} }\frac{\sigma}{\sqrt{n}} ]
$$
#### 2.1.3 估算 $\sigma $

原理：
$$
(n - 1)\frac{S^2}{\sigma^2} \sim \chi^2(n-1)
$$
结论：
$$
[\frac{(n - 1)s^2}{\chi^2_{1-\frac{\alpha}{2}}(n-1)},\quad \frac{(n - 1)s^2}{\chi^2_{\frac{\alpha}{2}}(n-1)}]
$$
之所以这个式子中既出现 $\chi^2_{1-\frac{\alpha}{2}}(n - 1)$ ，又出现 $\chi^2_{\frac{\alpha}{2}}(n - 1)$ 。是因为 $\chi^2$ 分布没有对称性。

#### 2.1.4 两正态分布相关估计

##### 2.1.4.1 已知 $\sigma_1, \sigma_2$，估算均值差：

原理：
$$
\frac{(\bar{x} - \bar{y}) - (\mu_1 - \mu_2)}{\sqrt{\sigma_1^2/m + \sigma_2^2/n}} \sim N(0,1)
$$
##### 2.4.1.2 未知 $\sigma_1, \sigma_2$，估算均值差：

原理：

因为 $t$ 分布不像卡方分布或者正态分布一样，同分布的相加后依然保持原分布，所以我们依然使用标准正态分布作为标准分布，但是这就要求m和n足够大。

$$
\frac{(\bar{x} - \bar{y}) - (\mu_1 - \mu_2)}{\sqrt{s_1^2/m + s_2^2/n}} \sim N(0,1)
$$
##### 2.4.1.3 未知 $\sigma_1, \sigma_2$ 但 $\sigma_1, \sigma_2$相等，估算均值差

原理：
$$
\frac{(\bar{X_1} - \bar{X_2}) - (\mu_1 - \mu_2)}{(m - 1)S_1^2 + (n - 1)S_2^2}\cdot\sqrt{\frac{mn(m + n -2)}{m + n}} \sim t(m + n - 2)
$$
##### 2.4.1.4 二正态总体方差比

原理：
$$
\frac{S_1^2/\sigma_1^2}{S_2^2/\sigma_2^2} \sim F(n-1, m - 1)
$$
### 2.2 参数检验

参数检验的思想与区间估计的思想一致，就不在此一一赘述了。

### 2.3 分布检验

#### 2.3.1 参数已知的分布检验

利用的是皮尔逊 $\chi^2$ 统计量，这种统计量服从 $\chi^2$ 分布。
$$
K = \frac{\sum^{k}_{i = 1}(n_i - np_i)^2}{np_i} \sim \chi^2(k - 1)
$$
其中我们需要将数轴分为 $k$ 个不相交的区间（如果是离散型，那么离散型随机变量有几个取值，就分几个就好了），这种说法应该是为了连续型随机变量，$p_i$ 是这些区间的**理论概率**，$n_i$ 是试验落在对应区间的个数。

 $K$ 的观测值如果过大，那么我们倾向于做出否定假设分布的判断。

#### 2.3.2 参数未知的分布检验

如果参数是未知的，那么我们就需要先利用极大似然估计出参数，如果需要估计的参数有 r 个，那么相应的，我们自由度需要减去 r 。

---



## 三、其他统计知识

### 3.1 点估计

#### 3.1.1 点估计与区间估计的区别

点估计法中的矩估计法建立的前提是“可以用样本矩代替总体矩”，极大似然法建立的前提是“可以用求导的结果代替总体特征”。但是这其实只是一个主观认识，所以我们又发明了**无篇**、**最小方差**，**一致**三个评价指标去评价我们参数估计是否合格。本质是**“先实践，再补救”**的思路

区间估计利用的建立在概率论体系的标准分布，通过给出能够接受的概率（比如大于0.95），获得一个参数的范围，本质是**“先预测，再挑选”**的方法。

#### 3.1.2 矩估计法

这里首先要区别一个之前已经强调过的概念，参数不是矩，尽管有的时候，分布的期望与某个参数相等或者是某个参数的函数，但是这并不意味着两者相等。

矩估计法的思路：

- 用带参的分布，构造出**带参的总体矩**
- 用试验获得样本构造出无参确定的样本矩
- 让总体矩等于对应的样本矩，获得方程组
- 解出方程组，就是解出了参数

#### 3.1.3 极大似然估计法

利用的对参数求导获得参数

极大似然法的思路：

- 构造

$$
L(\theta) = \amalg_{i = 1}^n f(x_i;\theta)
$$

- 对 $L(\theta)$ 或者 $\ln L(\theta)$ 求导，然后找到极大值点 $\hat{\theta}$ ，这组参数就是我们解出的参数