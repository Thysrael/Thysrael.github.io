<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>钟鼓楼</title>
  
  <subtitle>钟楼瘦，鼓楼胖</subtitle>
  <link href="https://thysrael.github.io/atom.xml" rel="self"/>
  
  <link href="https://thysrael.github.io/"/>
  <updated>2025-08-15T12:16:48.016Z</updated>
  <id>https://thysrael.github.io/</id>
  
  <author>
    <name>Thysrael</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>吃喝玩乐-流浪厦门</title>
    <link href="https://thysrael.github.io/posts/d3c9a793/"/>
    <id>https://thysrael.github.io/posts/d3c9a793/</id>
    <published>2025-06-13T01:55:10.000Z</published>
    <updated>2025-08-15T12:16:48.016Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>这么多人我不知道还算不算流浪，</p><p>可是从沙茶汤上刮起的风只掠过了我。</p><p>我急匆匆走过地图上标记的每一个浪漫角落，</p><p>自己却永远走不出地图。</p><p>我还记得凤凰花别在你耳朵上的样子。</p><p>所以现在你的波希米亚长裙去了哪里？</p></blockquote><h2 id="一、感受"><a href="#一、感受" class="headerlink" title="一、感受"></a>一、感受</h2><p>这次出游是实验室组织的团体活动，我有幸担任了旅游的组长。但是因为组长的缘故，在景点和美食的选择上并不能随心所欲，而是更要考虑大家的需求。不过这也并不是什么坏事情，如果由着我的性子，我一定会在宾馆躺三天。</p><p>厦门文旅给人的最直观印象就是“浪漫”。宣传里的十里长堤、海上列车、曾厝垵和鼓浪屿，是这座城市的浪漫名片。不过我倒没有明显感觉出很浪漫的地方，这里的浪漫似乎因为旅游开发的缘故，显得有些模式化。更感慨的是，沙坡尾，明明在小红书中被形容成“漫画感”，在我看来，十分萧条落寞：那些本应鲜艳的油漆，在离开了镜头后，显得斑驳和衰老。</p><p>但是那又如何呢？我相信它是浪漫的，不是因为那些景点，而是因为它在我的脑海里本来就是浪漫的。我相信那里每个姑娘都穿着各式各样的波西米亚长裙，海风会将裙摆轻轻吹起。凤凰花会像火红的瀑布一样，溢满整个巷子。</p><p>如果抛去浪漫这个元素，厦门是非常惊喜的，无论是历史文化还是自然景色，都非常好；当然吃得也非常好，除了姜母鸭！</p><hr><h2 id="二、地理"><a href="#二、地理" class="headerlink" title="二、地理"></a>二、地理</h2><p>厦门是福建省的一个城市，它直面大海，岛屿众多。</p><p><img src="/posts/d3c9a793/bba1cd11728b471089cf4434c8cec3fdfd032361.jpeg" alt="img"></p><p>而且向东远眺，就可以看到台湾省的金门岛。</p><p><img src="/posts/d3c9a793/730e0cf3d7ca7bcba1857ed7b5096b63f724a848.jpeg" alt="img"></p><p>厦门市是有思明岛和周围的半岛组成的，主要的景点都集中于思明岛：</p><p><img src="/posts/d3c9a793/d3f3f0de-2174-413e-9dcc-8619089db4f0.png" alt="d3f3f0de-2174-413e-9dcc-8619089db4f0"></p><p>更具体而言，思明岛上有 3 个景点群，集美学村有 1 个景点群：</p><p><img src="/posts/d3c9a793/c72fc5ed-e882-4e01-9911-1ddca03518e7.png" alt="c72fc5ed-e882-4e01-9911-1ddca03518e7"></p><p>鼓浪屿单独有一个景点地图（景点实在是太密集了）：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_154700_649.png" alt="微信图片_2025-06-14_154700_649"></p><p>厦门市内的共享单车和电动车并不是很多，地铁好像也不是太发达（当然可能也跟我没有深入探索有关系），我们多采用出租的形式，不过一个景点群里的景点，也可以采用步行的方式。</p><p>最后放一张厦门地图：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_145753_635.png" alt="微信图片_2025-06-14_145753_635"></p><hr><h2 id="三、景点"><a href="#三、景点" class="headerlink" title="三、景点"></a>三、景点</h2><h3 id="3-1-沙坡尾"><a href="#3-1-沙坡尾" class="headerlink" title="3.1 沙坡尾"></a>3.1 沙坡尾</h3><p>我们就住在了沙坡尾边儿上，所以到了以后的第一天我们就打算去沙坡尾看看。我非常期待这个地方，因为它在攻略里是长成这个样子的：</p><p><img src="/posts/d3c9a793/820_Chxky2PjuAeARinkAAco2Kvvsrg340.jpg" alt="img"></p><p>只可惜我们当天去的时候，攻略中的焦糖玛奇朵滤镜直接换成 BBC 阴间滤镜了：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_200725_520.png" alt="微信图片_2025-06-13_200725_520"></p><p>路上淅淅沥沥几家商户，卖的还都是景区套餐，我觉得就算是在模式化商业街里面，它也是排在南锣鼓巷后面的主儿。</p><p>我们去沙坡尾的时候会路过小区，这里的小区有一种“城中村”的感觉，与周星驰《功夫》里的猪笼城寨有点类似，但是要更加具有生活气息。</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_201113_459.png" alt="微信图片_2025-06-13_201113_459"></p><p>不过我真的理解不了他们为什么不整整齐齐的建楼房，平原人的强迫症神烦。</p><h3 id="3-2-鼓浪屿"><a href="#3-2-鼓浪屿" class="headerlink" title="3.2 鼓浪屿"></a>3.2 鼓浪屿</h3><p>鼓浪屿是思明岛旁的一个小岛，在鸦片战争后，各国相继在岛上设置领事馆，所以这是一个充满异域风情的小岛，也是厦门文旅最耀眼的名片。</p><p>从思明岛去鼓浪屿要坐船，船票有 35 的也有 80 的，似乎没有什么区别，早到一些可以上二楼，有座位，而且景色也更好：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_210709_087.png" alt="微信图片_2025-06-13_210709_087"></p><p>在船上可以看到鼓浪屿上立着的郑成功雕像，据说面向的方向就是台湾的方向：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_211044_458.png" alt="微信图片_2025-06-13_211044_458"></p><p>一进鼓浪屿就是网红打卡点 —— 最美转角，我其实很不理解这种打卡点存在的意义，没有逻辑啊：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_212047_025.png" alt="微信图片_2025-06-13_212047_025"></p><p>然后按照推荐路线我们应该向这个转角的左侧走去，而我们毅然决然地选择了右侧，主要原因是我觉得右侧有更多漂亮的穿裙子姑娘。我们的下一站是月光岩，这是鼓浪屿上的第二高峰，我们之所以去这里，也很简单，因为第一高峰日光岩要 50 块钱的门票，而我们并没有这个钱。在去月光岩的路上需要走这种山路阶梯：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_212414_096.png" alt="微信图片_2025-06-13_212414_096"></p><p>其实避开“规定路线”后，鼓浪屿的景色很美，热带植物层出不穷，民宿建筑和西式建筑有一个很好的融合，而且甚至这里还有一种烟火气和旅游气的融合（明明这两者是冲突的）：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_212619_412.png" alt="微信图片_2025-06-13_212619_412"></p><p>月光岩上的风景也很好，可以看到思明岛，只可惜月光岩在正中间，不如日光岩，可以看到金门岛。但是它不要钱，所以它就是最好的（除了笔架山很难找到入口外）：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_213032_905.png" alt="微信图片_2025-06-13_213032_905"></p><p>下山的路上开满了凤凰花，就像燃烧的瀑布一样：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_213300_040-1749821594496-23.png" alt="微信图片_2025-06-13_213300_040"></p><p>有些凤凰花落到了地上，就像瀑布溅出来的水洼：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_213352_209.png" alt="微信图片_2025-06-13_213352_209"></p><p>在下山路的尽头是第二转角，我没有感觉出它和第一转角的区别，也没有感觉出它和任意一个楼角的区别：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_213714_097.png" alt="微信图片_2025-06-13_213714_097"></p><p>如果往人流更多的地方去走，就会遇到一些经典商业街，感觉要比普通的商业街要更加“商业”一些：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_213810_387.png" alt="微信图片_2025-06-13_213810_387"></p><p>另一些商业街：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_213813_387.png" alt="微信图片_2025-06-13_213813_387"></p><p>这里的榕树都好大啊：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_214203_986.png" alt="微信图片_2025-06-13_214203_986"></p><p>沙滩也看过了，但是天气不怎么好，此外似乎沙子也没有那么细软（但是踩上去也很舒服了）：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_214553_039.png" alt="微信图片_2025-06-13_214553_039"></p><p>在沙滩上发现了一个水母，人生或许就跟这个一样易逝，或者说被海浪卷上岸后，离彻底蒸发干净还需要过去很久：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_214617_606.png" alt="微信图片_2025-06-13_214617_606"></p><p>我们还尝试了一下踩着礁石往海里面走去，哈哈哈哈我们太怂了：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_145344_974.png" alt="微信图片_2025-06-14_145344_974"></p><p>另外就是鼓浪屿上的小姐姐好多都穿着裙子啊。</p><h3 id="3-3-八市-amp-中山路"><a href="#3-3-八市-amp-中山路" class="headerlink" title="3.3 八市 &amp; 中山路"></a>3.3 八市 &amp; 中山路</h3><p>我们是离开鼓浪屿以后去的八市和中山路（两个地方离得挺近，可以步行）。因为我打错车的缘故，所以八市我没有进去，直接到了中山路。不过据去的同学说，八市确实只是一个菜市场，并不是一个商业街，所以可能买生食材的比较多，而饭店比较少。最后我们是在八市的街尾汇合的，可以看到这里还是没有商业街的那种浮华的：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_143511_415.png" alt="微信图片_2025-06-14_143511_415"></p><p>而中山路就是正经商业街的，街道两旁的油漆都很新：</p><p><img src="/posts/d3c9a793/微信图片_20250614140935.jpg" alt="微信图片_20250614140935"></p><p>这两侧的楼都被叫作骑楼，也就是第一层是街面，而第二层及以上都是完全盖住第一层街面的设计，这样的目的主要是为了避雨。也不知道是幸运还是不幸运，我们去中山路的时候大雨倾盆，我就在骑楼下来回穿梭，结结实实体验了一下这个建筑的妙用。</p><p><img src="/posts/d3c9a793/微信图片_20250614140950.jpg" alt="微信图片_20250614140950"></p><p>这里的商铺的招牌都还挺有改开时的年代感，可以看出厦门作为桥头堡的历史痕迹：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_143855_882.png" alt="微信图片_2025-06-14_143855_882"></p><h3 id="3-4-索道"><a href="#3-4-索道" class="headerlink" title="3.4 索道"></a>3.4 索道</h3><p>我在找攻略的时候就看上这个索道了，能够在索道上俯瞰厦门，感觉非常酷。因为我和我的朋友实在是太沉了，没法共用一个车厢，所以因祸得福获得了独立车厢：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_155001_508.png" alt="微信图片_2025-06-14_155001_508"></p><p>但是我是真没想到，它居然这么高，孩子恐高啊，而且我们去的那天，又是刮风，又是下雨的，那个车厢就晃晃悠，晃晃悠；雨点嘀嘀嗒，嘀嘀嗒，吓都把我吓死了：</p><p><img src="/posts/d3c9a793/微信图片_20250614150423.jpg" alt="微信图片_20250614150423"></p><p>不过上面的景色还是很好的，可以看到很多热带特色植物：</p><p><img src="/posts/d3c9a793/微信图片_20250614150323.jpg" alt="微信图片_20250614150323"></p><p>还可以看到一些在平原城市中难以看到的景色：</p><p><img src="/posts/d3c9a793/微信图片_20250614150336.jpg" alt="微信图片_20250614150336"></p><p>还可以远眺双子塔（上塔居然要 250 多块钱，好贵啊）：</p><p><img src="/posts/d3c9a793/微信图片_20250614150353.jpg" alt="微信图片_20250614150353"></p><h3 id="3-5-集美学村"><a href="#3-5-集美学村" class="headerlink" title="3.5 集美学村"></a>3.5 集美学村</h3><p>集美学村在思明岛外，要到集美学村可以做网红的“海上列车” —— 地铁一号线。而实际效果，就是普通的轻轨，并没有乘风破浪的感觉，因为从窗户向外望去，大部分的都是其他轨道，能看到的海面，也并不是很壮阔：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_161539_159.png" alt="微信图片_2025-06-14_161539_159"></p><p>下了地铁就是龙舟池，临近端午，有人在练习龙舟：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_161857_430.png" alt="微信图片_2025-06-14_161857_430"></p><p>再往前走就是集美中学，是爱国华侨陈嘉庚先生建立的学校，建筑非常有特点：</p><p><img src="/posts/d3c9a793/微信图片_20250614160601.jpg" alt="微信图片_20250614160601"></p><p>不过一想到上这个学校的人居然还要高考，我就想笑：</p><p><img src="/posts/d3c9a793/微信图片_20250614160617.jpg" alt="微信图片_20250614160617"></p><p>在集美中学后就是陈嘉庚先生为爱国华侨修建的归来堂：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_162246_830.png" alt="微信图片_2025-06-14_162246_830"></p><p>离开了归来堂就是陈嘉庚先生故居：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_162250_107.png" alt="微信图片_2025-06-14_162250_107"></p><p>故居里有一个沙发，据说是为了方便陈嘉庚先生办公，加装了桌板：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_162253_000.png" alt="微信图片_2025-06-14_162253_000"></p><p>最后我们还去参观了大社，不知道为什么，总感觉有种民俗朋克的感觉：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_165114_053.png" alt="微信图片_2025-06-14_165114_053"></p><h3 id="3-6-十里长堤"><a href="#3-6-十里长堤" class="headerlink" title="3.6 十里长堤"></a>3.6 十里长堤</h3><p>我之前一直以为十里长堤是一个“自古以来”存在的景点，没有想到居然是 2011 年左右才炒起来的景点，所以直接看上去，居然有点像石家庄音乐节：</p><p><img src="/posts/d3c9a793/微信图片_20250614165122.jpg" alt="微信图片_20250614165122"></p><p>十里长堤本身似乎也平平无奇：</p><p><img src="/posts/d3c9a793/微信图片_20250614165039.jpg" alt="微信图片_20250614165039"></p><p>海上列车如果从岸边的角度去看，似乎好看了一些？</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_165459_505.png" alt="微信图片_2025-06-14_165459_505"></p><p>然而就在我们离开十里长堤，就成功错过了最美晚霞，我是真急了：</p><p><img src="/posts/d3c9a793/微信图片_20250614165130.jpg" alt="微信图片_20250614165130"></p><p>在飞机上看似乎也不错：</p><p><img src="/posts/d3c9a793/微信图片_20250614165143.jpg" alt="微信图片_20250614165143"></p><hr><h2 id="四、美食"><a href="#四、美食" class="headerlink" title="四、美食"></a>四、美食</h2><h3 id="4-1-鹦哥楼"><a href="#4-1-鹦哥楼" class="headerlink" title="4.1 鹦哥楼"></a>4.1 鹦哥楼</h3><p>鹦哥楼是我在沙坡尾找到的一个非常经济实惠的饭店，本身是一个历史建筑物，因为顶楼上有一个鹦鹉雕塑，所以被叫作鹦哥楼。</p><p>但是遗憾的是，里面的饭菜真的很难吃。能吃得下的都是一些哪里都有的菜，比如说鲍汁山菌、虾球、茶香脆骨。但是一旦涉及了一些本地特色，似乎都带上了一种“寡淡诡异”的感觉：</p><ul><li>蒜香手工豆腐：豆腐有些发酵带来的酸口，但是我觉得为了一点特殊的滋味，牺牲了豆腐本身的口感（软的近似液体了）不值当。</li><li>黑蒜文蛤炖中排：非常清单，只有肉本身的腥味，而黑蒜有让食物带上了一种腻糊糊的感觉。</li><li>五花肉夹馍：五花肉非常肥，确实一咬就可以香得流油儿，但是有些过于腻，甚至都腻得发甜了。</li><li>酸菜筒骨：非常腥，而且酸菜非常难吃，我没有吃过这么难吃的酸菜。</li><li>醋肉：本来是冲着这个名字去点的，以为是那种有清爽醋香，能开开胃，但是实际上更像是酵酸味儿，而且肉汁也并不紧实。</li><li>沙茶烩：这个汤里面的每一个东西，还没有清汤锅里煮出来的咸。</li></ul><p>当然这几个难吃就难吃了，好歹还是特色的，有两样菜非常气人。一个是姜母鸭，这个是厦门的名菜，但是实际上非常难吃，鸭子很大，所以肉质很柴，而且并不入味，我感觉我像是在吃一只白水煮鸭子，而且这只鸭子本身也不嫩，肉是肉，油是油的。</p><p>另外一个就是底下这碗红菇猪肉汤了，卖整整 36 块大洋，跟涮锅水没有任何区别，红菇没有常见菌类的香气，猪肉真的就是白水煮猪肉。</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_183331_809.png" alt="微信图片_2025-06-13_183331_809"></p><p>结合后面几次吃到的饭，我觉得可能也不止是这家店的问题，我觉得可能整个厦门在对于“大肉”的处理上都没有办法契合我一个北方人的口味，在来之前，我实在是想象不到有人可以把排骨、五花肉、里脊这种怎么做都好吃的肉做得这么诡异，也想象不到居然一整只鸭子能做成没有一个地方是好吃的，鸭脖子、鸭腿、鸭内脏、鸭掌、鸭胸这些哪哪都不一样的肉是怎么给做成一样的难吃的啊？不过反过来说，只要不涉及大肉，福建的菜还都挺好吃的。</p><p>不过这里的服务很好，而且感觉很有闽南特色。</p><h3 id="4-2-鲨鱼丸"><a href="#4-2-鲨鱼丸" class="headerlink" title="4.2 鲨鱼丸"></a>4.2 鲨鱼丸</h3><p>我们在沙坡尾附近的一家店吃吃到的，按照店家的说法是纯手动制作的鲨鱼丸，我一个北方人对于鱼丸真的没有抵抗力。而且真的很好吃。鲨鱼丸的肉要比普通的鱼丸更加紧实弹牙，而且肉的颗粒感会更加明显。</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_193806_314.png" alt="微信图片_2025-06-13_193806_314"></p><p>而且里面还是有馅儿的，甚至馅儿的口感也很有层次，而不是那种超市的预制撒尿牛丸里的软趴趴的馅料可以相比的：</p><p><img src="/posts/d3c9a793/微信图片_20250613192410.jpg" alt="微信图片_20250613192410"></p><p>除了丸子本身好吃以外，这个看似平平无奇的汤也非常好喝，鲜到它能直接顺着嗓子眼儿滑下去，舌头怎么搂都搂不住。</p><p>唯一的缺点就是稍微有点贵，我忘记是 25 还是 30 了。</p><h3 id="4-3-火参果"><a href="#4-3-火参果" class="headerlink" title="4.3 火参果"></a>4.3 火参果</h3><p>在鼓浪屿上看到的，一个 10 块钱就买了，老板娘还特意帮我挑了一个红的：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_211116_385.png" alt="微信图片_2025-06-13_211116_385"></p><p>味道也没有很独特，类似于百香果，没有特别酸，但是也没有特别甜，而且汁水也不是很多（嘬吸管累死我了）：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-13_211736_888.png" alt="微信图片_2025-06-13_211736_888"></p><h3 id="4-4-上屿水产"><a href="#4-4-上屿水产" class="headerlink" title="4.4 上屿水产"></a>4.4 上屿水产</h3><p>上屿水产是我们在鼓浪屿上找的一家海鲜店，经济实惠（均 150）的同时服务也很好。一扫我对于闽南菜很难吃的担心。</p><p>蛰头没有什么稀奇的，我看重的是这个是用永春醋来泡的。永春醋是闽南的特色醋，所以我很想尝一尝是什么味道。颜色方面是比普通的醋要棕一些，口感上要更加醇厚，而味道上不怎么香，也不怎么甜。</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_111110_858.png" alt="微信图片_2025-06-14_111110_858"></p><p>豉油蒸乌耳鳗是这里面最好吃的一道菜，这是刚上桌的样子，等过了一轮再转回来的时候，连一瓣鱼肉都没有了。我觉得相比于日料店里的鳗鱼，它没有过于紧实；而相比于黄花鱼这种一筷子刀下去，肉彻底散了的鱼，有可以将汤汁紧紧锁在鱼肉里面。</p><p>再加上这里的鱼皮也没有像日料中的鳗鱼一样和鱼肉泾渭分明，以至于单独吃过腻，合在一起吃会在口腔里解体。</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_111354_675.png" alt="微信图片_2025-06-14_111354_675"></p><p>皮皮虾也很常见，反正就只是不难吃，没有那种非常应时的皮皮虾的甜美。</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_112217_912.png" alt="微信图片_2025-06-14_112217_912"></p><p>五香卷是闽南的特色美食，它是用油豆皮裹上肉、荸荠、洋葱，然后过油炸。就这个做法光听起来，就知道肯定难吃不了！</p><p>事实也确实如此，这个非常好吃。但是吃到后面，我总感觉有一种在吃“羊肠衣”而不是“油豆皮”的感觉，应该是因为里面掺了过量的肥肉，导致吃到最后有些腻人和腥气了（甚至有种吃羊肉串的感觉），不过也没有那么夸张，吃起来还是很好吃的。我在后面几次吃饭的时候，也点了这个菜。</p><p>右边的那个酱并不是普通的甜辣酱，而是这里特色的一种甜辣酱，相比于普通的甜辣酱，要更加的酸，而且有酵香（为什么这里什么东西都有酵香）。辣度也会弱一些，本来我是很喜欢吃不怎么辣的甜辣酱的，但是这个酱我是真的吃不惯，吃多了就有一种在干嚼呕吐物的感觉。</p><p><img src="/posts/d3c9a793/微信图片_20250614110924.jpg" alt="微信图片_20250614110924"></p><p>同安封肉，是蒸肉的一种，我觉得并不好吃，一个原因是因为这个五花肉肥的太多，瘦的太少。另一个原因是这个肥肉的口感非常奇怪，没有一点油脂的香气，更像是冬瓜和果粒爽里面的果粒的混合体，没有肉味也没有肉的口感。</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_113518_582.png" alt="微信图片_2025-06-14_113518_582"></p><p>小青龙，非常普通，不过我也没吃过啥好的龙虾，反正我觉得味道和普通的虾差不多。</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_114005_655.png" alt="微信图片_2025-06-14_114005_655"></p><p>干煎膏蟹，超级有特色且好吃的一道菜。我们平时吃的螃蟹都是蒸的，所以肉质会更加润滑松弛一些。而这道菜恰恰相反，采用干煎的手法，让蟹肉和蟹黄收缩到一起，提供新奇口感的同时紧紧锁住了蟹香。</p><p>而且不知道是怎么处理的，这个蟹的蟹肉吃完后口腔内会有一种干辣的涩感，让人食欲大开。</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_114247_985.png" alt="微信图片_2025-06-14_114247_985"></p><p>最后还能说什么呢？干杯！</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_114757_707.png" alt="微信图片_2025-06-14_114757_707"></p><h3 id="4-5-厚生林"><a href="#4-5-厚生林" class="headerlink" title="4.5 厚生林"></a>4.5 厚生林</h3><p>上屿水产一出来就是厚生林，是一个买类似于冰镇甜粥的饮品店。</p><p>我最喜欢吃里面的蜜藕了，枣红色的蜜藕，吃起来虽然不脆，但是紧实绵密（我似乎用了好多次“紧实”这个词了），咬下去以后不会被腌渍过的藕心儿腻住，反而是蜜味儿随着藕的纤维组织一点点在口腔里润开，加上藕是拿冰镇过的，所以完全不粘牙，实在是难得。</p><p><img src="/posts/d3c9a793/微信图片_20250614140808.jpg" alt="微信图片_20250614140808"></p><p>其他的配料，比如说银耳、莲子、百合，也非常好吃，这些配料和北方的八宝粥里面的类似，但是八宝粥是热的，而且是用大米来做基底，而这里是用糖水做基底，然后再冰镇。所以八宝粥喝起来黏黏糊糊，多种配料都混合交织在了一起，而这里的甜粥，则是用冰隔离了不同配料的口感，甚至锁住了不同配料的口感。</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_142348_079.png" alt="微信图片_2025-06-14_142348_079"></p><h3 id="4-6-夏氏沙茶面"><a href="#4-6-夏氏沙茶面" class="headerlink" title="4.6 夏氏沙茶面"></a>4.6 夏氏沙茶面</h3><p>这是我们在中山路上找到的一家店，完全没有预谋，看店门口说是上过电视，所以就进来尝一尝。</p><p>这家的老板真的非常 nice，我们因为经费的原因，六个人只点了两碗沙茶面，结果人家老板愣是拿了六个碗乘这两碗沙茶面，每碗都跟下面这碗一样满满当当的卤和面。</p><p><img src="/posts/d3c9a793/微信图片_20250614140906.jpg" alt="微信图片_20250614140906"></p><p>这家做得沙茶面是真的非常好吃，沙茶因为里面含有虾米的缘故，所有很喇嗓子而不够醇厚，而麻酱呢，虽然醇厚但是糊嗓子。这里调的卤子，不但没有传统沙茶酱的尖涩感，而且还有一种不同于麻酱的厚重，也就是并不黏糊的同时，还有一些重量感，温吞的整体口感里包裹着一些海鲜的刺激。</p><p>蛤仔煎，也是特色没事，应该是把蛤蜊、韭菜和鸡蛋摊在一起。蛤蜊的口感被韭菜和鸡蛋中和了很多，没有很明显的腥味和涩味。但是相应的，蛤蜊的咸鲜味也弱了一些，只剩下蛤蜊的口感被完整保留下来，甚至和韭菜鸡蛋形成了新的范式。不过他们又在上面洒上厦门特有甜辣酱了（甚至有一整桶甜辣酱摆在桌子上）。</p><p><img src="/posts/d3c9a793/微信图片_20250614140843.jpg" alt="微信图片_20250614140843"></p><p>蟹黄汤包就是烂大街的那种，在上海呆久了，我已经对这种东西去魅了：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_160956_905.png" alt="微信图片_2025-06-14_160956_905"></p><p>店家还赠送了五香卷，味道和在上屿水产吃到的类似：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_161311_036.png" alt="微信图片_2025-06-14_161311_036"></p><p>吃完以后我又在街边买了四果汤，别看名字取得很好听，但是完全不如冰粥好喝，都是预制品和添加剂。</p><p>不过我查了查四果汤指的是“红豆、绿豆、莲子、薏仁”，我当时喝到的并没有这些东西，可能并不是四果汤不好喝，而是这家店偷工减料坑人。</p><p><img src="/posts/d3c9a793/微信图片_20250614140922.jpg" alt="微信图片_20250614140922"></p><h3 id="4-7-此食此茶"><a href="#4-7-此食此茶" class="headerlink" title="4.7 此食此茶"></a>4.7 此食此茶</h3><p>这趟旅行最好的一家店，不但经济实惠，而且吃得最偏向于北方口味，而且不失闽南特色。</p><p><img src="/posts/d3c9a793/微信图片_20250614162747.jpg" alt="微信图片_20250614162747"></p><p>最关键是环境非常好，可以看到那种在宋词里面才会出现的廊庭：</p><p><img src="/posts/d3c9a793/微信图片_20250614162758.jpg" alt="微信图片_20250614162758"></p><p>二楼还有天台，虽然只能看见对面的幼儿园：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_163345_552.png" alt="微信图片_2025-06-14_163345_552"></p><p>鱼豆腐非常弹牙，而且有一种炸物一般没有的新鲜（怎么又有甜辣酱呀）：</p><p><img src="/posts/d3c9a793/微信图片_20250614162820.jpg" alt="微信图片_20250614162820"></p><p>羊肚菌酿虾滑是我吃过最好吃的羊肚菌，没有菌干那种突出的土腥味儿：</p><p><img src="/posts/d3c9a793/微信图片_2025-06-14_163811_624.png" alt="微信图片_2025-06-14_163811_624"></p><p>厦门特色咸饭，反正我觉得比上海菜泡饭好吃：</p><p><img src="/posts/d3c9a793/微信图片_20250614162945.jpg" alt="微信图片_20250614162945"></p><p>其他的饭也都很好吃，就来不及拍照了。不过我又不死心点了姜母鸭，发现即使在这个非常好吃的饭店里，姜母鸭依然很难吃。鸭子外面有姜的辛辣，而鸭肉依然不入味儿。我在鼓浪屿上看到了姜母鸭的做法，说的是用老姜（也就是“姜母”）炖整只鸭子，整只鸭子可是一刀不剁啊，怪不得外面辣得要死，里面不入味儿呢。</p><hr><h2 id="五、歌单"><a href="#五、歌单" class="headerlink" title="五、歌单"></a>五、歌单</h2><ul><li>Summer (久石让)</li><li>把握时间，掌握方向（林生祥）</li><li><strong>望春风</strong>（刘惜君）</li><li>我们的时光（赵雷）</li><li><strong>亚洲挚爱</strong>（红节奏）</li><li>城市的浪漫运作（甜约翰）</li><li>Grapejuice（Harry Styles）</li><li>面会菜（林生祥）</li><li>かざぐるま（山崎ハコ）</li></ul>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;这么多人我不知道还算不算流浪，&lt;/p&gt;
&lt;p&gt;可是从沙茶汤上刮起的风只掠过了我。&lt;/p&gt;
&lt;p&gt;我急匆匆走过地图上标记的每一个浪漫角落，&lt;/p&gt;
&lt;p&gt;自己却永远走不出地图。&lt;/p&gt;
&lt;p&gt;我还记得凤凰花别在你耳朵上的样子。&lt;/p&gt;
&lt;p&gt;所以现在你的波希米亚长裙去了哪里？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;一、感受&quot;&gt;&lt;a href=&quot;#一、感受&quot; class=&quot;headerlink&quot; title=&quot;一、感受&quot;&gt;&lt;/a&gt;一、感受&lt;/h2&gt;&lt;p&gt;这次出游是实验室组织的团体活动，我有幸担任了旅游的组长。但是因为组长的缘故，在景点和美食的选择上并不能随心所欲，而是更要考虑大家的需求。不过这也并不是什么坏事情，如果由着我的性子，我一定会在宾馆躺三天。&lt;/p&gt;
&lt;p&gt;厦门文旅给人的最直观印象就是“浪漫”。宣传里的十里长堤、海上列车、曾厝垵和鼓浪屿，是这座城市的浪漫名片。不过我倒没有明显感觉出很浪漫的地方，这里的浪漫似乎因为旅游开发的缘故，显得有些模式化。更感慨的是，沙坡尾，明明在小红书中被形容成“漫画感”，在我看来，十分萧条落寞：那些本应鲜艳的油漆，在离开了镜头后，显得斑驳和衰老。&lt;/p&gt;
&lt;p&gt;但是那又如何呢？我相信它是浪漫的，不是因为那些景点，而是因为它在我的脑海里本来就是浪漫的。我相信那里每个姑娘都穿着各式各样的波西米亚长裙，海风会将裙摆轻轻吹起。凤凰花会像火红的瀑布一样，溢满整个巷子。&lt;/p&gt;</summary>
    
    
    
    <category term="吃喝玩乐" scheme="https://thysrael.github.io/categories/%E5%90%83%E5%96%9D%E7%8E%A9%E4%B9%90/"/>
    
    
    <category term="吃喝玩乐" scheme="https://thysrael.github.io/tags/%E5%90%83%E5%96%9D%E7%8E%A9%E4%B9%90/"/>
    
    <category term="流浪厦门" scheme="https://thysrael.github.io/tags/%E6%B5%81%E6%B5%AA%E5%8E%A6%E9%97%A8/"/>
    
    <category term="S10课上" scheme="https://thysrael.github.io/tags/S10%E8%AF%BE%E4%B8%8A/"/>
    
  </entry>
  
  <entry>
    <title>海边拾贝-FlashInfer</title>
    <link href="https://thysrael.github.io/posts/7df595f9/"/>
    <id>https://thysrael.github.io/posts/7df595f9/</id>
    <published>2025-05-06T13:15:38.000Z</published>
    <updated>2025-08-15T12:16:48.895Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Attention Engine 可以被理解成<strong>“Attetion 算子库 + Attention 运行时</strong>”。有以下设计：</p><ul><li>可拆分的 Attention 算子：提高了 GPU 内存带宽利用率</li><li>新的 KV Cache 管理抽象 CBSR：兼具 PagedAttention 和 RadixAttention 的优点，更 general</li><li>宏观上动态、微观上静态的调度运行时：动态的同时不损害静态抽象和收益</li><li>可定制的 Attention 算子框架、JIT：一些工程特性</li></ul><p>FlashInfer 这篇工作在 2023 年就提出了，据作者所言，那个时候只有 FlashAttention1，还没有 FA2&amp;3，FlashDecode 等工作，但是这些工作论文发得更早。</p></blockquote><h2 id="一、Background"><a href="#一、Background" class="headerlink" title="一、Background"></a>一、Background</h2><h3 id="FlashAttention"><a href="#FlashAttention" class="headerlink" title="FlashAttention"></a>FlashAttention</h3><p>传统的 Attention 运算需要扫描 3 遍 GPU Memory 中的 Attention Logits 矩阵（len, len），计算密度低。</p><p>FlashAttention 提出了 1-pass 的 attention 算法，提高了计算密度，缓解了 GPU Memory 到 GPU Cache 的 IO 瓶颈：</p><p><img src="/posts/7df595f9/1746537571691-4.gif" alt="img"></p><h3 id="FlashAttention1-不适应-Decode-场景"><a href="#FlashAttention1-不适应-Decode-场景" class="headerlink" title="FlashAttention1 不适应 Decode 场景"></a>FlashAttention1 不适应 Decode 场景</h3><p>FlashAttention 是为了训练开发的，Queries 的长度往往很长（也就是 Queries 彩色方块的高度很高），这样可以充分利用 GPU 上的计算资源。</p><p>而在 decode 阶段，采用自回归生成，每次的 Queries 的长度就为 1（也就是 Queries 彩色方块高度只有 1），那么计算资源就不会得到充分利用（按照 FlashDecode 的说法，是不到 1%）。</p><p>更加形式化地去看，在 FlashAttention 中，设置 <script type="math/tex">l_q</script>是 Queries 的长度，<script type="math/tex">l_k</script>是 K 的长度，那么一次 Attention 计算的访存开销是 <script type="math/tex">O(l_q + l_k)</script>，计算开销是 <script type="math/tex">O(l_q l_k )</script>，则计算密度是：</p><script type="math/tex; mode=display">O(\frac{l_q l_k}{l_q + l_k}) = O(\frac{1}{\frac{1}{l_q} + \frac{1}{l_k}} )</script><p>如果考虑 <script type="math/tex">l_{k}</script>是一个很大的值（长文本或者推理模型都会导致 <script type="math/tex">l_k</script> 很大），那么计算密度约等于 <script type="math/tex">O(l_q)</script> 。当 <script type="math/tex">l_q = 1</script> 时就会导致计算资源利用不足。</p><h3 id="Attention-的输入是动态变化的"><a href="#Attention-的输入是动态变化的" class="headerlink" title="Attention 的输入是动态变化的"></a>Attention 的输入是动态变化的</h3><p>而实际情况会更加复杂，query 的长度是会动态变化的，从应用场景区分，有 3 种：</p><p><img src="/posts/7df595f9/1746537571691-1.png" alt="img"></p><p>放到 roofline 上来看</p><p><img src="/posts/7df595f9/1746537571691-2.png" alt="img"></p><p>动态变化的 Queries 长度就对 Attention 的动态性提出了一定的要求。</p><p>此外优化长文本有一种经典的技术就是 KV Cache 稀疏，也就是 KV Cache 也会存在变化（不止是单调递增），如 NSA 就包含三种稀疏特性：</p><p><img src="/posts/7df595f9/1746537571691-3.png" alt="img"></p><p>Attention 算子库既要利用特化的优势，又要有足够好的定制性。</p><hr><h2 id="二、Design"><a href="#二、Design" class="headerlink" title="二、Design"></a>二、Design</h2><h3 id="2-1-Split-K"><a href="#2-1-Split-K" class="headerlink" title="2.1 Split-K"></a>2.1 Split-K</h3><p>原版的 FlashAttention 需要利用前缀和不断缩放校正（scale）局部结果，但是“前缀和”就意味着“顺序遍历”，而当 Queries 的长度较小时，就容易导致利用率不高。</p><p>通过调整算法，我们可以实现并行计算不同的 KV Cache Chunk：</p><p><img src="/posts/7df595f9/1746537641901-13.gif" alt="img"></p><p>所以为了达到这种 merge 的效果，我们需要记录每个 block 的一些运算结果，这些结果在文中被称为 Attention State。</p><p>每个 block <script type="math/tex">\mathcal{I}</script> 需要记录两种 State，分别是 attention scale：</p><p><img src="/posts/7df595f9/1746537641901-14.png" alt="img"></p><p>和 attention output：</p><p><img src="/posts/7df595f9/1746537641901-15.png" alt="img"></p><p>有了这两个东西以后，我们就可以将 block <script type="math/tex">\mathcal{I}</script> 和 block <script type="math/tex">\mathcal{J}</script> 融合到一起了：</p><p><img src="/posts/7df595f9/1746537641902-16.png" alt="img"></p><p>Split-K 算法改善了 FA1 在 Decode 场景下计算资源利用率不足的问题。</p><p>Split-K 策略也是 FlashDecode 的核心 Idea，对此 FI 的作者叶子豪解释道：</p><blockquote><p>其实主要原因是我们跟 FA2 和 FlashDecoding 的开发几乎都是同期进行的，在 FlashAttention2 发布之前我们已经独立探索过了 FA2 中大部分的优化。而 FlashDecoding 我们在去年 8 月就已经有了较完整的实现和评测，不过我对 LLM 这个领域的内卷程度稍有低估没有及时推广，导致被抢发出来。抛开这些虚名而言，LLM Serving 还有很多工程上的问题需要解决，同志仍需努力。</p></blockquote><h3 id="2-2-Composable-Attention"><a href="#2-2-Composable-Attention" class="headerlink" title="2.2 Composable Attention"></a>2.2 Composable Attention</h3><p>在有了 Split-K 算法之后，我们就有一个可拆分、组合的 Attention 算子。也就是说，Attention 算子所需要的 Q，KV 都可以被拆分成 Chunk，然后分步或者并行计算，只要最后规约在一起就好了。这给了设计者极大的灵活性：</p><p>比如说我们可以自由组织各个计算步骤，将不同的任务分配给不同的 threadblock：</p><p><img src="/posts/7df595f9/1746537641902-17.png" alt="img"></p><p>也可以将计算的中间结果保存下来在多个 Request 之间共享。</p><h3 id="2-3-Block-Compressed-Sparse-Row"><a href="#2-3-Block-Compressed-Sparse-Row" class="headerlink" title="2.3 Block Compressed Sparse Row"></a>2.3 Block Compressed Sparse Row</h3><p>BCSR 是 FI 管理 KV Cache 的数据格式，更本质的说，FI 在<strong>用一个**</strong>稀疏矩阵<strong><strong>来模拟</strong></strong>页表**对 KV Cache 进行管理。</p><p>我们先用 OS 上的物理页面管理举例，我们有 2 个 Proc，2 个 Physical Page。其中 Proc0 只有 Page1，Proc1 有 Page0 和 Page1，那么我们就可以用一个 bool 矩阵表示这种关系：</p><p><img src="/posts/7df595f9/1746537641902-18.png" alt="img"></p><p>其中虚线的部分组成了一个 block，说明 Page1 是被 Proc0 和 Proc1 共享的。</p><p>然后我们迁移到 PI 上，将 Proc 换成 Query Chunk，将 Page 换成 KV Cache Chunk，有：</p><p><img src="/posts/7df595f9/1746537641902-19.png" alt="img"></p><p>直接用论文中的图来看：</p><p><img src="/posts/7df595f9/1746537641902-20.png" alt="img"></p><p>上图有一些省略的是，没必要用 bool 矩阵，而是可以用张量矩阵，矩阵中的每个元素都是一个形状为 <code>(layer, head, dim)</code> 的张量。</p><p>这种稀疏矩阵的表示方法，可以模拟出“内存分页”和“共享内存”的语义，这分别对应 PageAttention 和 RadixAttention 的设计。</p><p>使用稀疏矩阵这种数据结构，可以最大限度的发现里面“成块”的张量：</p><p><img src="/posts/7df595f9/1746537641902-21.png" alt="img"></p><p>这种 block 的矩阵，说明了其中的 KV Cache Chunk 会被 share，或者 Q Chunk 会被 Share，也就是会被经常使用。那么就应该把这种 KV Cache 或者 Q 放到高层次存储（寄存器或者 cache），而那些不被 share 的，放到低层次存储中。如下所示：</p><p><img src="/posts/7df595f9/1746537641902-22.png" alt="img"></p><p>此外稀疏矩阵形式，也可以很简单的描述 KV Cache 稀疏策略（没有比矩阵更加直白的描述方式了）。</p><h3 id="2-4-Dynamic-Schedule"><a href="#2-4-Dynamic-Schedule" class="headerlink" title="2.4 Dynamic Schedule"></a>2.4 Dynamic Schedule</h3><p>PI 调度的单位是 Attention 的小 block，调度算法的输入是一个 batch 内 QKV 的长度信息和当前硬件的架构信息（比如 TensorCore 的尺寸）。</p><p>调度的目标是 SM 的负载均衡，因为 Attention 可被拆分，所以调度算法设计并不难，如下所示：</p><p><img src="/posts/7df595f9/1746537641902-23.png" alt="img"></p><p>按照论文的说法，PI 采用的是一种“确定性调度”，这更有利于 LLM Serving，而且还可以发挥 CUDA Graph 的优势。</p><p>但是似乎这样就和动态调度有些违背，这里的动态调度指的是宏观上可以根据一个 batch 内的不同信息指定静态调度方针。</p><h3 id="2-5-Other"><a href="#2-5-Other" class="headerlink" title="2.5 Other"></a>2.5 Other</h3><ul><li>JIT：生成 CUDA 代码而不是 Triton 代码，一步到位</li><li>硬件架构：根据 GPU 架构选择 <code>LDGSTS</code> 还是 <code>TMA</code> ，使用 TensorCore 还是 CUDACore，Chunk Size</li><li>一系列 custom api，用于自定义 Attention 机制（FI 更像是一个 Attention 框架）。</li><li>融合 ROPE</li></ul><hr><h2 id="三、Eval"><a href="#三、Eval" class="headerlink" title="三、Eval"></a>三、Eval</h2><h3 id="3-1-端到端推理"><a href="#3-1-端到端推理" class="headerlink" title="3.1 端到端推理"></a>3.1 端到端推理</h3><p>使用 SGLang(FI) 与 SGLang(Triton) 和 TRTLLM 对比。</p><p>相比于 SGLang(Triton)，FI 的 FA 使用、JIT、动态调度使得其有良好的表现。</p><p>TRTLLM 作为 NVIDIA 的 Oracle，FI 有近似的表现。</p><p><img src="/posts/7df595f9/1746537641902-24.png" alt="img"></p><h3 id="3-2-Kernel-测试"><a href="#3-2-Kernel-测试" class="headerlink" title="3.2 Kernel 测试"></a>3.2 Kernel 测试</h3><p>与 FA2&amp;3 进行对比，主要测试的是针对 Query 的动态特性，能不能有及时的反应：</p><p><img src="/posts/7df595f9/1746537641902-25.png" alt="img"></p><p>可以看到当 Query 具有动态性的时候，FI 更胜一筹，这说明 FI 的 runtime 更强。</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Attention Engine 可以被理解成&lt;strong&gt;“Attetion 算子库 + Attention 运行时&lt;/strong&gt;”。有以下设计：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可拆分的 Attention 算子：提高了 GPU 内存带宽利用率&lt;/li&gt;
&lt;li&gt;新的 KV Cache 管理抽象 CBSR：兼具 PagedAttention 和 RadixAttention 的优点，更 general&lt;/li&gt;
&lt;li&gt;宏观上动态、微观上静态的调度运行时：动态的同时不损害静态抽象和收益&lt;/li&gt;
&lt;li&gt;可定制的 Attention 算子框架、JIT：一些工程特性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;FlashInfer 这篇工作在 2023 年就提出了，据作者所言，那个时候只有 FlashAttention1，还没有 FA2&amp;amp;3，FlashDecode 等工作，但是这些工作论文发得更早。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;一、Background&quot;&gt;&lt;a href=&quot;#一、Background&quot; class=&quot;headerlink&quot; title=&quot;一、Background&quot;&gt;&lt;/a&gt;一、Background&lt;/h2&gt;&lt;h3 id=&quot;FlashAttention&quot;&gt;&lt;a href=&quot;#FlashAttention&quot; class=&quot;headerlink&quot; title=&quot;FlashAttention&quot;&gt;&lt;/a&gt;FlashAttention&lt;/h3&gt;&lt;p&gt;传统的 Attention 运算需要扫描 3 遍 GPU Memory 中的 Attention Logits 矩阵（len, len），计算密度低。&lt;/p&gt;
&lt;p&gt;FlashAttention 提出了 1-pass 的 attention 算法，提高了计算密度，缓解了 GPU Memory 到 GPU Cache 的 IO 瓶颈：&lt;/p&gt;</summary>
    
    
    
    <category term="海边拾贝" scheme="https://thysrael.github.io/categories/%E6%B5%B7%E8%BE%B9%E6%8B%BE%E8%B4%9D/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="S10课上" scheme="https://thysrael.github.io/tags/S10%E8%AF%BE%E4%B8%8A/"/>
    
    <category term="海边拾贝" scheme="https://thysrael.github.io/tags/%E6%B5%B7%E8%BE%B9%E6%8B%BE%E8%B4%9D/"/>
    
  </entry>
  
  <entry>
    <title>吃喝玩乐-默契</title>
    <link href="https://thysrael.github.io/posts/47f13c89/"/>
    <id>https://thysrael.github.io/posts/47f13c89/</id>
    <published>2025-05-06T12:15:45.000Z</published>
    <updated>2025-08-15T12:16:48.672Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、Kuromi-amp-Melody"><a href="#一、Kuromi-amp-Melody" class="headerlink" title="一、Kuromi &amp; Melody"></a>一、Kuromi &amp; Melody</h2><p>Kuromi 是 AJ 送我的第一个礼物，好像是在五道口地下一层买的，当时我们好像还没有正式确立关系，在回去之前，她走进商店买了 Kuromi，然后挂在了我书包的后面。后面很多的日子里我背上书包，都感觉似乎有一只手在牵着我。</p><p>Melody 是后来我送给 AJ 的，琢磨着可以凑一对。</p><p>嗷对了，AJ 还不相信我能把挂着玩偶的链子解开后再挂到书包上去。</p><p><img src="/posts/47f13c89/2024-03-16_22-14-46_Kuromi&amp;Melody.jpg" alt="2024-03-16_22-14-46_Kuromi&amp;Melody" style="zoom: 50%;"></p><p>我电脑充电器上也有 Kuromi &amp; Melody 的贴纸，也是 AJ 贴上去的。</p><h2 id="二、200-Days"><a href="#二、200-Days" class="headerlink" title="二、200 Days"></a>二、200 Days</h2><p>这是保存在 AJ 手机的一个恋爱计时软件，不过这似乎是我唯一一次见到它。好像 100day 的时候我俩都忘了啥时候开始的了。</p><p>后来好像 300day 的时候关系就有些恶化了，好像就没有再一起过过了。</p><p><img src="/posts/47f13c89/2024-03-16_22-11-16_200day.jpg" alt="2024-03-16_22-11-16_200day" style="zoom:33%;"></p><p>我倒是在 org-mode 中设置了一个 org-habit 来提醒，经常在某些时间点出现在 org-agenda 的第一行。写完这篇文章，我去把它彻底关上。</p><h2 id="三、Tux"><a href="#三、Tux" class="headerlink" title="三、Tux"></a>三、Tux</h2><p>AJ 的生日礼物，小企鹅，本来想送只小鸭子的，但是找半天也没有找到。</p><p><img src="/posts/47f13c89/2024-03-16_22-09-49_微信图片_20240316215816.jpg" alt="2024-03-16_22-09-49_微信图片_20240316215816" style="zoom:33%;"></p><p>其实我也不知道送些什么合适，其实我不觉得这个礼物很能代表我的心意。我在害怕。</p><p>后来这只企鹅被 AJ 放在考研的那个桌斗里，时不时会拿出来。</p><h2 id="四、地坛"><a href="#四、地坛" class="headerlink" title="四、地坛"></a>四、地坛</h2><p>和 AJ 吃到了心心念念的打卤面，在雍和宫附近的“锅儿挑”吃得。不过有一说一只是普通的一碗面条，并没有想象中的好吃。不过他家的老豆腐超级好吃，豆腐紧致，豆香浓郁，蘸着调好的酱油醋非常鲜：</p><p><img src="/posts/47f13c89/2024-03-17_22-00-27_锅儿挑打卤面.jpg" alt="2024-03-17_22-00-27_锅儿挑打卤面" style="zoom:50%;"></p><p>这面确实不如我姥姥家里面做得好吃，店主人谱子还大，AJ 只是吐槽了几句，我念着 AJ 没有直接拂袖而去，也没有很生气。</p><p>不知道为什么，似乎我心里的“北京”在有 AJ 在场的时候总是很丢脸。</p><p>在地坛边上吃了三元梅园的豆沙奶卷，第一口觉的有些淡，但是后面混合甜甜的豆沙吃非常好吃：</p><p><img src="/posts/47f13c89/2024-03-17_22-01-29_豆沙奶卷.jpg" alt="2024-03-17_22-01-29_豆沙奶卷" style="zoom:50%;"></p><p>这个豆沙现在想起来实在是太好吃了，惹得我直流哈喇子。哦对了我想起来当时 AJ 吃得时候两只腿摆来摆去的，我当时一直在想为什么不是在地坛那里摆。</p><p>去了史铁生提到的地坛，在那个台子上坐了很久：</p><p><img src="/posts/47f13c89/dt.jpg" alt="2024-03-17_22-01-49_地坛"></p><p>那段时间我因为学习的事情一直心情不好，现在回看，似乎心情一直没有再好起来过。</p><h2 id="四、Free-Gundam"><a href="#四、Free-Gundam" class="headerlink" title="四、Free Gundam"></a>四、Free Gundam</h2><p>情人节 AJ 送的强袭自由，我还记得我小时候玩 SD 的时候，觉得它们的头都好大，现在玩起来感觉头也不是那么大，可能是手大了的缘故吧。</p><p><img src="/posts/47f13c89/2024-03-26_21-21-09_free.jpg" alt="2024-03-26_21-21-09_free" style="zoom:50%;"></p><p>其实当时我最担心的是她买成了 MGSD，那个好贵的。</p><p>所以人是没有办法走进对方的内心的，你跟别人形容你是怎么样的，别人就会把你当成什么样子。</p><h2 id="五、安妮意大利餐厅"><a href="#五、安妮意大利餐厅" class="headerlink" title="五、安妮意大利餐厅"></a>五、安妮意大利餐厅</h2><p>AJ 选得餐厅总是很好吃。我总觉得无论饭菜如何好吃或者难吃，都会过去的，最关键的是要把当时的味道和情感记录下来。但是我当时在写文章的时候，却总有一种落寞之感，我突然觉得我的文字不过是一个酸儒的矫饰，我无法让感情变得更加真挚，也无法让食物变得更加美味。</p><p>超级好吃的意餐（我甚至对着这张照片调了很久，因为果子的颜色被光掩盖了）：</p><p><img src="/posts/47f13c89/2024-04-01_22-53-58_微信图片_20240401225335.jpg" alt="2024-04-01_22-53-58_微信图片_20240401225335" style="zoom:50%;"></p><p>最好吃的是它的蜜瓜火腿，薄火腿片裹着哈密瓜，是一种非常创新的吃法。火腿的咸鲜渗透到哈密瓜瓤的甜蜜中，火腿的果木香与哈密瓜的果气儿缠绵，火腿的绵密和哈密瓜的脆爽交织，给味蕾留下了非常惊艳的记忆。</p><p><img src="/posts/47f13c89/2024-04-01_23-01-20_微信图片_20240401211548.jpg" alt="2024-04-01_23-01-20_微信图片_20240401211548" style="zoom: 50%;"></p><p>我第一次见火腿还是在《鹿鼎记》中，韦小宝用云南宣威火腿调戏小郡主的情节，配合上太监的旁白，就感觉非常好吃。虽然故事里是煮火腿，我们吃得是生火腿，但是其中意趣，也未必没有异曲同工的地方。</p><blockquote><p>韦小宝用筷子挟了一片鲜红喷香的宣威火腿，凑到小郡主口边，笑道：</p><p>“张开嘴来！”</p><p>小郡主牙齿咬实，紧紧闭嘴。</p><p>韦小宝将火腿在她嘴唇上擦来擦去，擦得满嘴是油……</p><p>小太监又送饭菜过来，道：</p><p>“桂公公，这宣威火腿是用蜜饯莲子煮的，煮得急了，或许不很软，请公公包涵。”</p></blockquote><p>与火腿相比，吃千层面主要是图个新鲜，很好奇加菲猫最爱吃的食物是什么样子的。千层面和千层饼并不像，实际上一层肉酱一层面饼，大概有个三四层，上面在铺一层芝士：</p><p><img src="/posts/47f13c89/2024-04-01_23-09-58_微信图片_20240401211558.jpg" alt="2024-04-01_23-09-58_微信图片_20240401211558" style="zoom:50%;"></p><p>我们还点了一个海鲜米饭，里面的虾和蛏子处理得很好，没有什么腥味，AJ 说起意餐的米饭总是要多煮一会儿，糯唧唧的就像粥泡饭一样，这我倒是不知道了，我只是觉得千层面，海鲜米饭和意大利面的味道都很近似，都是那种芝士奶油皮香和番茄肉酱的酸咸味儿。因为有火腿珠玉在前，便觉得后面两道菜逊色了一些：</p><p><img src="/posts/47f13c89/2024-04-01_23-14-40_微信图片_20240401211629.jpg" alt="2024-04-01_23-14-40_微信图片_20240401211629" style="zoom: 25%;"></p><p>其实餐前还上了免费的面包，可以蘸着紫苏酱、黄油和一种红红的酱吃。我觉得口感有些过于“粉”了，我不是很喜欢。</p><p>为了查那种红红的酱是啥，我翻了翻评论，没想到翻到了高晓松似乎是这里的常客。不过我查了查，《同桌的你》是 1993 就写完了，安妮是 1996 年才创建的，所以应该是假的？</p><p><img src="/posts/47f13c89/2024-04-01_23-25-15_微信图片_20240401232328.jpg" alt="2024-04-01_23-25-15_微信图片_20240401232328" style="zoom: 33%;"></p><p>我已经很久不和人说我喜欢听《同桌的你》了。</p><h2 id="六、B-Robot"><a href="#六、B-Robot" class="headerlink" title="六、B-Robot"></a>六、B-Robot</h2><p>这个铁甲小宝本来是我在贵州就看上了，就在 AJ 念高中对面的那个商场。</p><p>后来好像快毕业的时候我买了它。当时 AJ 很激动，我也不知道为什么，就拉着我在旗杆下面拼完了</p><p><img src="/posts/47f13c89/2024-04-29_23-58-42_微信图片_20240429235534.jpg" alt="2024-04-29_23-58-42_微信图片_20240429235534" style="zoom: 25%;"></p><p>拿起来也超级可爱（谁能想到左边才是我的手呢）：</p><p><img src="/posts/47f13c89/2024-04-29_23-59-36_微信图片_20240429235520.jpg" alt="2024-04-29_23-59-36_微信图片_20240429235520" style="zoom:25%;"></p><h2 id="七、真爱小熊"><a href="#七、真爱小熊" class="headerlink" title="七、真爱小熊"></a>七、真爱小熊</h2><p>过生日 AJ 送的真爱小熊。巧克力很好吃，嘎嘎嘎！</p><p><img src="/posts/47f13c89/2024-05-16_16-17-01_img_20240516161626.jpg" alt="2024-05-16_16-17-01_img_20240516161626" style="zoom: 25%;"></p><p>唉，哈哈哈哈哈哈。</p><hr><h2 id="八、总结"><a href="#八、总结" class="headerlink" title="八、总结"></a>八、总结</h2><p>光标悬了很久，我也不知道打什么字。</p><p>可能缺少一些运气和默契吧。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、Kuromi-amp-Melody&quot;&gt;&lt;a href=&quot;#一、Kuromi-amp-Melody&quot; class=&quot;headerlink&quot; title=&quot;一、Kuromi &amp;amp; Melody&quot;&gt;&lt;/a&gt;一、Kuromi &amp;amp; Melody&lt;/h2&gt;&lt;p&gt;Kuromi 是 AJ 送我的第一个礼物，好像是在五道口地下一层买的，当时我们好像还没有正式确立关系，在回去之前，她走进商店买了 Kuromi，然后挂在了我书包的后面。后面很多的日子里我背上书包，都感觉似乎有一只手在牵着我。&lt;/p&gt;
&lt;p&gt;Melody 是后来我送给 AJ 的，琢磨着可以凑一对。&lt;/p&gt;
&lt;p&gt;嗷对了，AJ 还不相信我能把挂着玩偶的链子解开后再挂到书包上去。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/posts/47f13c89/2024-03-16_22-14-46_Kuromi&amp;amp;Melody.jpg&quot; alt=&quot;2024-03-16_22-14-46_Kuromi&amp;amp;Melody&quot; style=&quot;zoom: 50%;&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="吃喝玩乐" scheme="https://thysrael.github.io/categories/%E5%90%83%E5%96%9D%E7%8E%A9%E4%B9%90/"/>
    
    
    <category term="吃喝玩乐" scheme="https://thysrael.github.io/tags/%E5%90%83%E5%96%9D%E7%8E%A9%E4%B9%90/"/>
    
    <category term="S10课上" scheme="https://thysrael.github.io/tags/S10%E8%AF%BE%E4%B8%8A/"/>
    
  </entry>
  
  <entry>
    <title>自由王国-没有银弹</title>
    <link href="https://thysrael.github.io/posts/afa7becb/"/>
    <id>https://thysrael.github.io/posts/afa7becb/</id>
    <published>2025-03-30T02:32:58.000Z</published>
    <updated>2025-08-15T12:16:49.003Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、总论"><a href="#一、总论" class="headerlink" title="一、总论"></a>一、总论</h2><p>这是一篇记录我配置新电脑，在新电脑上配置系统的过程。</p><p>之所以取名叫作“没有银弹”，是因为我被挑选硬件、软件的过程折磨的精疲力竭。“没有银弹”虽然是一个老生常谈的话题，但是发现它出现在非软件工程领域，还是非常让人意外的。</p><p>没有一个笔记本、可以兼具 PC 的量大管饱和 Macbook 的高续航和漂亮屏幕；没有一个操作系统，可以兼具 Linux 的开发环境相似性、Windows 的普世和 MacOS 的闭合生态；没有一个发行版，可以兼具 ArchLinux 的高可控性和及时性，NixOS 的可复现性，Ubuntu 的稳定性；没有一个图形服务器兼具 Xorg 的适配性和 Wayland 的高性能；甚至没有一个编辑器，可以兼具 Emacs 的键盘操作和 VSCode 的 Remote 功能！</p><p>在我各种权衡利弊下，我得到了一个低续航、很沉、没有独显、甚至还不便宜的笔记本；上面装着的操作系统，无法驱动触摸板、声卡和蓝牙；软件包管理形式依然是 <code>pacman</code>，只要我开始更新，我就要一直更新；依然是老旧的 Xorg，每使用一天就是在向死亡奔赴一天；都 2025 了，我甚至还要被 Emacs 的沉没成本绑架以至于无法使用 VSCode。</p><p>这岂止是“没有银弹”，这完全是“无法胜利”！我只能忍受这些事情，关键是我都不知道我为什么要忍受这些。我想起了我第一次看见学长在 Manjaro 的 Konsole 上敲命令的样子；我想起了同学开着 VSCode 打开 WSL 的样子；我想起了师兄一只手端着 Mac 去找老师讨论的样子。是的，我羡慕他们。但是又不止是这些，我想到我作为一个 system 方向的研究生，我连我自己的 Operating System 都无法控制；我想到了我第一次编译 Linux 内核的时候，哗哗滚动的命令行；我想到了我的 Emacs 可以显示出来文件图标的样子。</p><p>所以到底为什么？我为什么要执着于这些事情？我在执着于我自己。如果我放弃这些东西，我还是我自己吗？我管计算机世界叫作“自由王国”，因为我相信只要愿意付出精力和时间，那么就会获得自由。可是这些事情告诉我，不是这样的。我无法胜利，我无法自由，在我剩余的生命中，只有一次又一次的妥协。无数次妥协、无数次失败的我，还有自由意志可言吗？而失去自由意志的我，还是我吗？</p><p>如果，“没有银弹”这个事情，不止在“软件工程”和“装新电脑”这两件事情上发生呢？或许在爱情、事业、家庭中，它们都在发生……我到底在执着什么呢？</p><p>我想用我的余生回答这个问题。</p><hr><h2 id="二、Why-Not"><a href="#二、Why-Not" class="headerlink" title="二、Why Not?"></a>二、Why Not?</h2><p>这里会记录我为什么不做一些选择。</p><h3 id="2-1-Wayland"><a href="#2-1-Wayland" class="headerlink" title="2.1 Wayland"></a>2.1 Wayland</h3><p>目前 wayland 不支持腾讯会议的屏幕共享功能，这导致它没有办法作为一个办公本出现。此外 wayland 也不支持类似于 peek 这样的屏幕录制 gif 工具，我也很需要这种工具。</p><h3 id="2-2-Other-OS"><a href="#2-2-Other-OS" class="headerlink" title="2.2 Other OS"></a>2.2 Other OS</h3><h4 id="2-2-1-NixOS"><a href="#2-2-1-NixOS" class="headerlink" title="2.2.1 NixOS"></a>2.2.1 NixOS</h4><p>本次装机因为机子太新了，所以 NixOS 的网卡驱动一直装不上去。</p><p>此外 NixOS 除了可复现性以外，它还提供了一套声明式配置的设计理念。虽然声明式可以有效避免配置项本身的变化，但是我觉得用 Linux，不就是为了用它命令式“刀耕火种“、”手搓系统“的爽感嘛？如果啥啥都要去查 NixOS 的配置文档，那又有什么意思呢？</p><h4 id="2-2-2-Ubuntu"><a href="#2-2-2-Ubuntu" class="headerlink" title="2.2.2 Ubuntu"></a>2.2.2 Ubuntu</h4><p>太旧了，软件更新实在是太不及时了，我不想用一个 26 版本的 Emacs。</p><h3 id="2-3-KDE"><a href="#2-3-KDE" class="headerlink" title="2.3 KDE"></a>2.3 KDE</h3><p>我想要版本监控我的 DE 配置，但是 KDE 的配置文件近乎二进制，很难监控。</p><h3 id="2-4-14-Inch"><a href="#2-4-14-Inch" class="headerlink" title="2.4 14 Inch"></a>2.4 14 Inch</h3><p>没啥，我一个 186 的壮汉，岂能拿这种小家子气的机子。</p><hr><h2 id="三、Setup"><a href="#三、Setup" class="headerlink" title="三、Setup"></a>三、Setup</h2><h3 id="3-1-制作装机盘"><a href="#3-1-制作装机盘" class="headerlink" title="3.1 制作装机盘"></a>3.1 制作装机盘</h3><p>在这个 <a href="https://archlinux.org/download/">页面</a> 下载 ArchLinux ISO 镜像文件，并使用 <code>dd</code> 命令制作装机盘：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">dd</span> <span class="token assign-left variable">bs</span><span class="token operator">=</span>4M <span class="token assign-left variable">if</span><span class="token operator">=</span>/path/to/archlinux.iso <span class="token assign-left variable">of</span><span class="token operator">=</span>/dev/sdx <span class="token assign-left variable">status</span><span class="token operator">=</span>progress <span class="token assign-left variable">oflag</span><span class="token operator">=</span>sync<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中 <code>status</code> 用于显示 <code>dd</code> 进程，<code>oflay</code> 用于确保写入同步。</p><h3 id="3-2-Live-环境"><a href="#3-2-Live-环境" class="headerlink" title="3.2 Live 环境"></a>3.2 Live 环境</h3><p>Live 环境指的是采用 U 盘引导进入的系统，当我们把系统安装到主机上，这个过程就结束了（就可以拔 U 盘了）。</p><h4 id="3-2-1-分区前"><a href="#3-2-1-分区前" class="headerlink" title="3.2.1 分区前"></a>3.2.1 分区前</h4><p>reflector 会为你选择速度合适的镜像源，但其结果并不准确，同时会清空配置文件中的内容，对于新人来讲并不适用，我们首先对其进行禁用。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">systemctl stop reflector.service<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>无线连接使用 <code>iwctl</code> 命令进行，按照如下步骤进行网络连接：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">iwctl                           <span class="token comment"># 执行 iwctl 命令，进入交互式命令行</span>device list                     <span class="token comment"># 列出设备名，比如无线网卡看到叫 wlan0</span>station wlan0 scan              <span class="token comment"># 扫描网络</span>station wlan0 get-networks      <span class="token comment">#列出网络 比如想连接 YOUR-WIRELESS-NAME 这个无线</span>station wlan0 connect YOUR-WIRELESS-NAME <span class="token comment"># 进行连接 输入密码即可</span><span class="token builtin class-name">exit</span>                            <span class="token comment"># 成功后 exit 退出</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以等待几秒等网络建立链接后再进行下面测试网络的操作。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">ping</span> www.gnu.org<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果不能正常使用网络，那么要确定网卡是否 <code>up</code></p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">ip</span> <span class="token function">link</span><span class="token function">ip</span> <span class="token function">link</span> <span class="token builtin class-name">set</span> wlan0 up<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>如果还不行，其实可以将手机和电脑连接在一起，在手机中选择“共享网络”给电脑。</p><p>更新系统时钟：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">timedatectl set-ntp <span class="token boolean">true</span>    <span class="token comment"># 将系统时间与网络时间进行同步</span>timedatectl status          <span class="token comment"># 检查服务状态</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>主要是查看 <code>System clock synchronized</code> 和 <code>NTP Service</code> 这两项，时区设置在后面。</p><h4 id="3-2-2-分区"><a href="#3-2-2-分区" class="headerlink" title="3.2.2 分区"></a>3.2.2 分区</h4><p>为了使得 OS 能够安装在硬盘上并正常启动，我们需要对硬盘进行分区。我们可以先使用如下命令查看一下块设备情况：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">lsblk<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对于 laptop 来说，一般是有 <code>sda</code> 对应 U 盘，<code>nvme0n1</code> 对应硬盘。我们要对 <code>nvme0n1</code> 进行分区：</p><ul><li>boot 分区：也就是 UEFI 启动时需要的分区，需要 FAT32 格式。</li><li>swap 分区：当物理内存溢出时，可以交换到硬盘上的这个分区。此外休眠（Hibernate）时的状态文件也会保存在这个分区。</li><li><code>/</code> 分区：主分区</li><li><code>/home</code> 分区：家目录分区</li></ul><p>其实没有 swap 分区也可以，目前 laptop 的大内存一般也不会出现溢出的情况。即使需要 Hibernate 的功能，也可以用 swapfile 机制代替。但是我觉得 swapfile 太丑了，而且据说性能不如 swap 分区好，我就选择了 swap 分区。</p><p>此外还有要不要对 <code>/home</code> 单独分区的问题。对 <code>/home</code> 单独分区，可以隔绝系统软件和用户目录对彼此的影响，还可以方便地更换发行版。我之前出现过一次差点重装系统的事故，如果对 <code>/home</code> 单独分区，可以在重装系统的时候避免损坏家目录中的数据文件。</p><p>在进行分区前，需要创建 GPT 分区表：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">lsblk                       <span class="token comment"># 显示分区情况 找到你想安装的磁盘名称</span><span class="token function">parted</span> /dev/nvme0n1         <span class="token comment"># 执行 parted ，进入交互式命令行，进行磁盘类型变更</span><span class="token punctuation">(</span>parted<span class="token punctuation">)</span> mktable            <span class="token comment"># 输入 mktable</span>New disk label type? gpt    <span class="token comment"># 输入 gpt 将磁盘类型转换为 gpt 如磁盘有数据会警告，输入 yes 即可</span>quit                        <span class="token comment"># 最后 quit 退出 parted 命令行交互</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后执行如下命令进入 TUI 界面对硬盘进行分区：</p><pre class="line-numbers language-none"><code class="language-none">cfdisk /dev/nvme0n1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>界面非常简单，用方向键和回车就可以操作，分区的具体信息如下表所示：</p><div class="table-container"><table><thead><tr><th>Partition</th><th>Size</th><th>Type</th></tr></thead><tbody><tr><td>boot</td><td>512 MiB</td><td>EFI System</td></tr><tr><td>swap</td><td>16 GiB</td><td>Linux Swap</td></tr><tr><td><code>/</code></td><td>144 GiB</td><td>Linux filesystem</td></tr><tr><td><code>/home</code></td><td>793.4 GiB</td><td>Linux filesystem</td></tr></tbody></table></div><p>GB 是以 10 为基数的，厂商宣传一般用这个，而 GiB 是以 2 为基数的，更适合 SSD 硬件体质。</p><p>关于 <code>/</code> 的大小，我使用了 5 年的笔记本大约是 120G，其中有 50G 的 cache 还没有清理，所以我觉得 144G 是一个比较合理的数值。而关于 swap 分区的大小，纯粹是我舍不得了。</p><p>使用如下命令复查分区情况：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">fdisk</span> -l<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后格式化分区：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># boot</span>mkfs.vfat -F <span class="token number">32</span> /dev/nvme0n1p1<span class="token comment"># swap</span><span class="token function">mkswap</span> /dev/nvme0n1p2<span class="token function">swapon</span> /dev/nvme0n1p2<span class="token comment"># root</span>mkfs.ext4 /dev/nvme0n1p3mkfs.ext4 /dev/nvme0n1p4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>至于为啥选择了 ext4 而没有选择 btrfs，是因为 ext4 性能好，稳定，兼容性好，虽然 btrfs 功能多，但是那些功能我也不懂，所以就没有选。</p><h4 id="3-2-3-挂载"><a href="#3-2-3-挂载" class="headerlink" title="3.2.3 挂载"></a>3.2.3 挂载</h4><p>要按照顺序对分区进行挂载，先挂载 <code>/</code> 分区：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># root</span><span class="token function">mount</span> /dev/nvme0n1p3 /mnt<span class="token comment"># boot</span><span class="token function">mkdir</span> /mnt/boot<span class="token function">mount</span> /dev/nvme0n1p1 /mnt/boot<span class="token comment"># home</span><span class="token function">mkdir</span> /mnt/home<span class="token function">mount</span> /dev/nvme0n1p4 /mnt/home<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后修改镜像源，来为安装软件做准备：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">vim</span> /etc/pacman.d/mirrorlist<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="3-2-4-初步安装与配置"><a href="#3-2-4-初步安装与配置" class="headerlink" title="3.2.4 初步安装与配置"></a>3.2.4 初步安装与配置</h4><p>本质是把中国的源往前提：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">Server <span class="token operator">=</span> https://mirrors.ustc.edu.cn/archlinux/<span class="token variable">$repo</span>/os/<span class="token variable">$arch</span>Server <span class="token operator">=</span> https://mirrors.tuna.tsinghua.edu.cn/archlinux/<span class="token variable">$repo</span>/os/<span class="token variable">$arch</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>然后安装基础的包：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pacstrap /mnt base base-devel linux linux-headers linux-firmware  <span class="token comment"># base-devel 在 AUR 包的安装是必须的</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>安装必要的功能性软件</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pacstrap /mnt dhcpcd iwd <span class="token function">vim</span> bash-completion   <span class="token comment"># 有线所需(iwd 也需要 dhcpcd )、无线所需、编辑器、补全工具</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>生成 fstab 文件：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">genfstab -U /mnt <span class="token operator">&gt;&gt;</span> /mnt/etc/fstab<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>chroot</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">arch-chroot /mnt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>设置时区：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">ln</span> -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimehwclock --systohc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>然后设置 locale，它决定了地域、货币、时区日期的格式、字符排列方式和其他本地化标准。先用 vim 去掉 <code>/etc/locale.gen</code> 文件中的  <code>en_US.UTF-8</code> 和 <code>zh_CN.UTF-8</code> 的注释。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">vim</span> /etc/locale.gen<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后使用如下命令生成 locale：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">locale-gen<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>最后向 <code>/etc/locale.conf</code> 导入内容</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">echo</span> <span class="token string">'LANG=en_US.UTF-8'</span>  <span class="token operator">&gt;</span> /etc/locale.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后在 <code>/etc/hostname</code> 设置主机名：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">vim</span> /etc/hostname<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>接下来在<code>/etc/hosts</code> 设置与其匹配的条目。</p><pre class="line-numbers language-none"><code class="language-none">vim /etc/hosts<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>加入如下内容：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token number">127.0</span>.0.1   localhost::1         localhost<span class="token number">127.0</span>.1.1   loquat<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>然后为 root 设置密码：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">passwd</span> root<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后安装微码：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pacman -S intel-ucode   <span class="token comment"># Intel</span>pacman -S amd-ucode     <span class="token comment"># AMD</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="3-2-5-GRUB"><a href="#3-2-5-GRUB" class="headerlink" title="3.2.5 GRUB"></a>3.2.5 GRUB</h4><p>首先安装引导程序：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># grub 是启动引导器，efibootmgr 被 grub 脚本用来将启动项写入 NVRAM</span>pacman -S grub efibootmgrgrub-install --target<span class="token operator">=</span>x86_64-efi --efi-directory<span class="token operator">=</span>/boot --bootloader-id<span class="token operator">=</span>GRUB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>然后通过编辑 <code>/etc/default/grub</code> 文件，配置 grub 传递给 Linux Kernel 的参数：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token assign-left variable">GRUB_CMDLINE_LINUX_DEFAULT</span><span class="token operator">=</span><span class="token string">"loglevel=5 nowatchdog"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>增加 log level 有助于 debug， <code>nowatchdog</code> 可以提高启动速度。</p><p>然后让 grub 生成配置文件：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">grub-mkconfig</span> -o /boot/grub/grub.cfg<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="3-2-6-完成安装"><a href="#3-2-6-完成安装" class="headerlink" title="3.2.6 完成安装"></a>3.2.6 完成安装</h4><p>退出 <code>chroot</code> 环境，重启：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">exit</span>                <span class="token comment"># 退回安装环境#</span><span class="token function">umount</span> -R  /mnt     <span class="token comment"># 卸载新分区</span><span class="token function">reboot</span>              <span class="token comment"># 重启</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>重启后启动 dhcp 和无线网络服务</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">systemctl start dhcpcdsystemctl start iwd<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>然后就可以使用 <code>iwctl</code> 工具来连接网络了。</p><h3 id="3-3-开始之前"><a href="#3-3-开始之前" class="headerlink" title="3.3 开始之前"></a>3.3 开始之前</h3><p>在我们开始安装各种应用软件之前，我们还需要做一些准备工作：</p><h4 id="3-3-1-创建用户"><a href="#3-3-1-创建用户" class="headerlink" title="3.3.1 创建用户"></a>3.3.1 创建用户</h4><p>创建一个普通用户 thysrael：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">useradd</span> -m -G wheel -s /bin/bash thysrael  <span class="token comment"># wheel 附加组可使用 sudo，-m 同时创建用户家目录</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>设置 thysrael 的密码：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">passwd</span> thysreal<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑 sudoers 配置文件</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token assign-left variable">EDITOR</span><span class="token operator">=</span>vim visudo  <span class="token comment"># 需要以 root 用户运行 visudo 命令</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>找到下面这样的一行，把前面的注释符号 <code>#</code> 去掉，<code>:wq</code> 保存并退出即可。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#%wheel ALL=(ALL:ALL) ALL</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="3-3-2-网络连接"><a href="#3-3-2-网络连接" class="headerlink" title="3.3.2 网络连接"></a>3.3.2 网络连接</h4><p>我们在 live 环境下使用的网络连接工具是 <code>dhcpcd</code> 配合 <code>iwd</code>，但是在日常使用中，我们更喜欢 <code>networkmanager</code>，因为它的使用更加简便，而且和 GUI 界面融合的更好。所以我们安装 <code>networkmanager</code> 并关闭 <code>dhcpcd</code> 和 <code>iwd</code> 的功能。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> pacman -S networkmanager<span class="token function">sudo</span> systemctl disable iwd                             <span class="token comment"># 确保 iwd 开机处于关闭状态，其无线连接会与 NetworkManager 冲突</span><span class="token function">sudo</span> systemctl stop iwd                                <span class="token comment"># 同上，立即关闭 iwd</span><span class="token function">sudo</span> systemctl <span class="token builtin class-name">enable</span> --now NetworkManager             <span class="token comment"># 确保先启动 NetworkManager，并进行网络连接</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>可能需要重启才能生效。</p><p>我们可以使用如下命令在 CLI 界面使用 networkmanager：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 列出所有设备</span>nmcli device<span class="token comment"># 显示所有可用的 Wi-Fi 网络</span>nmcli device wifi list<span class="token comment"># 连接到一个 Wi-Fi 网络</span>nmcli device wifi connect <span class="token string">"SSID_NAME"</span> password <span class="token string">"your_password"</span><span class="token comment"># 断开网络连接</span>nmcli device disconnect iface_name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>应该配置一次后就可以自动连接了。</p><h4 id="3-3-3-包管理器"><a href="#3-3-3-包管理器" class="headerlink" title="3.3.3 包管理器"></a>3.3.3 包管理器</h4><p>首先我们先开启 32 位支持库（我也不知道为啥，可能这样包的数量就变多了吧），编辑 <code>/etc/pacman.conf</code> 将 <code>[multilib]</code> 那一节的注释取消掉。</p><p>然后使用如下命令刷新 <code>pacman</code> 数据库：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pacman -Syyu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后我们要安装 <code>yay</code> ，目前 <code>yay</code> 被墙了，所以我们要先安装 <code>git</code> ，然后 clone 下来 <code>yay</code> 仓库并构建：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pacman -S <span class="token function">git</span><span class="token function">git</span> clone https://aur.archlinux.org/yay-bin.git <span class="token comment"># 一定得是 yay-bin，因为 yay 基于 go 构建，go 也被墙了</span><span class="token builtin class-name">cd</span> yay-binmakepkg -si<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-4-GUI"><a href="#3-4-GUI" class="headerlink" title="3.4 GUI"></a>3.4 GUI</h3><p>我们要安装 i3 作为我们的窗口管理器。</p><h4 id="3-4-1-显卡驱动"><a href="#3-4-1-显卡驱动" class="headerlink" title="3.4.1 显卡驱动"></a>3.4.1 显卡驱动</h4><p>首先安装 Intel 集成显卡驱动：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pacman -S mesa lib32-mesa vulkan-intel lib32-vulkan-intel<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li><code>mesa</code> 是开源的 OpenGL 实现，支持 Intel 核显的 3D 图形渲染。</li><li><code>Vulkan</code> 是核显的 Vulkan API 驱动，支持现代图形渲染技术（如光线追踪、高性能计算）。</li></ul><p>不建议安装 <code>xf86-video-intel</code> ，似乎说性能不好。</p><h4 id="3-4-2-Xorg"><a href="#3-4-2-Xorg" class="headerlink" title="3.4.2 Xorg"></a>3.4.2 Xorg</h4><p>安装 xorg 作为我们的图形服务器：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pacman -S xorg-server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>xorg-server</code> ：是一个开源的 X Window System 服务器，用于管理图形显示和用户输入。</p><h4 id="3-4-3-登录器"><a href="#3-4-3-登录器" class="headerlink" title="3.4.3 登录器"></a>3.4.3 登录器</h4><p>我们需要先安装登录器，这样我们一开机就可以进入 GUI 了：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> pacman -S sdm<span class="token function">sudo</span> systemctl <span class="token builtin class-name">enable</span> sdm.service<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>本来想安装 lightdm 的，结果启动不成功。</p><h4 id="3-4-4-i3wm"><a href="#3-4-4-i3wm" class="headerlink" title="3.4.4 i3wm"></a>3.4.4 i3wm</h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> pacman -S i3-wm i3status dmenu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li><p><strong>i3-wm</strong> 是一个高度可定制、平铺式窗口管理器。</p></li><li><p><strong>i3status</strong> 是一个简单的状态栏生成器，它可以在 i3-wm 的栏上显示有关系统状态（如时间、电池状态、网络连接等）的信息。</p></li><li><strong>dmenu</strong> 是一个轻量级的动态菜单。它可以用于启动应用程序、执行命令或选择其他操作。</li></ul><p>此外，为了让我们进入 I3 后有个终端模拟器可以用，我们还安装 kitty：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> pacman -S kitty<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后我们重启就可以了。</p><h3 id="3-5-硬件适配"><a href="#3-5-硬件适配" class="headerlink" title="3.5 硬件适配"></a>3.5 硬件适配</h3><h4 id="3-5-1-改键位"><a href="#3-5-1-改键位" class="headerlink" title="3.5.1 改键位"></a>3.5.1 改键位</h4><p>然后我们就可以安装我心心念念的改键器了：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pacman -S interception-caps2esc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>安装好了以后，在<code>/etc/udevmon.yaml</code>添加下列代码</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token punctuation">-</span> <span class="token key atrule">JOB</span><span class="token punctuation">:</span> <span class="token string">"intercept -g $DEVNODE | caps2esc | uinput -d $DEVNODE"</span>  <span class="token key atrule">DEVICE</span><span class="token punctuation">:</span>     <span class="token key atrule">EVENTS</span><span class="token punctuation">:</span>       <span class="token key atrule">EV_KEY</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>KEY_CAPSLOCK<span class="token punctuation">,</span> KEY_ESC<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>在 <code>/etc/systemd/system/udevmon.service</code> 中添加下列代码</p><pre class="line-numbers language-toml" data-language="toml"><code class="language-toml"><span class="token punctuation">[</span><span class="token table class-name">Unit</span><span class="token punctuation">]</span><span class="token key property">Description</span><span class="token punctuation">=</span>udevmon<span class="token key property">Wants</span><span class="token punctuation">=</span>systemd-udev-settle<span class="token punctuation">.</span>service<span class="token key property">After</span><span class="token punctuation">=</span>systemd-udev-settle<span class="token punctuation">.</span>service<span class="token punctuation">[</span><span class="token table class-name">Service</span><span class="token punctuation">]</span><span class="token key property">ExecStart</span><span class="token punctuation">=</span>/usr/bin/nice -n <span class="token number">-20</span> /usr/bin/udevmon -c /etc/udevmon<span class="token punctuation">.</span>yaml<span class="token punctuation">[</span><span class="token table class-name">Install</span><span class="token punctuation">]</span><span class="token key property">WantedBy</span><span class="token punctuation">=</span>multi-user<span class="token punctuation">.</span>target<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最后使用如下命令来启动：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> systemctl <span class="token builtin class-name">enable</span> --now udevmon<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、总论&quot;&gt;&lt;a href=&quot;#一、总论&quot; class=&quot;headerlink&quot; title=&quot;一、总论&quot;&gt;&lt;/a&gt;一、总论&lt;/h2&gt;&lt;p&gt;这是一篇记录我配置新电脑，在新电脑上配置系统的过程。&lt;/p&gt;
&lt;p&gt;之所以取名叫作“没有银弹”，是因为我被挑选硬件、软件的过程折磨的精疲力竭。“没有银弹”虽然是一个老生常谈的话题，但是发现它出现在非软件工程领域，还是非常让人意外的。&lt;/p&gt;
&lt;p&gt;没有一个笔记本、可以兼具 PC 的量大管饱和 Macbook 的高续航和漂亮屏幕；没有一个操作系统，可以兼具 Linux 的开发环境相似性、Windows 的普世和 MacOS 的闭合生态；没有一个发行版，可以兼具 ArchLinux 的高可控性和及时性，NixOS 的可复现性，Ubuntu 的稳定性；没有一个图形服务器兼具 Xorg 的适配性和 Wayland 的高性能；甚至没有一个编辑器，可以兼具 Emacs 的键盘操作和 VSCode 的 Remote 功能！&lt;/p&gt;
&lt;p&gt;在我各种权衡利弊下，我得到了一个低续航、很沉、没有独显、甚至还不便宜的笔记本；上面装着的操作系统，无法驱动触摸板、声卡和蓝牙；软件包管理形式依然是 &lt;code&gt;pacman&lt;/code&gt;，只要我开始更新，我就要一直更新；依然是老旧的 Xorg，每使用一天就是在向死亡奔赴一天；都 2025 了，我甚至还要被 Emacs 的沉没成本绑架以至于无法使用 VSCode。&lt;/p&gt;</summary>
    
    
    
    <category term="自由王国" scheme="https://thysrael.github.io/categories/%E8%87%AA%E7%94%B1%E7%8E%8B%E5%9B%BD/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="自由王国" scheme="https://thysrael.github.io/tags/%E8%87%AA%E7%94%B1%E7%8E%8B%E5%9B%BD/"/>
    
    <category term="s10课上" scheme="https://thysrael.github.io/tags/s10%E8%AF%BE%E4%B8%8A/"/>
    
  </entry>
  
  <entry>
    <title>海边拾贝-FuseMax</title>
    <link href="https://thysrael.github.io/posts/ce241189/"/>
    <id>https://thysrael.github.io/posts/ce241189/</id>
    <published>2025-02-13T13:32:06.000Z</published>
    <updated>2025-08-15T12:16:48.910Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>这篇工作比较缝合，它引用了 3 个 idea：</p><ul><li><a href="https://arxiv.org/abs/2205.14135">Flash Attention</a> 和 pass 抽象</li><li><a href="https://dl.acm.org/doi/10.1145/3613424.3623791">TeAAL</a> 和它使用的 Einsum 规范</li><li><a href="https://arxiv.org/abs/2404.11591">Extended Einsum</a></li></ul><p>TeAAL 提出用 Einsum 的形式去描述算子，并指导加速器的设计。但是 Einsum 只能描述仅包含加法和乘法的算子，对于 Flash-Attension 这种包含指数运算（softmax）和迭代运算的算子无法描述，于是作者借用了 Extended Einsum 的形式描述了 Flash Attension 算子并实现了 FuseMax 加速器，同时论证了 pass 抽象的合理性。</p><p>而实际上，TeAAL 提出的用 Einsum 指导加速器设计的思路并没有因为使用了 Extended Einsum 而被拓展；FuseMax 所展现的性能优势，大部分来自于 Flash-Attension 算法本身，而不是其硬件实现。</p></blockquote><h2 id="一、Background"><a href="#一、Background" class="headerlink" title="一、Background"></a>一、Background</h2><h3 id="1-1-Flash-Attention-Pass"><a href="#1-1-Flash-Attention-Pass" class="headerlink" title="1.1 Flash Attention, Pass"></a>1.1 Flash Attention, Pass</h3><p>Flash-Attention 是一种 Attention 算子的实现，相比于传统的实现，它可以降低内存带宽的需求，并且使用更少的片上内存，更适合当前加速器存在的 memory bound。为了达到这个目的，我们需要：</p><ul><li>尽可能少的从内存中读取数据 -&gt; 算法设计的 pass 数要少</li><li>尽可能少使用片上内存 -&gt; tile 后 reduce</li></ul><p>而这两个需求都被 softmax 的传统实现阻止了，softmax 的表达式如下：</p><p><img src="/posts/ce241189/-17394538526611.png" alt="img"></p><p>传统的 softmax 实现是一种 3-pass 的实现：</p><p><img src="/posts/ce241189/-17394538576465.png" alt="img"></p><p>所谓的 pass，就是需要访问输入的次数：</p><blockquote><p>the number of times a given element of an input must be revisited after visiting every other element of the input. </p></blockquote><p>因为 softmax 需要先遍历所有元素计算出 max 值，然后根据 max 值遍历所有元素计算分母，再根据分母计算分子。</p><p>在 flash-attention 之前，有 2018 online-softmax 工作，将算法优化成了 2-pass 的。他将第 1，2 轮进行了合并：</p><p><img src="/posts/ce241189/-17394538620357.png" alt="img"></p><p>最终结果如图：</p><p><img src="/posts/ce241189/-173945386674411.png" alt="img"></p><p>如果仅在 softmax 层，那么 2-pass 就是极限了，不过如果考虑整个 Attention，那么是可以继续优化成 1-pass 的算法，这就是 Flash-Attention，2-pass 的 Attention 表示如下：</p><p><img src="/posts/ce241189/-173945387091113.png" alt="img"></p><p>然后我们注意到（直观上说，是利用了 a 这个数组并不是最终结果，而是会被 reduce 的性质）：</p><p><img src="/posts/ce241189/-173945387591215.png" alt="img"></p><p>整理后得到：</p><p><img src="/posts/ce241189/-173945387855817.png" alt="img"></p><p>这就是一个 1-pass 的 Flash-Attention 算法。在此基础上，如果增加了 tile 操作，那么就会获得完全体的 Flash-Attention，但这本文的重点是对于 pass 的优化。</p><p><img src="/posts/ce241189/-173945388095219.png" alt="img"></p><h3 id="1-2-Einsum-Notation"><a href="#1-2-Einsum-Notation" class="headerlink" title="1.2 Einsum Notation"></a>1.2 Einsum Notation</h3><p>爱因斯坦求和标记（Einstein summation notation）是一种标记的约定，用于描述张量运算。比如说二维矩阵乘法就可以被描述为：</p><p><img src="/posts/ce241189/-173945388316621.png" alt="img"></p><p>而矩阵与向量的乘法可以被描述为：</p><p><img src="/posts/ce241189/-173945388498323.png" alt="img"></p><p>Einsum 的输入包括张量，如<script type="math/tex">A, B</script>和其对应的坐标，如<script type="math/tex">m,k</script>和<script type="math/tex">k,n</script>，还有输出矩阵对应的坐标，如<script type="math/tex">m,</script>，比如在 numpy 中，$$$$和$$$$的矩阵乘法写作：</p><pre class="line-numbers language-Python" data-language="Python"><code class="language-Python">np.einsum('mk,kn-&gt;mn', A, B)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>Einsum 的特点在于，它将 compute 和 reduce 阶段完全区分开了，而不是混在一起，更加清晰了。</p><p>具体而言，在 compute 阶段，我们会根据输入坐标，构建一个迭代空间，然后遍历空间中的每一个点进行计算，得到一个相同维度的张量。以矩阵乘法为例，输入坐标是<script type="math/tex">m,k</script>和<script type="math/tex">k,n</script>，我们构建的迭代空间是<script type="math/tex">[1,M] \times [1,K] \times [1,N]</script>。经过计算得到的张量是<script type="math/tex">z'_{m,k, n} = [a_{m,k} \times b_{k,n}]</script>。</p><p>在 reduce 阶段，我们需要将我们得到的张量 $z<em>{m,k,n}$ 与输出坐标 <script type="math/tex">m,n</script> 进行比对，发现多了一个 <script type="math/tex">k</script> 维度。所以我们会沿着多出的维度进行规约，然后就可以得到 $$z</em>{m,n}=[\sum^{K}<em>{k=1}[a</em>{m,k} \times b_{k,n}]$$。</p><p>对比我平时用的矩阵乘法，可以看到 compute 和 reduce 是混合在一起的。</p><pre class="line-numbers language-C" data-language="C"><code class="language-C"> for (int i = 0; i &lt; M; i++) {     for (int j = 0; j &lt; N; j++) {        for (int k = 0; k &lt; K; k++) {            Z[i][j] += A[i][k] * B[k][j];         }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-3-TeAAL"><a href="#1-3-TeAAL" class="headerlink" title="1.3 TeAAL"></a>1.3 TeAAL</h3><p>TeAAL 是一个加速器模型 generator，可以根据不同算子生成不同的加速器模型。在它的设计中，算子需要使用 Einsum Cascade 来进行描述，也就是一系列的 Einsum 。</p><p>使用 Einsum 好处在于，引入了迭代空间，使得许多加速器设计中的优化和 tradeoff 都非常清晰。TeAAL 提出了 3 个维度的优化：</p><ul><li><strong>Loop Order</strong>：迭代空间“是<script type="math/tex">[1,M] \times [1,K] \times [1,N]</script>还是<script type="math/tex">[1,K] \times [1,M] \times [1,N]</script>”？这会影响数据是 stationary 的，还是 stream 的。</li><li><strong>Splitting</strong>：运算中我们常常将输入分块计算，也可以视为在对迭代空间分块。</li><li><strong>Work scheduling</strong>：根据迭代空间计算出的张量，是如何摆放的？包括空间和时间维度。</li></ul><p>总之 Einsum 是一个非常适合数学化表述加速器设计的标记。</p><h3 id="1-4-Extended-Einsum"><a href="#1-4-Extended-Einsum" class="headerlink" title="1.4 Extended Einsum"></a>1.4 Extended Einsum</h3><p>传统的 Einsum 是不能指定运算符的，比如说在 Numpy 中，Compute 阶段只能使用乘法，Reduce 阶段只能是加法：</p><pre class="line-numbers language-Python" data-language="Python"><code class="language-Python">np.einsum('mk,kn-&gt;mn', A, B)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> 而 Extended Einsum 则允许自定义 Compute 和 Reduce 阶段的运算符，例如：</p><p><img src="/posts/ce241189/-173945389006225.png" alt="img"></p><p><script type="math/tex">\bigwedg</script> 是 Compute 阶段使用的运算符，<script type="math/tex">\bigve</script>是 Reduce 阶段使用的运算符。</p><p>除此之外，Extended Einsum 还可以表达循环，比如说前缀和计算：</p><p><img src="/posts/ce241189/-173945389210827.png" alt="img"></p><p>还可以表达递推式，同样是前缀和计算：</p><p><img src="/posts/ce241189/-173945389430429.png" alt="img"></p><p>有了 Extended Einsum，我们就可以描述 Flash-Attention 这种包含许多复杂运算和递推式的算法。</p><hr><h2 id="二、Contribution"><a href="#二、Contribution" class="headerlink" title="二、Contribution"></a>二、Contribution</h2><h3 id="2-1-Einsum-与-Pass"><a href="#2-1-Einsum-与-Pass" class="headerlink" title="2.1 Einsum 与 Pass"></a>2.1 Einsum 与 Pass</h3><p>本文认为，如果将算子写成 Einsum 的形式，那么是有助于确定算子的 Pass 数的，比如说这个算子，就是 2-Pass：</p><p><img src="/posts/ce241189/-173945389672931.png" alt="img"></p><p>而相同功能的另一个算子，就是 1-Pass：</p><p><img src="/posts/ce241189/-173945389876733.png" alt="img"></p><p>本文认为，迭代空间也可以被表示成一个 fibertree，而根据这些 fibertree 就可以判断 pass。首先，我不知道为什么原本适用于稀疏矩阵表示的 fibertree 要用来表示一个非常稠密的迭代空间（它可能是想说 fibertree 用于表示根据迭代空间生成的那个向量），其次，我不知道为什么表示成了 fibertree，就可以看出来是多少个 Pass。</p><p>它原文中对迭代空间的 fibertree 定义如下，非常的简略：</p><blockquote><p>The is-fibertree is a special tree where each fiber belongs to a rank in the iteration space of the Einsum.</p></blockquote><p>而他介绍的根据 fibertree 识别 Pass 的方法，则依赖于非常主观的“Dependency”，其定义基本上和 Flash-Attention 中的定义一样：</p><blockquote><p>Now, in a scenario where fibers for a particular rank exist in multiple is-fibertrees; in each, they project to the same tensor; and <strong>there is a dependency such that all of the elements of the earlier is-fibertree’s fiber must be read before any element can be read again by the later is-fibertree (for all mappings of the</strong> <strong>cascade**</strong>)**, we refer to that read-read sequence as creating an additional pass.</p></blockquote><p>这种冗余和主观定义的方式，指示它无法编写成一个程序来自动优化 Pass 数目：</p><blockquote><p>We leave a full analysis of the space of pass-reduction approaches to future work.</p></blockquote><h3 id="2-2-用-Einsum-表示-Flash-Attention"><a href="#2-2-用-Einsum-表示-Flash-Attention" class="headerlink" title="2.2 用 Einsum 表示 Flash-Attention"></a>2.2 用 Einsum 表示 Flash-Attention</h3><p>用 Extended Einsum 表示 Flash-Attention，结果如图：</p><p><img src="/posts/ce241189/-173945390147135.png" alt="img"></p><p>文章只是将 Flash-Attention 换了一种标记形式（从伪代码到 Einsum Cascade），其算法的实质并没有发生改变。</p><h3 id="2-3-将-Flash-Attention-Map-到硬件上"><a href="#2-3-将-Flash-Attention-Map-到硬件上" class="headerlink" title="2.3 将 Flash-Attention Map 到硬件上"></a>2.3 将 Flash-Attention Map 到硬件上</h3><p>本文将 Flash-Attention 实现到了 Timeloop and Accelergy 模拟的 spatial 架构上：</p><p><img src="/posts/ce241189/-173945390429437.png" alt="img"></p><p>传统的 Attention 加速器，使用 2D Array 来计算矩阵乘法，使用 1D Array 来计算 softmax，这种安排的缺点在于，1D Array 计算 softmax 非常吃力，进而导致 2D Array 需要等待 1D Array 的计算，造成了低计算利用率。</p><p>但是 Flash-Attention 算法本身就融合 softmax 到前面的计算中，所以有一部分的 softmax 的计算任务，是可以放到 2D Array 中计算的，这样两个部分的计算任务就更加均衡了。</p><p>此外，2D Array 的 fill 和 drain 的开销很大，所以需要使用流水线的方法摊还（amortize）开销。</p><hr><h2 id="三、Evaluation"><a href="#三、Evaluation" class="headerlink" title="三、Evaluation"></a>三、Evaluation</h2><h3 id="3-1-Setup"><a href="#3-1-Setup" class="headerlink" title="3.1 Setup"></a>3.1 Setup</h3><p>实验在 TimeLoop 模拟器上进行（全是 Python 代码），BaseLine 分别是一个未经优化的 Attention 加速器，和 FLAT（经过 Fusion 等优化，但是依然使用普通 Attention 算法的加速器）。</p><p>WorkLoad 有 BERT，TrXL，T5，XLM。</p><h3 id="3-2-Compute-Utilization"><a href="#3-2-Compute-Utilization" class="headerlink" title="3.2 Compute Utilization"></a>3.2 Compute Utilization</h3><p>在真实负载情况下，计算单元利用率的比值：</p><p><img src="/posts/ce241189/-173945390670239.png" alt="img"></p><p>正如前文分析的，Baseline 的 2D Array 受到 1D Array 的拖累，导致利用率极低。</p><p>而在序列长度过长时，传统 Attention 算法会导致 global buffer 溢出，进而计算率下降，而 Flash-Attention 则没有这个问题。</p><h3 id="3-3-SpeedUp"><a href="#3-3-SpeedUp" class="headerlink" title="3.3 SpeedUp"></a>3.3 SpeedUp</h3><p>在 attention 时的加速比：</p><p><img src="/posts/ce241189/-173945390896841.png" alt="img"></p><p>在 inference 时的加速比：</p><p><img src="/posts/ce241189/28d63d58-4bd5-4995-ac91-a004c6cf6f85.png" alt=""></p><p>因为计算单元利用率提高，所以加速比也显著提高。</p><h3 id="3-4-Energy"><a href="#3-4-Energy" class="headerlink" title="3.4 Energy"></a>3.4 Energy</h3><p>在 attention 时的能耗：</p><p><img src="/posts/ce241189/-173945391102343.png" alt="img"></p><p>在 inference 时的能耗：</p><p><img src="/posts/ce241189/2861afa9-44ca-43ca-ba57-24cee9103951-1740103737579-3.png" alt="2861afa9-44ca-43ca-ba57-24cee9103951"></p><p>Flash-Attention 节约了 DRAM 的访存开销。</p><hr><h2 id="四、计算密度"><a href="#四、计算密度" class="headerlink" title="四、计算密度"></a>四、计算密度</h2><p>这篇工作主要结合了前人的工作，许多成果本质上是算法（Flash-Attention）或者开发框架（TeAAL，Timeloop）的成果，而非这篇工作自己的成果。</p><p>随着计算单元数目的增多，Roofline 模型中的硬件的 <script type="math/tex">I_{max}</script>越来越往右移动，这就导致越来越多的算法成为 memory bound 的：</p><p><img src="/posts/ce241189/-173945391334345.png" alt="img"></p><p>有一种解决问题的方式是减少内存读取的次数，比如说 Kernel Fusion：</p><p><img src="/posts/ce241189/-173945391528647.png" alt="img"></p><p>直白的 Fusion 并不会修改算子的实现，它只是将计算的中间结果存在了 On-chip Memory 中，但是 On-chip Memory 空间有限，这就导致一旦存不下来，依然会溢出到 Off-chip Memory 中，最终效果并不好（从上文的 Evaluation 中也可以看出）。</p><p>为了解决溢出问题（或者单纯为了减少访存次数），有一种思路是增加 On-chip Memory 的容量，比如说 IPU，相比于 CPU 和 GPU，就增加了更多的片上 SRAM：</p><p><img src="/posts/ce241189/-173945391724649.png" alt="img"></p><p>但是这种方式存在问题，就是片上 SRAM 的面积过大，IPU 很少去和 GPU 对比单位芯片面积（iso-area）下的性能。</p><p>Flash-Attention 和 FuseMax 我认为是另一种思路的代表，就是“以算代存”，计算的中间结果并存储后供后续使用，而是当需要使用的时候，再次计算一遍，是一种更加“数据流”的方法。通过构造额外的计算，来避免存储（Flash Attention 引入了更多的冗余的计算，但是减少了冗余的存储）：</p><p><img src="/posts/ce241189/-173945392031051.png" alt="img"><img src="/posts/ce241189/-173945392212853.png" alt="img"></p><p>我个人隐隐约约感觉，计算单元和存储单元有某种统一性，如果能把握它并提出一种更好的抽象，或许可以做出一个更本质的 tradeoff。</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;这篇工作比较缝合，它引用了 3 个 idea：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2205.14135&quot;&gt;Flash Attention&lt;/a&gt; 和 pass 抽象&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://dl.acm.org/doi/10.1145/3613424.3623791&quot;&gt;TeAAL&lt;/a&gt; 和它使用的 Einsum 规范&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2404.11591&quot;&gt;Extended Einsum&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;TeAAL 提出用 Einsum 的形式去描述算子，并指导加速器的设计。但是 Einsum 只能描述仅包含加法和乘法的算子，对于 Flash-Attension 这种包含指数运算（softmax）和迭代运算的算子无法描述，于是作者借用了 Extended Einsum 的形式描述了 Flash Attension 算子并实现了 FuseMax 加速器，同时论证了 pass 抽象的合理性。&lt;/p&gt;
&lt;p&gt;而实际上，TeAAL 提出的用 Einsum 指导加速器设计的思路并没有因为使用了 Extended Einsum 而被拓展；FuseMax 所展现的性能优势，大部分来自于 Flash-Attension 算法本身，而不是其硬件实现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;一、Background&quot;&gt;&lt;a href=&quot;#一、Background&quot; class=&quot;headerlink&quot; title=&quot;一、Background&quot;&gt;&lt;/a&gt;一、Background&lt;/h2&gt;&lt;h3 id=&quot;1-1-Flash-Attention-Pass&quot;&gt;&lt;a href=&quot;#1-1-Flash-Attention-Pass&quot; class=&quot;headerlink&quot; title=&quot;1.1 Flash Attention, Pass&quot;&gt;&lt;/a&gt;1.1 Flash Attention, Pass&lt;/h3&gt;&lt;p&gt;Flash-Attention 是一种 Attention 算子的实现，相比于传统的实现，它可以降低内存带宽的需求，并且使用更少的片上内存，更适合当前加速器存在的 memory bound。为了达到这个目的，我们需要：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;尽可能少的从内存中读取数据 -&amp;gt; 算法设计的 pass 数要少&lt;/li&gt;
&lt;li&gt;尽可能少使用片上内存 -&amp;gt; tile 后 reduce&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="海边拾贝" scheme="https://thysrael.github.io/categories/%E6%B5%B7%E8%BE%B9%E6%8B%BE%E8%B4%9D/"/>
    
    
    <category term="S9课上" scheme="https://thysrael.github.io/tags/S9%E8%AF%BE%E4%B8%8A/"/>
    
    <category term="海边拾贝" scheme="https://thysrael.github.io/tags/%E6%B5%B7%E8%BE%B9%E6%8B%BE%E8%B4%9D/"/>
    
    <category term="直观总结" scheme="https://thysrael.github.io/tags/%E7%9B%B4%E8%A7%82%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>Sys4AI-LLM</title>
    <link href="https://thysrael.github.io/posts/7dc4ea13/"/>
    <id>https://thysrael.github.io/posts/7dc4ea13/</id>
    <published>2025-01-30T14:24:19.000Z</published>
    <updated>2025-08-15T12:16:47.801Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、总论"><a href="#一、总论" class="headerlink" title="一、总论"></a>一、总论</h2><p>当我们提到大模型 LLM 的时候，总是和 Transformer 这种架构联系在一起，似乎只有使用了 Transformer 架构的深度学习模型才配叫作大模型。</p><p>不过以我目前浅薄的认知，我倒觉得 Transformer 并不是 LLM 的核心特征，因为 LLM 的算法变化很快，Transformer 从 2017 年到现在有了多种变体，也有完全不采用 Transformer 架构的 AI。我个人感觉 LLM 的核心有两点：</p><ul><li>模型参数极大：我们认为模型参数越多，模型就越智能。这是“涌现”的一种具体体现。</li><li>采用“预训练-微调-推理”范式：这种范式使得模型的通用性得到了增强，划分了不同的生态位。</li></ul><p>我希望在下文中记录一下关于 LLM 或者 Foundation Model 的基础知识，以避免被这个时代抛下太久。</p><hr><h2 id="二、数学基础"><a href="#二、数学基础" class="headerlink" title="二、数学基础"></a>二、数学基础</h2><h3 id="2-1-张量求导"><a href="#2-1-张量求导" class="headerlink" title="2.1 张量求导"></a>2.1 张量求导</h3><h4 id="2-1-1-规律"><a href="#2-1-1-规律" class="headerlink" title="2.1.1 规律"></a>2.1.1 规律</h4><p>之前我多次学习张量求导的数学定义，但是总感觉非常生硬和无厘头，因为我不清楚到底要求多少次偏导，导数矩阵的形状是什么（甚至有些都不是矩阵了，而是 3 维张量了），还有如何跟我之前学过的数学分析、线性代数知识联系在一起。</p><p>经过又一次的学习，我总结出如下规律：</p><ul><li>导数矩阵分量的个数，是因变量的分量个数与自变量的分量个数的乘积。这个细想下来非常显然，在求导的时候，当然应该对影响每个因变量的每个自变量求偏导，这样的每个结果就是导数矩阵中的一个分量。我们以最经典的雅各比矩阵举例，一个 $M$ 维的向量函数对于 $N$ 维的自变量向量求导，它的雅各比矩阵形状是 $M \times N$ ，也就是有 $MN$ 个分量。</li><li>导数矩阵的形状是出于适配链式求导法则等制定的，在梯度下降法中导数矩阵的形状需要与自变量形状相同。由上一条可知，我们已经可以确定导数矩阵中分量具体是什么了，但是如何排列这些分量组成导数矩阵依然不确定。经过我的学习，我觉得形状没有简单的规律可以总结。其核心在于一定要适用于链式法则，也就是要考虑到所有中间变量并求和（下文会有详述）。我又注意到，为了使梯度下降法生效，那么导数矩阵（也就是梯度矩阵），必须和自变量矩阵形状相同，要不然就无法实现矩阵减法了（对应元素相减）。顺便吐槽一下，梯度下降法并不是那么合理，用自变量减去导数，并没有实际意义，它只是在自变量处于极值点时，达到不动点。</li><li>在 ML 中，张量只是一种表示形式，高维度张量一定最终会被转化成矩阵运算。高维度导数张量是由于因变量是向量或者矩阵导致的，在 ML 中广泛存在向量值函数（比如 $softmax$）或者矩阵值函数（比如 $Attenction \space Score$）。但是不用担心，我们的最终目的是求解损失值函数对各个参数的导数矩阵，因为损失值函数是一个标量函数，所以导数矩阵一定是低维张量（后面有介绍）。</li></ul><h4 id="2-1-2-链式法则"><a href="#2-1-2-链式法则" class="headerlink" title="2.1.2 链式法则"></a>2.1.2 链式法则</h4><p>在标量世界中，对于 $z = g(y), y = f(x)$ ，链式法则通常写做：</p><script type="math/tex; mode=display">\frac{\partial z}{\partial x} = \frac{\partial z}{\partial y} \frac{\partial y}{\partial x}</script><p>那么如果 $x$ 不再是标量，而是一个向量 $X$ 怎么办，那么我们依然可以列出来 $X$ 的任意分量 $x_i$ ，有：</p><script type="math/tex; mode=display">\frac{\partial z}{\partial x_i} = \frac{\partial z}{\partial y} \frac{\partial y}{\partial x_i}</script><p>显然如果 $X$ 是一个矩阵，那么情形也是类似的，对于任意分量 $x_{ij}$ ，有：</p><script type="math/tex; mode=display">\frac{\partial z}{\partial x_{ij}} = \frac{\partial z}{\partial y} \frac{\partial y}{\partial x_{ij}}</script><p>上面的都很简单且显然，那么我们可以思考一下如果 $y$ 不再是标量，而是一个 $N$ 维向量 $Y$ 怎么办？那么 $X$ 的某个分量 $x_i$ 就可以通过影响 $Y$ 的所有分量 $y_1, y_2, \dots, y_n$ 来影响 $z$ ，所以当我们求 $z$ 对 $x_i$ 的偏导的时候，要考虑到所有的 $y_k$ ，所以其形式如下：</p><script type="math/tex; mode=display">\frac{\partial z}{\partial x_{i}} = \sum_{k = 1} ^ N \frac{\partial z}{\partial y_k} \frac{\partial y_k}{\partial x_{i}}</script><p>这个分量形式也可以被整理成更加规整的矩阵乘法形式（毕竟上面就是乘加运算），也就是如下所示：</p><script type="math/tex; mode=display">\frac{\partial z}{\partial \mathbf{X}} = \frac{\partial z}{\partial \mathbf{Y}} \frac{\partial Y}{\partial \mathbf{X}}\\= \begin{bmatrix}\frac{\partial z}{\partial y_1} \frac{\partial z}{\partial y_2} \cdots \frac{\partial z}{\partial y_n}\end{bmatrix}\begin{bmatrix}\frac{\partial y_1}{\partial x_{1}} & \frac{\partial y_1}{\partial x_{2}} & \cdots & \frac{\partial y_1}{\partial x_{m}} \\\frac{\partial y_2}{\partial x_{1}} & \frac{\partial y_2}{\partial x_{2}} & \cdots & \frac{\partial y_2}{\partial x_{m}} \\\vdots & \vdots & \ddots & \vdots \\\frac{\partial y_n}{\partial x_{1}} & \frac{\partial y_n}{\partial x_{2}} & \cdots & \frac{\partial y_n}{\partial x_{m}}\end{bmatrix}</script><p>右边的那个方阵，就是传说中的雅各比矩阵。</p><p>我们在“规律”这一节探讨的求导矩阵的形状问题，其实核心就在于求导矩阵的形状，可以在链式法则中直接应用，而不需要经过大量的 reshape。</p><p>那如果 $X$ 和 $Y$ 有任一方是一个矩阵怎么办？可以想见，此时的雅各比矩阵就不再是二维的了，而是三维张量或者四维张量了。此时就很难整理成矩阵乘法的形式了，但是分量求和公式依然成立。</p><p>而在 ML 实践中，常常因为有些 $\frac{\partial z}{\partial y_k}\frac{\partial y_k}{\partial x_i}$ 项为零，进而可以简化高维张量运算。</p><p>我们来举个例子，以 ML 中常见的全连接层 $Y = WX$ 为例（省略了偏置量 $B$），其中 $X$ 是 $N$ 维向量，$Y$ 是 $M$ 维向量，$W$ 是 $M \times N$ 维矩阵。那么在反向传播中，就有：</p><script type="math/tex; mode=display">\frac{\partial Y}{\partial W} = \begin{bmatrix}\begin{bmatrix}\frac{\partial y_1}{\partial w_{11}} & \frac{\partial y_1}{\partial w_{12}} & \cdots & \frac{\partial y_1}{\partial w_{1n}} \\\frac{\partial y_1}{\partial w_{21}} & \frac{\partial y_1}{\partial w_{22}} & \cdots & \frac{\partial y_1}{\partial w_{2n}} \\\vdots & \vdots & \ddots & \vdots \\\frac{\partial y_1}{\partial w_{m1}} & \frac{\partial y_1}{\partial w_{m2}} & \cdots & \frac{\partial y_1}{\partial w_{mn}}\end{bmatrix} \\\begin{bmatrix}\frac{\partial y_2}{\partial w_{11}} & \frac{\partial y_2}{\partial w_{12}} & \cdots & \frac{\partial y_2}{\partial w_{1n}} \\\frac{\partial y_2}{\partial w_{21}} & \frac{\partial y_2}{\partial w_{22}} & \cdots & \frac{\partial y_2}{\partial w_{2n}} \\\vdots & \vdots & \ddots & \vdots \\\frac{\partial y_2}{\partial w_{m1}} & \frac{\partial y_2}{\partial w_{m2}} & \cdots & \frac{\partial y_2}{\partial w_{mn}}\end{bmatrix}\\\vdots\\\begin{bmatrix}\frac{\partial y_n}{\partial w_{11}} & \frac{\partial y_n}{\partial w_{12}} & \cdots & \frac{\partial y_n}{\partial w_{1n}} \\\frac{\partial y_n}{\partial w_{21}} & \frac{\partial y_n}{\partial w_{22}} & \cdots & \frac{\partial y_n}{\partial w_{2n}} \\\vdots & \vdots & \ddots & \vdots \\\frac{\partial y_n}{\partial w_{m1}} & \frac{\partial y_n}{\partial w_{m2}} & \cdots & \frac{\partial y_n}{\partial w_{mn}}\end{bmatrix}\end{bmatrix}</script><p>这个式子看着就非常恐怖，再进行矩阵运算不得活活难死（其实还好），但是我们注意到对于任意分量 $y_i$ ，它等于：</p><script type="math/tex; mode=display">y_i = \sum_{j = 0}^N w_{ij} x_j</script><p>也就是说，对于特定的 $i$， $y_i$ 不和 $W$ 的所有分量有关，而是只跟 $W$ 第 $i$ 行分量有关，也就是：</p><script type="math/tex; mode=display">\frac{\partial Y}{\partial W} = \begin{bmatrix}\begin{bmatrix}\frac{\partial y_1}{\partial w_{11}} & \frac{\partial y_1}{\partial w_{12}} & \cdots & \frac{\partial y_1}{\partial w_{1n}} \\0 & 0 & \cdots & 0 \\\vdots & \vdots & \ddots & \vdots \\0 & 0 & \cdots & 0 \\\end{bmatrix} \\\begin{bmatrix}0 & 0 & \cdots & 0 \\\frac{\partial y_2}{\partial w_{21}} & \frac{\partial y_2}{\partial w_{22}} & \cdots & \frac{\partial y_2}{\partial w_{2n}} \\\vdots & \vdots & \ddots & \vdots \\0 & 0 & \cdots & 0 \\\end{bmatrix}\\\vdots\\\begin{bmatrix}0 & 0 & \cdots & 0 \\0 & 0 & \cdots & 0 \\\vdots & \vdots & \ddots & \vdots \\\frac{\partial y_n}{\partial w_{m1}} & \frac{\partial y_n}{\partial w_{m2}} & \cdots & \frac{\partial y_n}{\partial w_{mn}}\end{bmatrix}\end{bmatrix}=\begin{bmatrix}\begin{bmatrix}x_1 & x_2 & \cdots & x_n \\0 & 0 & \cdots & 0 \\\vdots & \vdots & \ddots & \vdots \\0 & 0 & \cdots & 0 \\\end{bmatrix} \\\begin{bmatrix}0 & 0 & \cdots & 0 \\x_1 & x_2 & \cdots & x_n \\\vdots & \vdots & \ddots & \vdots \\0 & 0 & \cdots & 0 \\\end{bmatrix}\\\vdots\\\begin{bmatrix}0 & 0 & \cdots & 0 \\0 & 0 & \cdots & 0 \\\vdots & \vdots & \ddots & \vdots \\x_1 & x_2 & \cdots & x_n \\\end{bmatrix}\end{bmatrix}</script><p>其实我们都没有必要再关注这个复杂的 $\frac{\partial Y}{\partial W}$ 的稀疏性质了，我们直接回归本源，我们的核心目的是求解损失函数 $l$ 对 $W$ 的导数，那么按照原本来说，有：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial w_{ij}} = \sum_{k = 0}^M \frac{\partial l}{\partial y_k} \frac{\partial y_k}{\partial w_{ij}}</script><p>又因为在 $i,j$ 确定的情况下， $w_{ij}$ 只会影响 $Y$ 的 $y_i$ 分量，所以上面这个式子就会变化成：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial w_{ij}} = \sum_{k = 0}^M \frac{\partial l}{\partial y_k} \frac{\partial y_k}{\partial w_{ij}} = \frac{\partial l}{\partial y_i}\frac{\partial y_i}{\partial w_{ij}} = \frac{\partial l}{\partial y_i}x_j</script><p>有了这样的化简后，就可以被整理成新的向量乘法，如下所示：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial W} = \frac{\partial l}{\partial Y} X^T</script><p>再次变得简洁优雅。</p><p>这件事情很启发我，我之前学习反向传播时，太关注复杂的神经网络的梯度的张量表示了，动不动就会出现三维或者四维的张量，然后陷入停滞。而实际上，就算在数学上产生了这些拦路虎，我们也并不在意，因为这些高维张量本来就不是我们的目的，它只是链式求和公式的一种形式。我们会重新回到链式求和公式，来构建更加简单的矩阵乘法，而不是固守高维张量。</p><h4 id="2-1-3-标量-张量"><a href="#2-1-3-标量-张量" class="headerlink" title="2.1.3 标量-张量"></a>2.1.3 标量-张量</h4><p>标量对张量进行求导时，生成的导数矩阵和张量（无论张量是标量、向量还是矩阵）的形状完全相同。比如说对于一个 $N$ 维列向量 $X$ ，其导数矩阵如下所示：</p><script type="math/tex; mode=display">\frac{\partial y}{\partial \mathbf{X}} = \begin{bmatrix}\frac{\partial y}{\partial x_1} \\\frac{\partial y}{\partial x_2} \\\vdots \\\frac{\partial y}{\partial x_n}\end{bmatrix}</script><p>而对于 $M \times N$ 维的矩阵求导，其形式也是类似的：</p><script type="math/tex; mode=display">\frac{\partial y}{\partial \mathbf{X}} = \begin{bmatrix}\frac{\partial y}{\partial x_{11}} & \frac{\partial y}{\partial x_{12}} & \cdots & \frac{\partial y}{\partial x_{1n}} \\\frac{\partial y}{\partial x_{21}} & \frac{\partial y}{\partial x_{22}} & \cdots & \frac{\partial y}{\partial x_{2n}} \\\vdots & \vdots & \ddots & \vdots \\\frac{\partial y}{\partial x_{m1}} & \frac{\partial y}{\partial x_{m2}} & \cdots & \frac{\partial y}{\partial x_{mn}}\end{bmatrix}</script><h4 id="2-1-4-张量-张量"><a href="#2-1-4-张量-张量" class="headerlink" title="2.1.4 张量-张量"></a>2.1.4 张量-张量</h4><p>当因变量是张量的时候，就是对于因变量张量的每一个分量都应用一遍上文介绍的“标量-张量”方法。因变量分量会组成导数张量的外层维度，每个元素都是一个“标量-张量”导数矩阵。我们举个例子，有 $2 \times 3$ 维的向量 $X$ 和 $3 \times 2$ 维的 $Y$ 相乘得到 $2 \times 2$ 维的 $Z$ ，对于 $\frac{\partial Z}{\partial X}$ 有：</p><script type="math/tex; mode=display">\frac{\partial Z}{\partial X} =\begin{bmatrix}\frac{\partial z_{11}}{\partial X} & \frac{\partial z_{12}}{\partial X} \\\frac{\partial z_{21}}{\partial X} & \frac{\partial z_{22}}{\partial X} \\\end{bmatrix}=\begin{bmatrix}\begin{bmatrix}\frac{\partial z_{11}}{\partial x_{11}} & \frac{\partial z_{11}}{\partial x_{12}} & \frac{\partial z_{11}}{\partial x_{13}} \\\frac{\partial z_{11}}{\partial x_{21}} & \frac{\partial z_{11}}{\partial x_{22}} & \frac{\partial z_{11}}{\partial x_{23}} \\\end{bmatrix}& \begin{bmatrix}\frac{\partial z_{12}}{\partial x_{11}} & \frac{\partial z_{12}}{\partial x_{12}} & \frac{\partial z_{12}}{\partial x_{13}} \\\frac{\partial z_{12}}{\partial x_{21}} & \frac{\partial z_{21}}{\partial x_{22}} & \frac{\partial z_{21}}{\partial x_{23}} \\\end{bmatrix}\\\begin{bmatrix}\frac{\partial z_{21}}{\partial x_{11}} & \frac{\partial z_{21}}{\partial x_{12}} & \frac{\partial z_{21}}{\partial x_{13}} \\\frac{\partial z_{21}}{\partial x_{21}} & \frac{\partial z_{21}}{\partial x_{22}} & \frac{\partial z_{21}}{\partial x_{23}} \\\end{bmatrix}& \begin{bmatrix}\frac{\partial z_{22}}{\partial x_{11}} & \frac{\partial z_{22}}{\partial x_{12}} & \frac{\partial z_{22}}{\partial x_{13}} \\\frac{\partial z_{22}}{\partial x_{21}} & \frac{\partial z_{22}}{\partial x_{22}} & \frac{\partial z_{22}}{\partial x_{23}} \\\end{bmatrix}\end{bmatrix}</script><p>可以看到最后形成了四维 $2 \times 2 \times 2 \times 3$ 的导数矩阵。</p><p>如果我们考虑“向量-向量”这种特殊形式的求导，就会生成著名的雅可比矩阵（Jacobian Matrix）。考虑 $M$ 维 $Y$ 向量对 $N$ 维 $X$ 向量求导，有：</p><script type="math/tex; mode=display">J = \frac{\partial \mathbf{Y}}{\partial \mathbf{X}} =\begin{bmatrix}\frac{\partial y_1}{\partial x_1} & \frac{\partial y_1}{\partial x_2} & \cdots & \frac{\partial y_1}{\partial x_n} \\\frac{\partial y_2}{\partial x_1} & \frac{\partial y_2}{\partial x_2} & \cdots & \frac{\partial y_2}{\partial x_n} \\\vdots & \vdots & \ddots & \vdots \\\frac{\partial y_m}{\partial x_1} & \frac{\partial y_m}{\partial x_2} & \cdots & \frac{\partial y_m}{\partial x_n}\end{bmatrix}</script><p>这里列出的方阵，横轴是 $x$ 分量，而纵轴是 $y$ 分量。我个人觉得只要保证链式法则的基本要求，似乎转置一下也没有大关系，矩阵形状和矩阵乘法，只不过是一种简写的方式。</p><p>在 ML 中因为向量值函数很常见，所以经常可能会出现高维度张量，它们似乎就无法被擅长矩阵这种低维张量计算的 GPU 或者加速器中处理了，而实际上，正如“链式法则”这一章节中提到的，我们很少真正计算高维度张量。</p><h4 id="2-1-5-实例"><a href="#2-1-5-实例" class="headerlink" title="2.1.5 实例"></a>2.1.5 实例</h4><p>最后放一张 MLP 的图来总结一下反向传播过程中的链式求导和常见导数：</p><p><img src="/posts/7dc4ea13/1jt_OvqvfWkvuSUau4BPVWQ.png" alt="img"></p><h3 id="2-2-FLOPS"><a href="#2-2-FLOPS" class="headerlink" title="2.2 FLOPS"></a>2.2 FLOPS</h3><h4 id="2-2-1-GEMM"><a href="#2-2-1-GEMM" class="headerlink" title="2.2.1 GEMM"></a>2.2.1 GEMM</h4><p>GEMM 即 General Matrix Multiply ，就是最为常见的矩阵乘法操作。</p><p>对于一个 $M \times K$ 的矩阵与一个 $K \times N$ 的矩阵进行 GEMM 运算，FLOPS 是 $2 MNK$ 。</p><p>这是因为结果矩阵中有 $MN$ 个元素，而每个元素都是一个 $K$ 维行向量和一个 $K$ 维列向量的点积结果。而点积需要进行 $K$ 次乘法操作和 $K - 1$ 次加法操作，故总共需要约 $2K$ 次操作（其实我觉得这里存疑，因为如果是 MAC，Multi-Add 的话，其实点积只需要 $K$ 次操作）。进而 GEMM 需要 $2MNK$ 次操作。 </p><p>总之在 GEMM 中，FLOPS 分别是 3 个维度的一次函数。</p><h4 id="2-2-2-损失函数"><a href="#2-2-2-损失函数" class="headerlink" title="2.2.2 损失函数"></a>2.2.2 损失函数</h4><p>在神经网络中的最后一层，往往输出一个 $N$ 维向量 $Z$ ，我们需要根据向量 $Z$ 来计算损失函数 $l$ ，我们考虑一种最常见的损失函数：</p><script type="math/tex; mode=display">l = \sum^{N}_{i = 1} (z_i - t)^2</script><p>其中 $t$ 是目标期望值，那么就有：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial Z} = 2(Z - T)</script><p>其中 $T$ 是一个每个分量均为 $t$ 的 $N$ 维向量。因为要进行 $N$ 次元素操作，此时的 FLOPS 就是 $N$ 。</p><h4 id="2-2-3-隐藏层"><a href="#2-2-3-隐藏层" class="headerlink" title="2.2.3 隐藏层"></a>2.2.3 隐藏层</h4><p>我们首先定义一下隐藏层，首先我们有一个 $N$ 维的输入向量 $I$ ，他会先经过线性变换变成一个 $M$ 维向量 $Y$ ，如下所示：</p><script type="math/tex; mode=display">Y = WI + B</script><p> 然后经过激活函数 $\sigma(Y)$ 的元素变化进行激活，有：</p><script type="math/tex; mode=display">\sigma(y_i) = \frac{1}{1 + e^{-x}}</script><p>我们记录 $M$ 维向量 $O$ 为激活后的值，即：</p><script type="math/tex; mode=display">O = \sigma(Y)</script><p>我们首先计算正向传播一个向量的 FLOPS。在计算 $Y$ 这个步骤的 FLOPS 是 $2NM$ ，计算 $O$ 这个步骤是 $M$ ，所以总体的 FLOPS 就是 $2NM + M$  （常数凑活看吧，领会精神）。</p><p>然后我们计算反向传播一个向量的 FLOPS。我们还需要定义一些其他辅助计算的符号。反向传播是遵循链式法则的，所以我们在计算当前层时，一定已经有了后面一个隐藏层输入的梯度，而后一个隐藏层的输入就是当前隐藏层的输出，也就是说，我们已知 $\frac{\partial l}{\partial O}$ 的值了。</p><p>在这个反向传播的过程中，我们希望求解参数的梯度 $\frac{\partial l}{\partial W}, \frac{\partial l}{\partial B}$ ，此外，我们还需要求解 $\frac{\partial l}{\partial I}$ ，虽然这个值和当前层的参数更新没有关系，但是上一层的反向传播的参数梯度，需要 $\frac{\partial l}{\partial I}$ ，正如我们需要  $\frac{\partial l}{\partial O}$ 一样。</p><p>首先我们计算激活值的梯度，有</p><script type="math/tex; mode=display">\frac{\partial l}{\partial Y} = \frac{\partial l}{\partial O} \frac{\partial O}{\partial Y}</script><p>又因为有：</p><script type="math/tex; mode=display">\sigma'(x) = \sigma(x) \cdot (1 - \sigma(x))</script><p>所以有：</p><script type="math/tex; mode=display">\frac{\partial O}{\partial Y} = \begin{bmatrix}o_1 (1 - o_1) \\o_2 (1 - o_2) \\\cdots \\o_m (1 - o_m)\end{bmatrix}</script><p>计算 $\frac{\partial l}{\partial Y}$ 的过程总 FLOPS 是 $2M$ ，先计算出 $\frac{\partial O}{\partial Y}$ 的 FLOPS 是 $M$ ，然后 $\frac{\partial l}{\partial O}$ 和 $\frac{\partial O}{\partial Y}$ 对应元素相乘，FLOPS 是 $M$ 。</p><p>然后我们计算权重矩阵的梯度，有：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial W} = \frac{\partial l}{\partial Y} \frac{\partial Y}{\partial W}</script><p>按理说 $\frac{\partial Y}{\partial W}$ 是一个三维张量，比较难处理，但是又因为线性变换的特性（在“链式规则”处证明），有：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial W} = \frac{\partial l}{\partial Y} I^T</script><p>因为 $\frac{\partial l}{\partial Y}$ 是 $M$ 维， $I$ 是 $N$ 维，所以总 FLOPS 是 $MN$ （没有加法过程，所以没有常数 $2$）。但是如果还要考虑用 $\frac{\partial l}{\partial W}$ 来修正 $W$ ，那么总 FLOPS 就是 $2MN$ 。</p><p>然后我们计算偏置量的梯度，有：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial B} = \frac{\partial l}{\partial Y} \frac{\partial Y}{\partial B}</script><p>又因为：</p><script type="math/tex; mode=display">\frac{\partial Y}{\partial B} =\begin{bmatrix}1 \\1 \\\cdots \\1\end{bmatrix}</script><p>所以：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial B} = \frac{\partial l}{\partial Y}</script><p>FLOPS 直接可忽略，如果算上更新 $B$ ，那么 FLOPS 是 $N$ 。</p><p>最后我们还需要计算 $\frac{\partial l}{\partial I}$ ，有：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial I} = \frac{\partial l}{\partial Y} \frac{\partial Y}{\partial I}</script><p>又因为：</p><script type="math/tex; mode=display">\frac{\partial Y}{\partial I} = W^T</script><p>所以总的 FLOPS 是一次 $M$ 维向量与 $M \times N$ 维矩阵乘法的 FLOPS，也就是 $2MN$ 。</p><p>所以总得来看，反向传播的 FLOPS 是 $4MN$ 左右，但是这个值很没有意义，只是说，它的量值依然是正比于输入维度 $N$ 和输出维度 $M$ 。</p><h4 id="2-2-4-Attention"><a href="#2-2-4-Attention" class="headerlink" title="2.2.4 Attention"></a>2.2.4 Attention</h4><p>Softmax 是一个独特的元素映射函数，这里记录一下它的梯度函数。设 softmax 的输入是一个 $N$ 维向量 $Z$ ，输出是一个 $N$ 维向量 $P$ ，有：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial Z} = \frac{\partial l}{\partial P} \frac{\partial P}{\partial Z}</script><p>其中 $\frac{\partial P}{\partial Z}$ 是一个 $N \times N$ 维的雅克比矩阵。有如下定理，当 $i = j$ 时：</p><script type="math/tex; mode=display">\frac{\partial p_{i}}{\partial z_j} = p_i(1 - p_i)</script><p>当 $i \ne j$ 时：</p><script type="math/tex; mode=display">\frac{\partial p_{i}}{\partial z_j} = -p_ip_j</script><p>那么这里的反向传播的本质也是一个矩阵与向量乘法，FLOPS 大约是 $N^2$ 。</p><p>而 Attention 的其他部分用到了在隐藏层中没有出现过的矩阵乘法，比如说 $QK^T$ 计算，看似会产生四维张量，实际上和线性变换类似，非常直观，设：</p><script type="math/tex; mode=display">S = \frac{QK^T}{\sqrt{d_k}}</script><p>有：</p><script type="math/tex; mode=display">\frac{\partial l}{\partial Q} = \frac{\partial l}{\partial S} \frac{\partial S}{\partial Q} = \frac{1}{\sqrt{d_k}} \frac{\partial l}{\partial S} K \\\frac{\partial l}{\partial K} = \frac{\partial l}{\partial S} \frac{\partial S}{\partial K} = \frac{1}{\sqrt{d_k}} \frac{\partial l}{\partial S} Q</script><p>因此依然是矩阵与向量乘法的 FLOPS，FLOPS 是 $Q,K$ 维度的乘积，也就是 $seq_len \times d_{k}$ 。</p><h3 id="2-3-Im2Col"><a href="#2-3-Im2Col" class="headerlink" title="2.3 Im2Col"></a>2.3 Im2Col</h3><p>IM2Col 的意思是 Image To Column，本质是将卷积计算转换成矩阵乘法，然后因为矩阵乘法已经被优化得很好了，所以可以加速计算。如下所示：</p><p><img src="/posts/7dc4ea13/image-20250202175313184.png" alt="image-20250202175313184"></p><p>但是这种方式并不从理论上减少计算的复杂度，只是比较简单实现，并且效果较好。此外 FFT 也可以用于加速卷积计算，并且是理论上加速。</p><hr><h2 id="三、Transformer"><a href="#三、Transformer" class="headerlink" title="三、Transformer"></a>三、Transformer</h2><h3 id="3-1-Embedding"><a href="#3-1-Embedding" class="headerlink" title="3.1 Embedding"></a>3.1 Embedding</h3><p>我们都知道人工神经网络中每一层的神经网络都可以对前一层输入进行一次矩阵运算（如果刨除激活不算的话），从线性代数的知识可知，这其实是在做一次空间映射，如果矩阵是 $M \times N$ 的，那么每经过一层，就是将一个原本在 $M$ 维空间向量映射到一个 $N$ 维的空间中。</p><p>人工神经网络的原理是将一段数据先 tokenize ，也就是将原本的字符串之类（比如我们和 chatgpt 说的话）的东西转换成一组一维的向量，每个标量被称为一个 token ，然后将他们映射到一个向量空间中，这个过程叫做“嵌入”（embedding），然后就是对于这个向量的一次次映射。</p><p>那么我们这样做的直观理解是什么，我觉得是这样的，人工神经网络是在描述语义。说白了，就是通过构建一个语义空间的方式去掌握各个 token 的语义，语义空间就是一个多维向量空间。那么为什么一个多维向量空间就可以描述语义呢？因为多维向量空间中存在距离，我们可以用距离的方式来描述两个 token 的相似性，而这就构成了语义。比如在一个空间中，当我们观测到“苹果，梨，香蕉”的距离很近，那么可能就是因为她们都具有水果的语义。</p><p>语义空间的设计有两个极端，一个是一维标量，另一个是独热码。如果用一维标量的话，有些复杂的语义没有办法表示，比如说“苹果”，它既有“水果”的意思，又有“电子品牌”的意思，那么它应该既和“香蕉”离得近，又和“三星”离得近，但是“香蕉”和“三星”不应该离那么近。而独热码则是尽可能的扩大自己的维度，并只使用一个维度，那么我们很难表示出相近的含义，因为独热码的所有点的距离都是相同的。</p><p>Embedding 的维度通常被称为 $d_{model}$ 。</p><p>此外，为了将位置信息（Position），也就是当前 token 在序列中的位置考虑在内，我们还要经过一个位置编码（Position Encoding）的过程，说白了就是将位置编码进去，非常显然。</p><h3 id="3-2-Attention"><a href="#3-2-Attention" class="headerlink" title="3.2 Attention"></a>3.2 Attention</h3><p>Transformer 最初开发出来被用于进行机器翻译，其中最有特色的点就在于使用了 Attention 机制。为了理解 Attention 机制，有必要了解一下在 Transformer 提出之前，人们是怎样进行机器翻译的。</p><p>我最初的理解是，机器翻译就是存着一个字典，然后一个词一个词的翻译就够了（也就是只进行依次 embedding 和逆向 embedding 的过程）。但是仔细一想就不太可能，这是因为不同语言之间并不是只需要逐词翻译，因为语法的不同，导致不同语言的上下文顺序也是不同的。所以人们最先设计出的机器翻译机制，是让每个句子对应一个向量，被称作 Context Vector，在翻译的时候，先用神经网络将句子编码成 Context Vector，然后再用神经网络解码成另一门语言的句子，如下图所示：</p><p><img src="/posts/7dc4ea13/image-20250202211138372.png" alt="image-20250202211138372"></p><p>至于为什么要使用 RNN，将 token 一个个喂入神经网络，而不是一股脑将整个句子当作输入一口气喂进去。是因为翻译的难点在于理解上下文，RNN 可以更好的发现序列之间的关系。</p><p>但是这种方式也存在缺点，那就是 context vector 的维度是有限的，而句子的量级显然不是 context vector 所能容纳的，所以这种方法的效果并不好，而如果我们减小句子的范围，那么就又不利于长上下文的理解。此外，这个方法的并行度也非常差，是串行输入每一个 token 。</p><p>Attention 机制就是解决这个问题的。它的最本质思想是，上下文关系如果存储在隐藏层或者 context vector 中，很容易受到维度的限制，那么我们就专门用一个方阵 $A$ ，用 $a_{ij}$ 记录第 $i$ 个 token 和第 $j$ 个 token 之间的联系，根据这个方阵再结合每个 token 的语义，来确定输出。</p><p>那么 Attention 具体是怎样的呢？首先我们需要先介绍 Attention 的输入。经过 Embedding 过程，每个 token 都是一个 $1 \times d_{model}$ 维的行向量。</p><p>我们设序列长度为 $t$ ，那么输入可以被整理成一个 $t \times d_{model}$ 的矩阵 $X$。</p><p>那么我们如何获得 $A$ 呢（学名叫作 $Attention \space Score$）？很简单，我们可以用向量内积的思想，如果两个向量的内积很大，就说明两个向量离得很近，因为如果二者夹角很小的话，那么内积就会增大。虽然这并不严谨，但是这基本上就是它的思想了。于是我们有了：</p><script type="math/tex; mode=display">A = XX^T</script><p>也就是说有：</p><script type="math/tex; mode=display">a_{ij} = x_i x_j^T</script><p>所以 $a_{ij}$ 就可以表示第 $i$ 个 token 和第 $j$ 个 token 之间的相似度。$A$ 是一个 $t \times t$ 的方阵。</p><p>当然在有了 $A$ 并不够，我们只是获得了不同 token 之间的联系，但是我们并没有考虑原本 token 的语义，所以我们再将 $A$ 与 $X$ 相乘，那么就可以得到一个新的 $t \times d_{model}$ 的矩阵 $Y$ ，如下所示：</p><script type="math/tex; mode=display">Y = AX = XX^TX</script><p>我们将 $Y$ 视为多个 token 的集合，那么对于第 $i$ 个 token，也就是第 $i$ 行的行向量，有：</p><script type="math/tex; mode=display">Y_i = \sum^t_{j = 0} a_{ij} X_j</script><p>现在让我们重新回顾这个模型，我们的输入是一个含有 $t$ 个 token 的集合 $X$ ，输出依然是含有 $t$ 个 token 的集合 $Y$ 。此时 $Y$ 中的每个 token，都是 $X$ 中所有 token 的语义的加权和，权重是 $X$ 中对应的 token 与其他剩余 token 的相关性。在 $X$ 中每个 token 的语义都是独立的（每个 token 单独进入网络层），经过 Attention 机制后，具有相似语义的 token 会互相影响，此时 $Y$ 中的每个 token 都是携带上下文信息的。</p><p>下面举个例子，有 $d_{model} = 4, t = 6$ ，如下所示： </p><p><img src="/posts/7dc4ea13/attention1.drawio.png" alt=""></p><p>这里我有一个有趣的思考，就是并不是所有的模型都可以随着规模增大而性能更好。比如说 RNN 相比于传统的多层感知机，就可以有更多的层数，这是因为 RNN 削弱因层数增多而导致的“梯度消失”现象。但是正如前所述，虽然 RNN 避免了“梯度消失”，但是过于串行化的算法和较低的状态维度（我觉得这点可能可以改进），导致我们无法进一步扩大模型规模。而基于 Attention 机制的 Transformer 模型则有更好的可拓展性，并行化程度高，所以才能在更大规模时有更加智能的表现。</p><h3 id="3-3-Cross-Attention"><a href="#3-3-Cross-Attention" class="headerlink" title="3.3 Cross-Attention"></a>3.3 Cross-Attention</h3><p>上文介绍的 Attention 机制和”Attention is All you Need“这篇论文中的并不太一样，这是因为我在上面只是介绍了最为基础的 Attention 原理，在下文中我会进一步拓展这个机制。</p><p>首先我们注意到，上文中计算 $Y$ 的公式，只有一个输入 $X$ ，如下所示：</p><script type="math/tex; mode=display">Y = XX^TX</script><p>那么这里面的 $X$ 的含义都一样吗？其实并不应该一样，还是以机器翻译来举例，如果输入只有一个 $X$ ，那么谈什么翻译呢？如果希望将中文翻译成英语，怎么也得有 3 个输入，也就是：</p><ul><li>待翻译的中文</li><li>中译英字典（语料库）的索引</li><li>中译英字典（语料库）的内容</li></ul><p>Attention 机制是可以满足这 3 种输入的，正好 $Y$ 的表达式中有 3 个 $X$ ，他们可以被差异化成如下公式：</p><script type="math/tex; mode=display">Y = AV = QK^TV</script><p>此时各个字符的含义如下：</p><ul><li><p>$Q$：Query，即要翻译的中文语句，它的形状是 $t_{sen} \times d_{in}$ 。</p><ul><li>$t_{sen}$ 被理解成语句的长度。</li><li>$d_{in}$ 是表示一个中文 token 语义所需的分量个数。</li></ul></li><li><p>$K$：Key，即中译英字典（语料库）的索引，它的形状是 $t_{all} \times d_{in}$ 。</p><ul><li>$t_{all}$ 可以被理解成所有中文语料的个数。</li></ul></li><li><p>$A$：Attention Score，依然是相关性分数，它的形状是 $t_{sen} \times t_{all}$ 。</p><ul><li>分量 $a_{ij}$ 表示待翻译的中文语句中的第 $i$ 个 token 和语料库中的第 $j$ 个语料的相关性。这很合理，我们查字典的过程，不就是根据待翻译的中文语句中的字，来查询对应的英文吗？</li><li>Attention 对应的就是”查字典“这个过程，只不过”查字典“可以查到准确的单词，而在复杂的翻译过程中，只能查询到与 token 语义相近的语料。</li></ul></li><li><p>$V$：Value，即中译英字典（语料库）的内容，它的形状是 $t_{all} \times d_{out}$ 。</p><ul><li>$d_{out}$ 是表示一个英文 token 语义所需的分量个数。</li></ul></li><li><p>$Y$：Output，即翻译好的英文语句，它的形状是 $t_{sen} \times d_{out}$ 。</p><ul><li>它的每个行向量都是一个英文的 token。</li><li>它是 $A$ 和 $V$ 的乘积，也就是每个英文的 token，都是中译英语料库中以相关性为权重形成的加权和。</li></ul></li></ul><p>上面这个中译英的例子可能还不是那么直观，具体的例子很难举，因为语言和数字的对应还是有些难度的。我们举另一个例子，我们进行一个”成绩-能力“的翻译。也就是我们有上一届同学的考试成绩，还有他们的学习能力，我们希望根据当前这届同学的成绩，来推测他们的学习能力是怎样的，完成一个从”成绩“到”能力“的翻译。</p><p>考试一共有”数学“和”语文“ 2 个科目，成绩是 5 分制。学习能力一共有”记忆“、”创新“和”勤奋“ 3 种。数据都是我瞎编的，勿杠。</p><p>当前这届同学的成绩就构成了 $K$ 矩阵，其中：</p><ul><li>$t_{sen}$ 为 2，表示这届两名同学 s1 和 s2</li><li>$d_{in}$ 为 2，表示 2 门考试科目。</li></ul><p>$K$ 如下所示：</p><div class="table-container"><table><thead><tr><th></th><th>数学</th><th>语文</th></tr></thead><tbody><tr><td>s1</td><td>5</td><td>2</td></tr><tr><td>s2</td><td>1</td><td>5</td></tr></tbody></table></div><p>往届同学的成绩构成了 $Q$ 矩阵，其中 $t_{all}$ 为 3，表示前一届的 3 名同学 s3, s4 和 s5 。$Q$ 如下所示：</p><div class="table-container"><table><thead><tr><th></th><th>数学</th><th>语文</th></tr></thead><tbody><tr><td>s3</td><td>2</td><td>5</td></tr><tr><td>s4</td><td>4</td><td>1</td></tr><tr><td>s5</td><td>3</td><td>3</td></tr></tbody></table></div><p>又因为 $A = QK^T$ ，如下所示：</p><div class="table-container"><table><thead><tr><th></th><th>s3</th><th>s4</th><th>s5</th></tr></thead><tbody><tr><td>s1</td><td>20</td><td>22</td><td>21</td></tr><tr><td>s2</td><td>27</td><td>9</td><td>20</td></tr></tbody></table></div><p> 可以看到非常合理，s1 擅长数学而不擅长语文，s4 也是如此，所以在 3 名往届学生中，s4 和 s1 最像，相关性也是最高的（22）。s2 擅长语文而不擅长数学，与 s3 最为相似，可以看到相关性也很高（27）。</p><p>往届同学的能力构成了 $V$ 矩阵，其中 $d_{out}$ 为 3，对应 3 种能力，如下所示：</p><div class="table-container"><table><thead><tr><th></th><th>记忆</th><th>创新</th><th>勤劳</th></tr></thead><tbody><tr><td>s3</td><td>15</td><td>6</td><td>7</td></tr><tr><td>s4</td><td>3</td><td>12</td><td>5</td></tr><tr><td>s5</td><td>9</td><td>9</td><td>6</td></tr></tbody></table></div><p>在我编的这个情景下，”记忆“越好，”语文“成绩就越高；”创新“越好，”数学“成绩就越高；”勤劳“越好，总成绩就越高。可以看到基本上都是合理的，比如 s3 擅长语文，它的”记忆“能力就比”创新“能力好。</p><p>然后我们用 $Y = AV$ 来看看当前这届同学的能力，有：</p><div class="table-container"><table><thead><tr><th></th><th>记忆</th><th>创新</th><th>勤劳</th></tr></thead><tbody><tr><td>s1</td><td>555</td><td>573</td><td>376</td></tr><tr><td>s2</td><td>612</td><td>450</td><td>354</td></tr></tbody></table></div><p>可以看到基本上还是合理的（当然我们也不能指望着只有 3 个数据的数据集有多准确）。s1 的数学成绩很高而语文成绩很差，按理说他的“创新”能力应该是高于“记忆”能力的；s2 的语文成绩很高而数学成绩很差，按理说他的“记忆”能力是高于“创新”能力的。这些推理都被 $Y$ 体现了。</p><p>当然 $Y$ 也存在两个问题：</p><ul><li>能力绝对值过大了，在 $V$ 矩阵中能力值都是两位数，而在 $Y$ 中都是 3 位数，很夸张。</li><li>能力相对值不明显，以 s1 同学为例，明明“数学”成绩比“语文”成绩高 3 分，但是“记忆”能力和“创新”能力却相差不大。</li></ul><p>第一个问题主要是因为 $A$ 矩阵没有按行归一化导致的，按理说加权和里的权重应该是一个“百分比”，而我们没有归一化，所以绝对值会偏大。而第二个问题是因为在数据集中，只有 s4 一个同学和 s1 一样是“数学比语文高”，而且 s4 还不如 s1 成绩好，所以 s1 的能力很容易被 s3 和 s5 的数据干扰，如果有办法让与 s1 更相似的同学（也就是 s4）相比于不相似的同学更突出。</p><p>上述两个问题都可以使用 $softmax$ 来改善，这是一个作用于向量的向量函数，如下所示：</p><script type="math/tex; mode=display">\sigma(\mathbf{z})_i = \frac{e^{z_i}}{\sum_{j=1}^{n} e^{z_j}}</script><p>可以看到这是一个归一化函数，所以解决了第一个问题。而 $softmax$ 中使用的指数函数，使得相关性高的分量变得更加明显，所以解决了第二个问题。</p><p>我们用 $softmax$ 来修正 $A$ ，$softmax$ 对矩阵作用，本质就是对矩阵中的每一个行向量作用，修正后的 $A$ 如下所示：</p><div class="table-container"><table><thead><tr><th></th><th>s3</th><th>s4</th><th>s5</th></tr></thead><tbody><tr><td>s1</td><td>0.09</td><td>0.67</td><td>0.24</td></tr><tr><td>s2</td><td>0.99</td><td>0</td><td>0</td></tr></tbody></table></div><p>可以看到这时的相关性非常完美，按照修正后的 $A$ 计算修正后的 $Y$：</p><div class="table-container"><table><thead><tr><th></th><th>记忆</th><th>创新</th><th>勤劳</th></tr></thead><tbody><tr><td>s1</td><td>5.5</td><td>10.7</td><td>5.4</td></tr><tr><td>s2</td><td>15.0</td><td>6.0</td><td>7.0</td></tr></tbody></table></div><p>可以看到非常合理。</p><p>此外，$A$ 还有一个问题，就是当 $d_{in}$ 过大时， $QK^T$ 很容易产生数值很大的分量。</p><p>所以在实践上，我们需要对每个分量除以 $\sqrt{d_{in}}$ 来避免数据的溢出，这个过程被称为 scale。</p><p>综上所述，我们得出了一个和最终版本非常像的算子，如下所示：</p><script type="math/tex; mode=display">Y = softmax(\frac{QK^T}{\sqrt{d_{in}}})V</script><p>当 $Q, K, V$ 来源不相同时，我们称之为 Cross-Attention，即交叉注意力机制，常用于机器翻译。而当 $Q, K, V$ 来源相同时，则被称为 Self-Attention 机制，常用于发现上下文联系，理解或者产生新的语义。</p><p>我们看一下 Transformer 的架构图：</p><p><img src="/posts/7dc4ea13/image-20250204155327984.png" alt="image-20250204155327984"></p><p>我们以“中译英”来距离， <code>inputs</code> 就是要中译英的语料库，<code>outputs</code> 刚开始就是要翻译的中文 ，<code>output probabilities</code> 是翻译好的英文（之所以叫作 probalities，应该是因为这里采用了 Self-Regression 架构）。在右上角的橙色 Attention 块中，<code>inputs</code> 负责提供 $K, V$ ，而 <code>outputs</code> 提供 $Q$。</p><p>那么如果在 Self-Attention 中，还有必要区分 $Q, K, V$ 吗？还是说只要像最开始那样，直接使用 $X$ 就好了呢？其实还是有必要区分 $Q, K, V$ 的，在上面的介绍中可以看出， $Q, K, V$ 是各司其职，所以即使在 Self-Attention 中，也是有这样的分工。我们可以使用三个权重矩阵，来使得来源相同的 $Q, K, V$ 有不同的作用，如下所示：</p><script type="math/tex; mode=display">Q = X W_Q \\K = X W_K \\V = X W_V</script><p>这样做，还可以改变 $Q, K, V$ 的形状，他们不再必须和 $X$ 保持相同的形状 $t \times d_{model}$ ，而是可以变成 $t \times d_k$ 和  $t \times d_v$ 。之所以没有 $d_q$ ，是因为 $d_q$ 和 $d_k$ 是相等的。</p><h3 id="3-4-Self-Regression"><a href="#3-4-Self-Regression" class="headerlink" title="3.4 Self-Regression"></a>3.4 Self-Regression</h3><p>正如前文所述，Attention 机制最初用于机器翻译，所以其核心部分是 Cross-Attention。而如今大火的生成式（Generative）大模型，则对原始模型的一个改进。也就是“自回归”（Self-Regression）。</p><p>自回归的意思是，将输出重新作为输入，用于产生新的输出，周而复始。这个概念还比较好理解，问题在于它和 Attention 机制并不搭配，如下所示：</p><script type="math/tex; mode=display">Y = softmax(\frac{QK^T}{\sqrt{d_{in}}})V</script><p>最后生成的是一个 $t \times d_{v}$ 的矩阵 $Y$ ，在机器翻译中，这就是那个翻译好的英文句子。但是在生成式中呢？难道就是把 prompt 翻译了吗？显然不是的，实际上 self-regression 的设计非常“浪费”，它只会选取 $Y$ 的最后一个行向量，作为生成出来的 token 输出，并将这个 token 连接 $X$ 的最后面，其伪代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">generative</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span><span class="token punctuation">:</span>    X <span class="token operator">=</span> prompt             <span class="token comment"># prompt 是最开始的输入</span>    R <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                 <span class="token comment"># Result 最开始为空</span>        <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        Y <span class="token operator">=</span> attention<span class="token punctuation">(</span>X<span class="token punctuation">)</span>   <span class="token comment"># 进行 attention 机制</span>        y <span class="token operator">=</span> Y<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>         <span class="token comment"># 取最后一个 token</span>        <span class="token keyword">if</span> y <span class="token operator">==</span> <span class="token string">'&lt;EOS&gt;'</span><span class="token punctuation">:</span>   <span class="token comment"># 如果是 End of Sequence，则退出循环</span>            <span class="token keyword">break</span>        R <span class="token operator">+=</span> y             <span class="token comment"># 记录 token 作为输出</span>        X <span class="token operator">+=</span> y             <span class="token comment"># 将 token 作为输入</span>        <span class="token keyword">return</span> R<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这种“浪费”会被下文的 KV-Cache 缓解。</p><h3 id="3-5-Encoder-Decoder"><a href="#3-5-Encoder-Decoder" class="headerlink" title="3.5 Encoder Decoder"></a>3.5 Encoder Decoder</h3><p>我们从上面的 Transformer 架构中注意到，上面一共有 3 种 Attention，我们详细介绍过的是位于右上角的 cross attention 块。在左下和右下还有两个 self-attention 快，分别是 encode-attention 和 decode-attention。</p><p>这两种 attention 实现的都不是翻译任务，而是一种“让 token 关注上下文语义”的任务。通过 attention，原本独立的 token 语义会在上下文的影响下发生变化，这对之后的 cross-attention 是一种帮助。</p><p>但是为什么 decoder-attention 相比于 encode-attention，多了一个 Sequence Mask 机制，它说得是对于 $A$ 矩阵中的 $a_{ij}$ ，如果有 $j &gt; i$ ，那么就会被 $softmax$ 忽略。这样的目的是确保模型在生成当前词时，只能使用当前词及其之前的词，而不能“偷看”未来的词。而 encoder 就没有这个问题，为了获得语料库中的所有语义，Encoder 是允许使用全部上下文的。</p><p>这里有个问题，就是在 Self-Regression 中，本来就是逐词生成的，在当前词没有生成的时候，未来的词也肯定没有生成，那么就算模型想偷看，也偷看不成。为了解释清楚，我们就需要理解逐词生成是推理的行为，而在训练的时候，模型是并行处理整个目标序列的，所以才需要掩码。</p><h3 id="3-5-Multi-Head"><a href="#3-5-Multi-Head" class="headerlink" title="3.5 Multi-Head"></a>3.5 Multi-Head</h3><p>除了计算资源的浪费之外，我们还注意到 Self-Attention 的并行度又变差了。本来在机器翻译中，Attention 机制改进了 RNN 每个 token 逐个翻译的缺点，可以并行生成一整个输出语句（也就是 token 集合 $Y$）。但是在这个算法中，并行生成的 $Y$ 只用最后一个 token 的行向量 $y$ ，就又变成串行生成了。</p><p>但是这种“串行生成”是 self-regression 的精髓，所以我个人感觉很难改变。但是我们依然有办法加速，那就是每次 attention 的时候通过减少 <script type="math/tex">d_k, d_v</script> 来提高速度。这种缩减 <script type="math/tex">d_k, d_v</script> 的行为，可以理解为在原本 <script type="math/tex">d_{model}</script> 的空间里提取特征。</p><p>那么仅提供一个特征，就容易导致精度丧失，所以我们可以使用多个 attention，提取多个不同的特征，最后再将结果拼接在一起，这样提高了并行度和延迟，又不损失精度。我们设模型的 head 数为 $h$ ，通常有：</p><script type="math/tex; mode=display">d_{model} =  h \cdot d_k</script><p>我们举一个例子，有参数：</p><ul><li>$d_{model} = 4$</li><li>$t = 6$</li><li>$h = 2$</li><li>$d_k = 2$</li></ul><p>示意图如下：</p><p><img src="/posts/7dc4ea13/attention2.drawio.png" alt=""></p><h3 id="3-6-KV-Cache"><a href="#3-6-KV-Cache" class="headerlink" title="3.6 KV Cache"></a>3.6 KV Cache</h3><p>正如前所述，在 Self-Regression 中我们计算 $Y$ 的目的只是为了得到最后一个行向量 $Y_t$ ，在上述计算中，有很多计算是冗余的，我们在上图中用“实心”标出计算 $Y_t$ 所需要的分量：</p><p><img src="/posts/7dc4ea13/attention3.drawio.png" alt=""></p><p>也就是说，只需要 $Q$ 的最后一个行向量，全部的 $K, V$ 向量，就可以满足计算要求，我们并不需要全部的 $Q$ 。</p><p>更进一步，因为 $K, V$ 都是逐步增长的，也就是每次增加最后一个横向量，所以前面的部分都是可以被 cache 的，避免了 $X$ 每次都需要与 $W$ 进行运算，如果对 $K,V$ 进行 cache（用“交叉线”填充），那么计算量会进一步减少：</p><p><img src="/posts/7dc4ea13/attention4.drawio.png" alt=""></p><p>但是因为 $KV$ 的形状都包括一个 $t$ ，所以在长上下文场景下（也就是 $t$ 很大），会导致缓存的数据很多，这样就会导致 GPU 的访存压力很大。</p><h3 id="3-7-Prefill-amp-Decode"><a href="#3-7-Prefill-amp-Decode" class="headerlink" title="3.7 Prefill &amp; Decode"></a>3.7 Prefill &amp; Decode</h3><p>在了解完 KV Cache 后，我们可以来计算一下 Attention 机制的复杂度。对于一个 decode 阶段的 token 的时间复杂度而言：</p><p>使用 $W_Q$ 对输入进行投影得到 $q$ ，时间复杂度是：</p><script type="math/tex; mode=display">2 d_{model}d_k</script><p>利用 $q$ 与 $K$ 相乘得到注意力得分，时间复杂度是：</p><script type="math/tex; mode=display">2d_{k}t</script><p>对于一个 $t$ 个元素的注意力得分与 $V$ 进行计算，时间复杂度是：</p><script type="math/tex; mode=display">2d_{k}t</script><p>也就是说，这是一个与 $t$ 呈线性时间复杂度的算法。</p><p>不过这么好的方法并不适用于整个算法。在我们生成第一个 token 的时候，是将整个 prompt 进行计算的，所以还是会需要计算出一个注意力方阵，而非一个注意力向量。</p><p>那么在 prefill 阶段，那么注意力得分的时间复杂度是：</p><script type="math/tex; mode=display">2d_kt^2</script><p>而与 $V$ 进行计算的时间复杂度为：</p><script type="math/tex; mode=display">2d_kt^2</script><p>都是 $O(t^2)$ 的算法。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、总论&quot;&gt;&lt;a href=&quot;#一、总论&quot; class=&quot;headerlink&quot; title=&quot;一、总论&quot;&gt;&lt;/a&gt;一、总论&lt;/h2&gt;&lt;p&gt;当我们提到大模型 LLM 的时候，总是和 Transformer 这种架构联系在一起，似乎只有使用了 Transformer 架构的深度学习模型才配叫作大模型。&lt;/p&gt;
&lt;p&gt;不过以我目前浅薄的认知，我倒觉得 Transformer 并不是 LLM 的核心特征，因为 LLM 的算法变化很快，Transformer 从 2017 年到现在有了多种变体，也有完全不采用 Transformer 架构的 AI。我个人感觉 LLM 的核心有两点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型参数极大：我们认为模型参数越多，模型就越智能。这是“涌现”的一种具体体现。&lt;/li&gt;
&lt;li&gt;采用“预训练-微调-推理”范式：这种范式使得模型的通用性得到了增强，划分了不同的生态位。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我希望在下文中记录一下关于 LLM 或者 Foundation Model 的基础知识，以避免被这个时代抛下太久。&lt;/p&gt;</summary>
    
    
    
    <category term="Sys4AI" scheme="https://thysrael.github.io/categories/Sys4AI/"/>
    
    
    <category term="直观理解" scheme="https://thysrael.github.io/tags/%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/"/>
    
    <category term="S9假期" scheme="https://thysrael.github.io/tags/S9%E5%81%87%E6%9C%9F/"/>
    
    <category term="Sys4AI" scheme="https://thysrael.github.io/tags/Sys4AI/"/>
    
  </entry>
  
  <entry>
    <title>计算机系统-分布式</title>
    <link href="https://thysrael.github.io/posts/47da48a7/"/>
    <id>https://thysrael.github.io/posts/47da48a7/</id>
    <published>2025-01-16T06:49:42.000Z</published>
    <updated>2025-08-15T12:16:49.026Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、分布式系统"><a href="#一、分布式系统" class="headerlink" title="一、分布式系统"></a>一、分布式系统</h2><h3 id="1-1-总论"><a href="#1-1-总论" class="headerlink" title="1.1 总论"></a>1.1 总论</h3><p>分布式系统指的是利用多个单体计算机系统构建的多体计算机系统。</p><p>与并行计算不同，分布式系统更侧重于用多个计算实体完成<strong>非常多个</strong>细碎的任务。而并行计算侧重于利用多个计算实体来更快更高效地完成<strong>一个</strong>计算任务。</p><p>分布式系统包括了执行流的分布式和数据的分布式。在北航 OO 课电梯问题中，涉及了多线程，属于是执行流的分布式，这就导致我以为分布式只是执行流的分布式，涉及的问题只是互斥和同步，这是非常片面的。数据的分布式指的是，存在多个数据副本，cache 就是一种数据分布式的实体。</p><h3 id="1-2-背景"><a href="#1-2-背景" class="headerlink" title="1.2 背景"></a>1.2 背景</h3><p>分布式系统虽然出现在各个系统层次，比如说多核的 CPU，多级存储系统，多线程的程序，分布式式的 Web APP。但是大部分的分布式理论都源于 Web APP，这是因为 Web 时代发展的红利导致的。</p><p>传统的 Web APP 架构被称为 LAMP，即 Linux + Apache + MySQL + PHP。</p><p>LAMP 的拓展性并不符合要求，其核心原因在于 Web APP 的用户拓展性非常好，一个用户生产 1M 的数据（非常小），那么一百万个用户就会生产出 1T 的数据，这就不再是一个磁盘可以简单存放的了，我们就需要一个存储的集群了。及时人们可以制造出一个非常大的磁盘，但是它的速度一定是会受到影响的。</p><p>计算也是同理，可能一个用户请求的计算量并不大，但是一百万个用户的计算量就非常大了。而受到摩尔定律和登纳德缩放定律失效的影响，人们是无法制造出一个超级强悍的单体芯片的，这就导致必须使用多个芯片。</p><p>这个时候将系统从单机拓展成分布式系统，就非常自然了。</p><h3 id="1-3-组成"><a href="#1-3-组成" class="headerlink" title="1.3 组成"></a>1.3 组成</h3><p>下面会介绍一个分布式的 Web APP （电商平台）由哪几个部分组成，其架构如图所示：</p><p><img src="/posts/47da48a7/image-20250116163924056.png" alt="image-20250116163924056" style="zoom:40%;"></p><p>存在如下分布式：</p><ul><li>外存的分布式：将数据存放在多个外存服务器上，也就是分布式的文件系统和分布式的数据库。</li><li>内存的分布式：分布式外存无法高效的缓存数据，且 APP 所在的单机的内存不够大，所以将内存也进拓展，也就是 Memcached</li><li>app 的分布式：app 不需要部署在同一个单机上，可以部署在不同单机上，每个单机负责不同的功能。</li><li>Load Balance：仅存在一个 app 依然非常局限，可以在多个单机上启动多个相同的 app，再由 Load Balancer 来决定请求发往哪个更为空闲的单机。这种技术除了依赖负载平衡技术外，还依赖 HTTP 协议的无状态性，使得负载均衡可以做得很轻松，如果是有状态的，那么负载均衡调度的就不再只是请求，就还包括之前的状态信息。</li><li>CDN：将一些多媒体资源，放置在距离用户更近的地方。</li><li>Compute 的分布式：将大量的计算任务放在单独的集群上（这张图上好像没有）。</li></ul><h3 id="1-4-CAP-理论"><a href="#1-4-CAP-理论" class="headerlink" title="1.4 CAP 理论"></a>1.4 CAP 理论</h3><h4 id="1-4-1-介绍"><a href="#1-4-1-介绍" class="headerlink" title="1.4.1 介绍"></a>1.4.1 介绍</h4><p>CAP 指的是分布式的三种重要属性，之所以将它们三个单独拎出来，是因为这三个属性构成了一个不可能三角（我也不知道有没有严格数学证明）。</p><p>我个人认为理解 CAP 理论的难点在于理解清楚这三个属性的定义，他们的定义如下：</p><ul><li><strong>C</strong>onsistency（一致性）：多个数据备份中的数据是一模一样的，用户可能会对某个备份中的数据进行修改，然后另一个数据备份中的数据也会跟随变化，保持一致。当系统没有一致性的时候，可能存在不同的数据备份，也就是正确性出现了问题。</li><li><strong>A</strong>vailable（可用性）：这是非常难理解的一个属性，他指的是用户对于数据的操作（读取或者写入一个数据等）是成功的概率非常高。而当失去可用性的时候，用户的操作经常会收到“操作失败，请重新尝试”的回应。</li><li><strong>P</strong>artition Tolerance（分区容忍性）：这个也非常难理解，它指的是在多个数据备份失去连接的时候（也就是所谓的“分区”），系统依然保持一致性和可用性的能力。C 和 A 对于一个单机系统而言，是非常自然的属性（要不然就是写出来 bug）了，但是如果是分布式系统，一旦数据备份之间失去同步能力，那么是很难保证 C 和 A 的。</li></ul><p>那么为什么这是一个不可能三角呢？我们考虑如下图这样的情况，目前有两个分布式服务器 $S_1$、$S_2$，这两个服务器里都存储着数据 $V$ 的数据备份，客户 $C$ 可以读写 $V$ ，在开始阶段，$S_1$、$S_2$ 中 $V$ 的值都是 $v_0$ 。</p><p>然后出现了网络故障，导致 $S_1$、$S_2$ 之间的同步机制失效，出现了分区情况。然后 $C$ 向 $S_1$ 写入 $V$ 的值为 $v_1$ ，因为缺乏同步机制，所以 $S_2$ 中 $V$ 的值依然是 $v_0$ 。</p><p>此时如果 $C$ 从 $S_2$ 处读取 $V$ 的值，那么有两种可能，第一种是为了可用性，我们告诉 $C$ ，$V$ 的值是 $v_0$ ，这样就牺牲了一致性原则。第二种是我们为了一致性，告诉 $C$ 目前网络出现问题，读取并不成功，那么这样就牺牲了可用性原则。</p><p><img src="/posts/47da48a7/image-20250117111613066.png" alt="image-20250117111613066" style="zoom:40%;"></p><p>从这个例子就可以看出，CAP 不可兼得。而根据业务场景的不同，我们选择牺牲的属性也不同：</p><ul><li>CA 牺牲 P：牺牲 P 就意味着系统不再是一个真正的分布式系统了，因为分布式系统出现“分区“是非常核心的场景，或者说，在分布式系统中不考虑”同步机制“，就过于理想和不可靠了。所以牺牲 P 的系统往往是一个单机系统（或者是某种无法享受分布式优势的分布式系统）。对于一个单机系统而言，保证 C 和 A 是非常基本的事情。</li><li>CP 牺牲 A：牺牲 A 意味着操作有可能失败，但是只要操作成功了，那么它的一致性（也就是正确性）就得到了保证。对于银行 APP 或者支付宝这种对于正确性比较看重的软件，一般会采用这种策略。毕竟谁也不希望自己的账户里的钱突然没了。</li><li>AP 牺牲 C：牺牲 C 意味着虽然每次操作都会得到响应，但是操作的结果不一定保证一致性。对于微信对这种实时性要求比较高的聊天软件，一般会采用这种策略。这也是我们在使用微信的时候，常常会出现”引用的内容不存在“的原因。</li></ul><h4 id="1-4-2-ACID-vs-BASE"><a href="#1-4-2-ACID-vs-BASE" class="headerlink" title="1.4.2 ACID vs BASE"></a>1.4.2 ACID vs BASE</h4><p>在传统的数据库理论研究中，有 ACID 理论：</p><ul><li><strong>原子性 (Atomicity)</strong>：原子性保证了事务中的所有操作要么全部成功，要么全部失败，不能只完成部分操作。如同“原子”一样，事务是不可分割的。</li><li><strong>一致性 (Consistency)</strong>：一致性保证了事务在执行前后，数据库的数据必须是合法的。当事务完成后，所有数据约束条件都必须得到满足。</li><li><strong>隔离性 (Isolation)</strong>：隔离性确保了并发执行的事务之间不会互相干扰。每个事务的执行都像是独占资源，其他事务不能看到其未提交的结果。</li><li><strong>持久性 (Durability)</strong>：持久性确保了已提交的事务所做的更改是永久性的，即使系统崩溃或出现故障，这些更改也不会丢失。</li></ul><p>可以看出大部分的属性都是在保证 C 和 A，而对于 P 是没有描述的。</p><p>而随着 Web 时代的来临，传统的 ACID 就跟不上时代了，所以人们又提出了 BASE 理论：</p><ul><li><strong>基本可用性 (Basically Available)</strong>：系统在大多数时间内是可用的，即使在部分节点出现故障时也能处理请求。这意味着要牺牲部分一致性来保证系统的可用性。</li><li><strong>柔性状态 (Soft state)</strong>：在 BASE 理论中，数据的状态不是瞬时的一致性，而是在某个时间点上可能处于“柔性”的状态，允许数据在一定时间内有暂时的不一致性。</li><li><strong>最终一致性 (Eventual consistency)</strong>：在较长的时间内，系统会最终达到一致状态。这意味着虽然可能存在短期的不一致性，但经过一段时间后，所有副本最终会一致。</li></ul><p>从这里可以看出，BASE 的思路是弱化 C 和 A ，来保证 P。理论的变化折射出不同的时代需求。</p><h3 id="1-5-指标"><a href="#1-5-指标" class="headerlink" title="1.5 指标"></a>1.5 指标</h3><p>虽然 CAP 理论提出了一些关于分布式理论的指标，但是我觉得它更像是为了理论服务的，而不是为了实际的生产。</p><p>在实际中，我们更看重这些指标：</p><p><img src="/posts/47da48a7/image-20250117115544649.png" alt="image-20250117115544649" style="zoom:35%;"></p><p>我们为了这些指标发明了很多技术：</p><p><img src="/posts/47da48a7/image-20250117115658051.png" alt="image-20250117115658051" style="zoom:35%;"></p><p>和 CAP 理论一样，这些指标之间也存在一定的权衡，不同的技术满足不同的场景：</p><p><img src="/posts/47da48a7/image-20250117115923738.png" alt="image-20250117115923738" style="zoom:50%;"></p><p>我们下面会详细介绍一些特性的实现。</p><hr><h2 id="二、一致性"><a href="#二、一致性" class="headerlink" title="二、一致性"></a>二、一致性</h2><h3 id="2-1-总论"><a href="#2-1-总论" class="headerlink" title="2.1 总论"></a>2.1 总论</h3><p>在分布式系统中，会存在多个数据备份和多个执行流。这种情况下，很容易出现各个实体间操作和数据不一致的情况。也就是说，不一致是自然的，我们希望通过我们的努力，让这个复杂的模型简单下来。</p><p>我们简化模型的方式是这样的：</p><ul><li>所有数据只有一份拷贝</li><li>整体并发的操作序列会被等价成一个串行序列</li></ul><p>也就是如下图所示：</p><p><img src="/posts/47da48a7/image-20250117152505550.png" alt="image-20250117152505550" style="zoom:33%;"></p><p>那这是怎么办到的呢？从图上可以看出，确实很多操作就是同时进行的，而不是串行执行的呀？我们改变操作的顺序，本质是在改变操作的起始时间，如果两个操作重叠在一起了，那么我们就让一个操作晚一些启动，也就是<strong>阻塞</strong>一个操作，来将两个操作错开。</p><p>也就是说，为了编程的易用性，我们牺牲的是系统的性能，更具体一些，牺牲的是操作的时延（可能还有些别的）。</p><p>一致性模型的光谱（Spectrum）如下：</p><p><img src="/posts/47da48a7/image-20250117153143453.png" alt="image-20250117153143453" style="zoom:30%;"></p><p>我们还可以从另一个角度去分析为什么性能和易用性可以形成 tradeoff，当我们有一个并发的操作序列的时候，我们可以将他们排列成多种串行的全排列。一致性模型的本质，就是规定一些全排列是符合要求的，而另一些全排列是不符合要求的。越严格的一致性模型，允许的全排列的数目就越少，那么行为就更好被预测，那么易用性就高；而越宽松的模型，允许的全排列的数目就越多，那么底层实现就可以越灵活，性能就可以越好。</p><p>此外还需要强调，这里的一致性，并不完全等价于正确性，并不是说，我们只要遵循了某个一致性的模型，那么程序就不会出我们意想不到的 bug 了（不同的一致性模型可能有不同强度的编程约束，在这个约束下可能有一些奇怪的行为，但是都是符合一致性模型的内在逻辑的）。这是因为这里说的一致性里的操作，每个操作只涉及一个数据 object，而涉及多个 object 的操作（比如说银行账户的转账，涉及一个账户金额的减少和另一个账户金额的增加），就不再是一致性的范畴了，而是下文讨论的隔离性的范畴了。这种涉及多个 object 的操作被称作一个事务（Transaction，TX）。</p><h3 id="2-2-一致性模型"><a href="#2-2-一致性模型" class="headerlink" title="2.2 一致性模型"></a>2.2 一致性模型</h3><h4 id="2-2-1-Strict"><a href="#2-2-1-Strict" class="headerlink" title="2.2.1 Strict"></a>2.2.1 Strict</h4><p>strict 模型指的是按照每个 operation 的起始时间来对这些 operation 进行排列。那么这种模型基本上就等同于只允许一个全排列（因为每个 operation 的开始时间一般都是不同的），是最严格的模型。</p><p>这种模型基本上只是只能存在于理论中，因为在分布式系统中很难建立起一个全局的统一时钟。</p><h4 id="2-2-2-Linearizability"><a href="#2-2-2-Linearizability" class="headerlink" title="2.2.2 Linearizability"></a>2.2.2 Linearizability</h4><p>Linearizability 指的是如果 op1 的终止时间在 op2 的起始时间之前，那么在串行排列中，也一定是 op1 在 op2 之前。如下图所示，这种排列就是不被允许的：</p><p><img src="/posts/47da48a7/image-20250117163653516.png" alt="image-20250117163653516" style="zoom:40%;"></p><p>Linearizability 看似也是需要全局时钟的，而实际上并不是，Linearizability 的本质是确定各个操作的相对顺序而不是绝对顺序，所以实现难度会低一些。</p><h4 id="2-2-3-Sequential"><a href="#2-2-3-Sequential" class="headerlink" title="2.2.3 Sequential"></a>2.2.3 Sequential</h4><p>Sequential 指的是在每个计算实体上维护操作的相对顺序，而 Linearizability 是全局的相对顺序。</p><p>也就是说，下面的这个图（就是上面的那个图），虽然不符合 Linearizability ，但是符合 Sequential 。这是因为原本在 Linearizability 中存在的依赖，因为分别属于 P0 和 P1，所以在 Sequential 中并不存在：</p><p><img src="/posts/47da48a7/image-20250117164908037.png" alt="image-20250117164908037" style="zoom:40%;"></p><h4 id="2-2-4-Eventual"><a href="#2-2-4-Eventual" class="headerlink" title="2.2.4 Eventual"></a>2.2.4 Eventual</h4><p>Eventual 是一种弱一致性模型，它只能保证最终每个数据副本的状态是一致的，而中途的状态就不一定了。</p><p>这种模型似乎就是微信这种实时聊天软件所采用的模型，所以微信的实时性更好，但是经常出现错误。</p><h3 id="2-3-实现"><a href="#2-3-实现" class="headerlink" title="2.3 实现"></a>2.3 实现</h3><p>Linearizability 有一个特性，就是如果每个 object 的 Linearizability  得到了维持，那么整个系统的 Linearizability  就得到了维持。这个特性我其实不是太理解，因为我感觉不同的 object 之间也会存在一些依赖关系。所以就算了，只是记录在这里。</p><p>下面我们开始介绍 Linearizability 的实现，其中最简单的一个模型就是 Primary-Backup Model，也就是将某个数据备份设置为 Primary，而其他的数据备份是 Backup。所有的写入操作都需要先对所有的 Backup 写入后，再对 Primary 进行写入。所有的读取操作，也只是对于 Primary 的读取，并不会读 Backup，也就是如下：</p><p><img src="/posts/47da48a7/image-20250117170621899.png" alt="image-20250117170621899" style="zoom:33%;"></p><p>这种方式有两个很有趣的点，一个是要先写 backup，然后写 Primary，这是因为如果先写 Primary，那么就又可能在写操作还没有 Done 的时候，另一个读操作就可以读出来新值了，这就违反了 Linearizability 的定义。换句话说，将 Primary 的写入视为整个写入操作的结束，是一种实现 Linearizability 的一种手段。</p><p>另一个就是即使本地有数据，也依然要到 Primary 中去读取，这是因为 Read 操作必须完全在 Write 操作之前或者之后，下图就表示了一种不遵循这种方式造成的问题，Read_1 读出了新值，而 Read_2 明明在 Read_1 之后，读出的却是旧值。</p><p><img src="/posts/47da48a7/image-20250117171434398.png" alt="image-20250117171434398" style="zoom:33%;"></p><p>当然这种非常愚蠢的读操作也是有办法缓解的，我们还是能读取本地值的，即使本地值是 backup，也就是我们设计每个 object 有两种模式，一种模式下只可以读取本地值，而另一个模式不允许，必须读取 Primary 的值，当 Primary 要写 object 的时候，就会把模式调整为不允许，而写入完成后，就调整成允许。这种设计非常类似于 Cache Coherency 的设计。</p><p>此外 Backup 的 op 的顺序也可能因为网络等问题，导致和 Primary 上的 op 的顺序存在差异，如下所示：</p><p><img src="/posts/47da48a7/image-20250117172212189.png" alt="image-20250117172212189" style="zoom:33%;"></p><p>明明在 P0 上是 op1，op2，到了 P1 上就变成了 op2，op1 。我们可以给操作一个 seq number，来解决这个问题：</p><p><img src="/posts/47da48a7/image-20250117172401101.png" alt="image-20250117172401101" style="zoom:33%;"></p><p>在 Primary-Backup 模型中，Primary 因为承担了过多的通信开销，导致其成为性能瓶颈。我们可以采用分区的方法，也就是不同的 object 的 Primary 并不是同一个，来避免瓶颈问题，下图中 x 的 Primary 是 P0，而 y 的 Primary 是 P1：</p><p><img src="/posts/47da48a7/image-20250117172756191.png" alt="image-20250117172756191" style="zoom:33%;"></p><p>在了解完 Linearizability 的实现后，如果我们每次都只读取 local 的数据，写入的时候也只写入 local 数据，对于其他的备份，采用后台写入的方式，那么我们就得到了 Eventual 模型。</p><hr><h2 id="三、隔离性"><a href="#三、隔离性" class="headerlink" title="三、隔离性"></a>三、隔离性</h2><h3 id="3-1-总论"><a href="#3-1-总论" class="headerlink" title="3.1 总论"></a>3.1 总论</h3><p>在一致性这一章，我们讨论了在分布式系统下，多个并发 op 的一致性模型，但是即使我们让这些 op 满足了某种一致性，也是依然会出现问题的。比如说银行转账问题。出现问题的原因就在于，这些 op 是一个个零散得进行排序的，而在生产中，我们希望一组 op 可以绑定在一起进行排序（起码看上去是绑定在一起的），这样绑定在一起的一组 operation 我们就称之为“事务”（Transaction，TX）。</p><p>隔离性（Isolation）就是描述事务的性质，它指的是事务之间看上去是相互隔离的，不会出现“犬牙交错”的情况，也就是不同 TX 里的 op 交替执行。隔离性还有很多其他的名字，比如说 Before-After Atomicity，Serializability 等，都是相同的意思。在下文中我们主要采用 Serializability 这个词。</p><p>那么 Serializability 和 Consistency 的关系是什么？我觉得它们是不完全正交的。虽然他们看上去都涉及了某种“视图”，但是其本质是不一样的。Consistency 的视图是一个 op 的串行序列，而 Serializability 的视图是多个 op 的串行序列，也就是常说的 Grid Notion，在 Grid Notion 中有 3 个概念：</p><p>Operation ⊂ Transaction ⊂ Schedule</p><p>也就是一个调度（Schedule）就是一个“历史记录”，这段历史记录里有所有事务（Transaction）里的所有 Operation 的排列顺序。数据库开发者能做得就是“歪曲” Schedule 来获得性能，而用户需要明确被开发者歪曲过的 Schedule 和一个理想的 Schedule （一般就是原子性事务形成的 Schedule）之间的差距有多大。</p><p>如下所示：</p><p><img src="/posts/47da48a7/clipboard-20241105T194227.png" alt="clipboard-20241105T194227" style="zoom: 50%;"></p><p>写到这里其实我迷茫了，感觉虽然上面是两个 op 序列，但是实际上依然是一个 op 序列（或者说实际上依然是并行的，只是在视图上变成了串行的）。所以我也说不好。</p><p>Serializability 只是要求 TX 看上去保持原子性，其中的 op 是不能被打散的。但是在实际上如果真的这样去做，那么性能就又会受到一定的影响。所以实际上不同 TX 的 op 依然是交错执行，甚至是并行执行的，只是看上去是满足 Serializability 的，这点和 Consistency 类似，也是存在着多种 Serializability 的模型，如下所示：</p><p><img src="/posts/47da48a7/image-20250118173609510.png" alt="image-20250118173609510" style="zoom:33%;"></p><p>我在网上找到了一个图，因为图上有一些我不懂的概念，所以我不知道是不是可以说明 Serializability 和 Consistency 的不完全正交性。</p><p><img src="/posts/47da48a7/clipboard-20241105T194446.png" alt="clipboard-20241105T194446"></p><h3 id="3-2-Serializability-模型"><a href="#3-2-Serializability-模型" class="headerlink" title="3.2 Serializability 模型"></a>3.2 Serializability 模型</h3><h4 id="3-2-1-Conflict-Serializability"><a href="#3-2-1-Conflict-Serializability" class="headerlink" title="3.2.1 Conflict Serializability"></a>3.2.1 Conflict Serializability</h4><p>Conflict Serializability 是一种约束较强的 Serializability 模型。它首先定义了什么是 operation 之间的 conflict：</p><ul><li>它们操作同一个 object</li><li>至少其中一个是写操作</li><li>它们属于不同的事务</li></ul><p>然后如果一个 Schedule 的 conflict order 和某个串行化 Schedule 的 conflict order 是一样的，那么这个 Schedule 就是符合 Conflict Serializability 。</p><p>这个定义说得非常的不清楚，其实应该是这样。所谓的“串行化 Schedule”指的是让这些 TX（注意不是 op）串行化的 schedule。我们在现实中希望能交替或者并行执行不同 TX 中的 op，如果两个 op 毫不相干，那么显然是可以交替执行的。而 conflict 定义了一种 op 之间“相干”的关系，存在 conflict 的 op 就不能随便调度了，它必须和一种串行化的调度的 conflict 顺序相同（相当于和理想状态一致）。</p><p>而在实践中，我们可以用 Conflict Graph 是否成环来判断一个 schedule 是否满足 Conflict Serializability。conflict graph 是有向图，的节点是 TX（注意不是 op），而如果两个 TX 中有 op 是 conflict，那么就有一条边，从在 schedule 中更靠前的 op 所在的 TX 的节点，指向更靠后的 op 所在的 TX 的节点。当 Conflict Graph 成环的时候，就说明这个 schedule 是不满足 Conflict Serializability 的。</p><p>为什么 Conflict Graph 是否成环就可以判断是否是 Conflict Serializability 呢？这是因为对于一个串行的 schedule 而言，它的 Conflict Graph 一定是不成环的，这是非常显然的，反之，当一个 schedule 对应的 Conflict Graph 是成环的，那么它一定没有办法表示成一个串行的 schedule。所以我们就可以用 Conflict Graph 来判断。</p><h4 id="3-2-2-View-Serializability"><a href="#3-2-2-View-Serializability" class="headerlink" title="3.2.2 View Serializability"></a>3.2.2 View Serializability</h4><p>Conflict Serializability 的约束还是过强了，类似于 CPU 指令的调度，RAW，WAW，WAR 都会被判定为 conflict，而实际上约束并不需要这么强。比如说下图的 schedule 不符合 Conflict Serializability，但是读出的值、最后的状态（也就是我们在调度中最关心的两点），和串行 schedule “T1 -&gt; T2 -&gt; T3”一样：</p><p><img src="/posts/47da48a7/image-20250118202954360.png" alt="image-20250118202954360" style="zoom:40%;"></p><p>为了允许这种情况，我们发明了 View Serializability。它的定义就是，如果读操作和最终状态都和一个串行 schedule 相同，那么就是符合 View Serializability 的。也就是 View 的含义，即“看上去没啥毛病”。</p><p>View Serializability 就是一种较为理想的状态，它一共有 3 点要求（非常数学形式化的要求），其中第二点就是 RAW，而剩下两点是关于 init 和 end 的约束，就比 Conflict Serializability 要更加合理地多。</p><p>可惜的是，View Serializability 很难检验是否达成，而且也很难实现；相反的，Conflict Serializability 可以用 Conflict Graph 来检验，而且可以用 2PL 来实现。</p><h3 id="3-3-实现"><a href="#3-3-实现" class="headerlink" title="3.3 实现"></a>3.3 实现</h3><h4 id="3-3-1-2PL"><a href="#3-3-1-2PL" class="headerlink" title="3.3.1 2PL"></a>3.3.1 2PL</h4><p>Lock 是一种保证多个 Serializability 的有效手段。而具体而言，需要使用 2PL （2 Phase Lock）的方式。</p><p>按理说是一份 object 对应一份锁，但是并非锁的粒度仅仅取决于资源的粒度。比如说我们希望将 A 账户里的钱转账到 B 账户上，在语义上，A 和 B 是一个共同体，所以锁不能仅仅是 A Lock 和 B Lock（这样会导致有一个中间态是 A 账户的钱已经没了，而 B 账户还没有收到钱），而应该是一个 AB Lock 。</p><p>在实践上，我们没有必要真的声明一个 AB Lock，这样的话，一个有 N 个账户的银行就需要 $C_{n}^{2}$ 个锁了，这显然是不现实的。我们只需要同时拿住 A Lock 和 B Lock 即可保证粒度是 AB 。</p><p>从上面我们说到，锁的粒度不仅取决于资源本身的粒度，还取决于事务（上面的例子是转账）的粒度。如果一个事务需要多种资源，那么它应该同时拿多把锁。问题在于，拿锁这个行为并不能同时发生。两阶段锁（Two Phase Locking, 2PL）这个理论告诉我们，只要按照它说得做，就可以达到跟“同时拿两个锁”一样的效果。</p><p>2PL 的两个阶段：</p><ul><li>Expanding phase：只拿锁，不放锁</li><li>Shrinking phase：只放锁，不拿锁</li></ul><p>也就是说，以对共享资源进行具体的操作为界，在操作前只拿锁，在操作后只放锁，不会存在放锁后再拿锁的情况。</p><p><img src="/posts/47da48a7/image-20250118204019137.png" alt="image-20250118204019137" style="zoom:33%;"></p><p>Lock 有一个问题 Deadlock，为了避免死锁，其实 2PL 已经给出了一个方法，就是在拿锁的时候需要按照一定的顺序，而放锁的时候按照相反的顺序，这样就可以避免死锁。</p><p>但是这种方法的难点在于，很难给所有的共享的 object 进行一个排序，而且对程序员也是负担。</p><p>此外，我们还可以用 Conflict Graph 来判断是否出现死锁，但是这种检验方式成本也太大。所以我们现在一般采用一些启发式方法。</p><h4 id="3-3-2-OCC"><a href="#3-3-2-OCC" class="headerlink" title="3.3.2 OCC"></a>3.3.2 OCC</h4><p>OCC 即 Optimistic Concurrency Control。</p><p>相对应的，Lock 的方式被视为 Pessimistic 。这是因为拿锁的目的是为了保证 object 的独占性，但是这建立于这个 object 真的会被多个 TX 并发访问的假设，这个假设在某些场景下有些过于悲观了。</p><p>OCC 的意思是 TX 不再使用锁，而是直接操作，如果出现了竞态，那么再修正。即：</p><ul><li><p><strong>阶段 1：并发本地处理</strong></p><ul><li><p>读取数据到读集。</p></li><li><p>将写操作缓存在写集中。</p></li></ul></li><li><p><strong>阶段 2：验证可串行化（在临界区内）</strong></p><ul><li>验证是否保证可串行化：</li><li>检查读集中的数据是否被修改过。</li></ul></li><li><p><strong>阶段 3：提交或中止（在临界区内）</strong></p><ul><li><p><strong>中止</strong>：如果验证失败，则中止事务。</p></li><li><p><strong>提交</strong>：如果验证成功，则安装写集并提交事务。</p></li></ul></li></ul><p>Git 就是一种 OCC，每个人都在自己本地进行修改，而如果发生冲突，再手动 merge。</p><p>后两个阶段还是需要用锁来保证独占性的，但是因为这两个阶段都很短，所以性能开销并不大。后两个阶段伪代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">validate_and_commit</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># phase 2 &amp; 3 with before-or-after</span>    <span class="token keyword">for</span> d <span class="token keyword">in</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>write_set<span class="token punctuation">)</span><span class="token punctuation">:</span>        d<span class="token punctuation">.</span>lock<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> d <span class="token keyword">in</span> read_set<span class="token punctuation">:</span>        <span class="token keyword">if</span> d has changed <span class="token keyword">or</span> d has been locked<span class="token punctuation">:</span>           abort<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> d <span class="token keyword">in</span> write_set<span class="token punctuation">:</span>        write<span class="token punctuation">(</span>d<span class="token punctuation">)</span>    <span class="token comment"># release the locks</span>    <span class="token comment"># ...</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>OCC 的问题在于经常会出现假阳性的 abort。所以当并发事务增多的时候，OCC 的性能并不好，其与 2PL 的对比如下：</p><p><img src="/posts/47da48a7/image-20250118211510893.png" alt="image-20250118211510893" style="zoom:50%;"></p><h4 id="3-3-3-HTM"><a href="#3-3-3-HTM" class="headerlink" title="3.3.3 HTM"></a>3.3.3 HTM</h4><p>HTM 即 Hardware Transactional Memory。从本质上讲，HTM 就是 OCC 思想的硬件实现。</p><p>Intel 在 Haswell 处理器上首次支持了了 HTM，被称为 Restricted Transactional Memory（RTM）。RTM 引入了 3 条新指令</p><pre class="line-numbers language-assembly" data-language="assembly"><code class="language-assembly">xbegin() ; 标识事务开始 xend() ; 标识事务开始 xabort() ; 标识事务中断<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>HTM 在实现上，使用 CPU Cache 来追踪 read/write_set，那如何探测 conflict 呢？是基于 Cache Coherency 实现的。</p><p>HTM 的问题在于支持的事务不能特别长，read/write_set 也不能特别大。</p><h4 id="3-3-4-MVCC"><a href="#3-3-4-MVCC" class="headerlink" title="3.3.4 MVCC"></a>3.3.4 MVCC</h4><p>OCC 在多并发读的性能不好，2PL 也是同样的，那么有没有什么方式可以优化多读少写的场景呢？</p><p>MVCC 即 multi-versioning concurrency control ，就是一种适应这种场景的新式版本控制方式。</p><p>其设计思路是维护 object 的多个 version，也就是多个 snapshot，用 time 作为版本号，这样可以避免并行读的竞争。</p><p><img src="/posts/47da48a7/image-20250118220106083.png" alt="image-20250118220106083" style="zoom:40%;"></p><p>其伪代码形式如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">Commit</span><span class="token punctuation">(</span>tx<span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token keyword">for</span> record <span class="token keyword">in</span> tx<span class="token punctuation">.</span>write_set<span class="token punctuation">:</span>        lock<span class="token punctuation">(</span>record<span class="token punctuation">)</span>   let commit_ts <span class="token operator">=</span> FAA<span class="token punctuation">(</span>global_counter<span class="token punctuation">)</span>   <span class="token keyword">for</span> record <span class="token keyword">in</span> tx<span class="token punctuation">.</span>write_set<span class="token punctuation">:</span>       record<span class="token punctuation">.</span>insert_new_version<span class="token punctuation">(</span>commit_ts<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>        unlock<span class="token punctuation">(</span>record<span class="token punctuation">)</span> <span class="token keyword">def</span> <span class="token function">Get</span><span class="token punctuation">(</span>tx<span class="token punctuation">,</span> record<span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token keyword">while</span> record<span class="token punctuation">.</span>is_locked<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token keyword">pass</span>   <span class="token keyword">for</span> version<span class="token punctuation">,</span>value <span class="token keyword">in</span> record<span class="token punctuation">.</span>sort_version_in_decreasing<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token keyword">if</span> version <span class="token operator">&lt;=</span> tx<span class="token punctuation">.</span>start_time<span class="token punctuation">:</span>           <span class="token keyword">return</span> value <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中 <code>commit</code> 是事务最终提交前的工作（主要是写操作），<code>get</code> 是读操作。</p><hr><h2 id="四、容错性"><a href="#四、容错性" class="headerlink" title="四、容错性"></a>四、容错性</h2><h3 id="4-1-RSM"><a href="#4-1-RSM" class="headerlink" title="4.1 RSM"></a>4.1 RSM</h3><p>增加容错最常用的方法，就是增加数据备份。这样即使出现网络错误，或者有什么物理 crash，备份的数据也保存完好。</p><p>但是让多个数据备份保持一致性，非常的困难。这里说的一致性，并不是上面的一致性，上面的一致性更侧重于从并发控制流角度的一致性，而这里的一致性更侧重于数据的一致性。</p><p>RSM 即 Replicated State Machine。它是人们提出的一种理论模型，这个理论指导了人们如何实现多个具有一致性的数据备份服务器。它将备份服务器视为状态机，只要初始状态一致，操作的顺序一致，那么最终状态就一定是一致的。这个理论将“让备份服务器保持一致”这个问题转换成了“让所有备份服务器的操作顺序一致”。</p><p>也就是说，我们需要确定一个唯一的执行序列（如果操作中有随机函数，还需要将执行结果记录下来），这样就能保证多个备份服务器的内容都一致了。</p><h3 id="4-2-Primary-Backup"><a href="#4-2-Primary-Backup" class="headerlink" title="4.2 Primary-Backup"></a>4.2 Primary-Backup</h3><p>很容易想到可以使用 Primary-Backup 机制来实现 RSM，也就是 Primary 负责接受用户请求，确定执行序列，然后发送给 Backup 让它执行。其形式如下：</p><p><img src="/posts/47da48a7/image-20250118222048627.png" alt="image-20250118222048627" style="zoom:33%;"></p><p>当 S1 挂掉了，那么 S2 就可以担任起备份的重任：</p><p><img src="/posts/47da48a7/image-20250118222217330.png" alt="image-20250118222217330" style="zoom:33%;"></p><p>这里图中只画了一个 Coordinator 用于将 clients 的请求转发给 Primary，而在实际的生产中，可能出现多个 Coordinator，这样可以更好地转发多个 client 的请求。此时就有可能出现问题了，就是一旦发生网络分区（Network Partition），如果两个  Coordinator  可能会选出两个 primary，如下所示：</p><p><img src="/posts/47da48a7/image-20250118222721272.png" alt="image-20250118222721272" style="zoom:33%;"></p><p>那这样每个 Primary 收到的请求就不一样了，不一致性自然就产生了。</p><p>所以我们提出了 View Server，说白了就是将“选出 Primary”这个任务指派给一个全局单例服务器上</p><p><img src="/posts/47da48a7/image-20250118222955428.png" alt="image-20250118222955428" style="zoom:33%;"></p><p>不过这种方法其实治标不治本，如果 VS 挂了怎么办？就没有办法解决了。只是说 VS 挂掉的可能性很小。</p><p>这种思路其实代表一种“中心化”的思路，即 Primary 是被某个中心权威（这个例子中是 VS）指定的。而当中心权威出现故障的时候，就无能为力了。</p><h3 id="4-3-Raft-共识算法"><a href="#4-3-Raft-共识算法" class="headerlink" title="4.3 Raft 共识算法"></a>4.3 Raft 共识算法</h3><p>共识算法是一种“分布式选举 Primary”的算法，这就避免了中心权威出现问题，进而导致系统不一致的情况出现。经典的共识算法有 Paxos 和 Raft。</p><p>Raft 于 2013 年由 Diego Ongaro 和 John Ousterhout 提出，旨在提供一种易于理解和实现的一致性协议。Raft 似乎是一个非常易懂的方式（比另一种 Paxos “希腊选举”），因为它论文里直接写伪代码了（面向工程师而非数学家）。不过似乎在设计上它比 Paxos 更反直觉。</p><p>具体的实现细节就不在这里写了。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、分布式系统&quot;&gt;&lt;a href=&quot;#一、分布式系统&quot; class=&quot;headerlink&quot; title=&quot;一、分布式系统&quot;&gt;&lt;/a&gt;一、分布式系统&lt;/h2&gt;&lt;h3 id=&quot;1-1-总论&quot;&gt;&lt;a href=&quot;#1-1-总论&quot; class=&quot;headerlink&quot; title=&quot;1.1 总论&quot;&gt;&lt;/a&gt;1.1 总论&lt;/h3&gt;&lt;p&gt;分布式系统指的是利用多个单体计算机系统构建的多体计算机系统。&lt;/p&gt;
&lt;p&gt;与并行计算不同，分布式系统更侧重于用多个计算实体完成&lt;strong&gt;非常多个&lt;/strong&gt;细碎的任务。而并行计算侧重于利用多个计算实体来更快更高效地完成&lt;strong&gt;一个&lt;/strong&gt;计算任务。&lt;/p&gt;
&lt;p&gt;分布式系统包括了执行流的分布式和数据的分布式。在北航 OO 课电梯问题中，涉及了多线程，属于是执行流的分布式，这就导致我以为分布式只是执行流的分布式，涉及的问题只是互斥和同步，这是非常片面的。数据的分布式指的是，存在多个数据副本，cache 就是一种数据分布式的实体。&lt;/p&gt;</summary>
    
    
    
    <category term="计算机系统" scheme="https://thysrael.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="计算机系统" scheme="https://thysrael.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="S9复习" scheme="https://thysrael.github.io/tags/S9%E5%A4%8D%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>计算机系统-虚拟化</title>
    <link href="https://thysrael.github.io/posts/670dae13/"/>
    <id>https://thysrael.github.io/posts/670dae13/</id>
    <published>2025-01-02T09:48:54.000Z</published>
    <updated>2025-08-15T12:16:49.046Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、CPU-虚拟化"><a href="#一、CPU-虚拟化" class="headerlink" title="一、CPU 虚拟化"></a>一、CPU 虚拟化</h2><h3 id="2-1-背景"><a href="#2-1-背景" class="headerlink" title="2.1 背景"></a>2.1 背景</h3><p>CPU 虚拟化范畴还挺多的，但是我们这里应该指的不包括不同 ISA 的虚拟化，而只是 CPU 的虚拟化，也就是虚拟出来的 CPU 和原本的 CPU 具有相同的 ISA 。</p><h3 id="2-2-Trap-amp-Emulate"><a href="#2-2-Trap-amp-Emulate" class="headerlink" title="2.2 Trap &amp; Emulate"></a>2.2 Trap &amp; Emulate</h3><p>为了虚拟化出多个 CPU，我们让虚拟的 OS 跑在用户态，也就是如下结构：</p><p><img src="/posts/670dae13/image-20250104222633971.png" alt="image-20250104222633971"></p><p>但是这种方式的问题在于，一旦执行到在 User mode 和 Kernel mode 行为不一致的指令的时候，那么就会导致出现 bug。</p><p>于是我们提出了 Trap&amp;Emulate 技术，它基于这样的一种观察：行为不一致的指令（被称作敏感指令）大部分都是特权指令或者访问特权寄存器，那么这种指令在 user mode 下指令，本身就会引发 trap，而 trap 到 Host OS 时，我们就用软件模拟执行的效果，也就是 Emulate。示意图如下：</p><p><img src="/posts/670dae13/image-20250104223628736.png" alt="image-20250104223628736" style="zoom:50%;"></p><p>而 Trap&amp;Emulate 技术有两点缺陷：</p><ul><li>并不是所有敏感指令都是特权指令，那么可能有些指令不会触发 trap，那么就导致这个部分 bug 了。这种行为敏感指令都是特权指令的特性被称为 strictly virtualizable，不幸的是，X86 ISA 就不是一种严格虚拟化的 ISA。</li><li>Trap 的性能开销过大。</li></ul><p>为了解决这些缺陷，我们又提出了新的技术。</p><h3 id="2-3-解决方案"><a href="#2-3-解决方案" class="headerlink" title="2.3 解决方案"></a>2.3 解决方案</h3><h4 id="2-3-1-Instruction-Interpreter"><a href="#2-3-1-Instruction-Interpreter" class="headerlink" title="2.3.1 Instruction Interpreter"></a>2.3.1 Instruction Interpreter</h4><p>也就是用软件模拟出一个 CPU 来，这样所有的指令并不是通过硬件执行的，而是通过软件模拟，这样就解决了不严格虚拟化的问题（所有的指令现在都是模拟执行了）。</p><p>Boch 就采用了这种思路。</p><h4 id="2-3-2-Binary-Translator"><a href="#2-3-2-Binary-Translator" class="headerlink" title="2.3.2 Binary Translator"></a>2.3.2 Binary Translator</h4><p>在执行代码前，需要先经过一个 translate 的过程，也就是将代码进行扫描，并将其中的敏感指令，替换成函数调用，这样就可以避免不一致问题了。</p><p>翻译的基本单位是基本块，并且翻译好的基本块会被放入 translation cache 中，下次如果还使用这个基本块的话，那么就直接使用了。至于为什么一基本块为粒度，可能是因为按指令为粒度，会频繁触发翻译拖慢速度；按可执行文件为粒度，很多执行不到的基本块其实是不需要翻译的。</p><p>Binary translation 有两个缺点：</p><ul><li>难以处理中断：在翻译后的代码中，中断只能在基本块边界处发生，而真实机器上中断可以在任何指令处发生。这可能导致精度问题，影响程序的实时性和响应能力。而且为了处理中断，需要在基本块边界保存和恢复CPU状态。这增加了上下文切换的开销和复杂性。</li><li>难以处理自修改代码（SMC）：为了检测自修改代码，必须监控对翻译后代码的写操作，这会引入额外的性能开销。</li></ul><p>如 VMware，Qemu。</p><h4 id="2-3-3-Para-virtualization"><a href="#2-3-3-Para-virtualization" class="headerlink" title="2.3.3 Para-virtualization"></a>2.3.3 Para-virtualization</h4><p>半虚拟化的设计思路是让 OS 意识到自己是一个虚拟机的 OS，对于敏感指令，就主动调一个 hypercall 自己 trap，这样就避免了被动 trap 不完全的情况。</p><h4 id="2-3-4-Hardware-Supported"><a href="#2-3-4-Hardware-Supported" class="headerlink" title="2.3.4 Hardware Supported"></a>2.3.4 Hardware Supported</h4><p>以 Intel 提供的 VT-x （x 是 eXtend 的意思）为例，它引入了 root 和 non-root 两个模式，non-root 模式下，只要遇到敏感指令，都会 trap，这样就避免了使用原本的特权机制来 trap 的缺陷。</p><p><img src="/posts/670dae13/image-20250104232230440.png" alt="image-20250104232230440" style="zoom:50%;"></p><p>此外，VTX 还提供了 VMCS ，用于保存了虚拟机的状态信息和控制信息，使 VMM 能够精确管理和恢复虚拟机的执行状态。</p><hr><h2 id="二、内存虚拟化"><a href="#二、内存虚拟化" class="headerlink" title="二、内存虚拟化"></a>二、内存虚拟化</h2><h3 id="2-1-背景-1"><a href="#2-1-背景-1" class="headerlink" title="2.1 背景"></a>2.1 背景</h3><p>首先强调，除了 <code>load</code>，<code>store</code> 指令会涉及虚拟地址的使用，<code>call</code>， <code>return</code>， <code>jump</code> 这样的指令同样会涉及虚拟地址的使用。</p><p>在虚拟化背景下，一共有 3 种地址：</p><ul><li>GVA：Guest Virtual Address</li><li>GPA：Guest Physical Address</li><li>HPA：Host Physical Address</li></ul><p>又有 3 种页表：</p><ul><li>GPT：Guest Page Table</li><li>HPT：Host Page Table</li><li>SPT：Shadow Page Table</li></ul><p>正因为有 3 种地址的存在，VM 的 GPA 并不是真实的物理地址，所以我们需要将其映射到真实的物理地址 HPA，这就是内存虚拟化要解决的问题。</p><p>下图展示了 3 种地址的关系，和两种解决办法：</p><p><img src="/posts/670dae13/image-20250107104440121.png" alt="image-20250107104440121" style="zoom:33%;"></p><h3 id="2-2-Shadow-Page-Table"><a href="#2-2-Shadow-Page-Table" class="headerlink" title="2.2 Shadow Page Table"></a>2.2 Shadow Page Table</h3><p>按理来说，因为需要完成 3 个地址之间的转换，所以需要 2 个页表，但是在早期，我们只有一个页表基地址寄存器，如 <code>CR3</code> 。所以我们如果想借助 MMU 的力量完成地址翻译，那么就需要想办法把两个页表融合成一个页表，这个页表直接完成 GVA -&gt; HPA 的地址翻译，这种页表被称作影子页表，shadow paging。</p><p>影子页表的构建就是遍历 GPT 和 HPT 的过程，其伪代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">set_cr3 <span class="token punctuation">(</span>guest_page_table<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> GVA <span class="token keyword">in</span> <span class="token number">0</span> to <span class="token number">220</span>        <span class="token keyword">if</span> guest_page_table<span class="token punctuation">[</span>GVA<span class="token punctuation">]</span> <span class="token operator">&amp;</span> PTE_P<span class="token punctuation">:</span>            GPA <span class="token operator">=</span> guest_page_table<span class="token punctuation">[</span>GVA<span class="token punctuation">]</span> <span class="token operator">&gt;&gt;</span> <span class="token number">12</span>            HPA <span class="token operator">=</span> host_page_table<span class="token punctuation">[</span>GPA<span class="token punctuation">]</span> <span class="token operator">&gt;&gt;</span> <span class="token number">12</span>            shadow_page_table<span class="token punctuation">[</span>GVA<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>HPA <span class="token operator">&lt;&lt;</span> <span class="token number">12</span><span class="token punctuation">)</span> <span class="token operator">|</span> PTE_P        <span class="token keyword">else</span>            shadow_page_table <span class="token operator">=</span> <span class="token number">0</span>     CR3 <span class="token operator">=</span> PHYSICAL_ADDR<span class="token punctuation">(</span>shadow_page_table<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>影子页表的维护也比较繁琐，主要有两个问题。一个问题是如果 VM 修改自己的 GPT 怎么办？实际上 GPT 并不存在，那么修改后不会有任何效果，所以我们需要 trap 这种修改行为（通过将 GPT 设置成只读的），并将修改同步到影子页表。</p><p>另一个问题是如果 Guest App 访问 Guest OS 的虚拟地址怎么办，因为此时 SPT 本质上是一个用户页表，所以也不存在用户地址空间和内核地址空间的隔离问题。我们可以准备两个 SPT，为 Guest App 提供的 SPT 中不包含 Guest OS 的地址映射，这样就解决了问题。</p><p>SPT 的优点在于对落后硬件的兼容性强，并且只需要一次地址翻译流程，访问时延较低。而缺点在于，对于页表的修改需要时时 trap，性能不佳。此外，SPT 的数目会非常膨胀（其实也不是太多），这是因为每个 SPT 对应一个 (GPT, HPT) 对，而每个 Guest App 都有自己的 GPT，这就导致 SPT 的数量和所有 VM 上的所有 App 一致。如果为了避免 Guest OS 地址空间被 Guest App 读写，还需要多一倍的 SPT。</p><h3 id="2-3-Direct-Paging"><a href="#2-3-Direct-Paging" class="headerlink" title="2.3 Direct Paging"></a>2.3 Direct Paging</h3><p>Direct Paging 是一种半虚拟化方法，也就是 Guest OS 使用 hypercall 来更新页表，并不能直接修改页表。页表记录的是 GVA -&gt; HPA 。</p><p>这个的好处是实现简单，而问题在于对于 VM 不透明，而且 VM 会获得更多 Host Memory 的信息，引发安全事故。</p><h3 id="2-4-Hardware-Support"><a href="#2-4-Hardware-Support" class="headerlink" title="2.4 Hardware Support"></a>2.4 Hardware Support</h3><p>硬件支持的方式就是拓展 MMU 的功能，使其可以完成二级翻译，如 Intel 的 EPT（Extended Page Table），AMD 的 NPT（Nested Page Table）。</p><p>而二级翻译最大的缺点是，二级页表的内存访问次数会过多。对于 4 级页表而言，一次地址翻译最多需要访问内存 20 次。</p><p><img src="/posts/670dae13/image-20250107123106563.png" alt="image-20250107123106563" style="zoom:50%;"></p><hr><h2 id="三、设备虚拟化"><a href="#三、设备虚拟化" class="headerlink" title="三、设备虚拟化"></a>三、设备虚拟化</h2><h3 id="3-1-背景"><a href="#3-1-背景" class="headerlink" title="3.1 背景"></a>3.1 背景</h3><p>我们希望一个真实设备可以供多个虚拟机使用，在此基础上，我们希望有如下功能：</p><ul><li>无论虚拟机想使用什么设备，我们都能模拟出来，这样便于迁移</li><li>虚拟机看到的设备应该是独占的</li></ul><p>为此我们开发了以下技术：</p><h3 id="3-2-Direct-access"><a href="#3-2-Direct-access" class="headerlink" title="3.2 Direct access"></a>3.2 Direct access</h3><p>指的是，每个 VM 都独占设备，并不存在设备同时给多个 VM 使用的情况。不过同一个设备可以在不同时间给不同的 VM 使用。</p><p>这就引出了一个问题，就是现代 DMA 设备，是可以访问物理内存的，那么一个 VM 就可以利用设备，去接触另一个 VM 的物理内存。为了解决这一点，Intel 引入了 VT-d 拓展，这个拓展提供了 IOMMU，IOMMU 里也有一套页表，用于完成 device addr 到 physical addr 的映射，切换 VM 的时候需要切换 IOMMU 中的页表，这样就限制了设备的访存能力，增强了隔离性：</p><p><img src="/posts/670dae13/image-20250104234121679.png" alt="image-20250104234121679" style="zoom:50%;"></p><p>这种 Direct Acess 的优点在于，性能非常好；而且 VMM 实现简单（基本上没有引入额外的功能）。但是缺点在于，只能提供特定的设备（host 上得有这个设备）；而且不利于拓展，如果有 100 个 VM 同时运行，难道要 100 个网卡吗？此外，也不利于 VMM 监控设备情况，因为 VM 有设备的全部控制权，VMM 不好拦截。</p><h3 id="3-3-Emulating-Devices"><a href="#3-3-Emulating-Devices" class="headerlink" title="3.3 Emulating Devices"></a>3.3 Emulating Devices</h3><p>我们也可以使用软件去模拟真实硬件（需要注意，有些模拟硬件功能的实现还是要依赖真实硬件，比如网卡收发包）。VM 使用设备时，会 trap 到 VMM，VMM 调用模拟器，如下所示：</p><p><img src="/posts/670dae13/image-20250104234817734.png" alt="image-20250104234817734" style="zoom:40%;"></p><p>这种方式的优势在于，可以模拟出多种硬件，而且允许插桩。但是缺点是性能较差。</p><h3 id="3-4-Para-Virtualized-Devices"><a href="#3-4-Para-Virtualized-Devices" class="headerlink" title="3.4 Para-Virtualized Devices"></a>3.4 Para-Virtualized Devices</h3><p>这种方式类似于 CPU 的半虚拟化，即 VM 知道自己使用的不是真实设备，而是虚拟设备。这样的好处在于，虚拟设备可以比真实设备更简单，软件栈更薄，比如说 virtio：</p><p><img src="/posts/670dae13/image-20250104235458673.png" alt="image-20250104235458673" style="zoom:50%;"></p><h3 id="3-5-Hardware-Support"><a href="#3-5-Hardware-Support" class="headerlink" title="3.5 Hardware Support"></a>3.5 Hardware Support</h3><p>我们也可以让设备自身具有虚拟化的能力（有点类似于虚拟地址空间的感觉）。这种能力被称为 SR-IOV。一个支持 SR-IOV 功能的设备，在 PCI 配置空间中呈现为“多个设备”。其物理功能部分被称为 PF，虚拟功能部分被称为 VF，如下图所示：</p><p><img src="/posts/670dae13/image-20250104235923446.png" alt="image-20250104235923446" style="zoom:30%;"></p><h3 id="3-6-总结"><a href="#3-6-总结" class="headerlink" title="3.6 总结"></a>3.6 总结</h3><p>虚拟化技术总结如下：</p><p><img src="/posts/670dae13/image-20250105000018381.png" alt="image-20250105000018381" style="zoom:40%;"></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、CPU-虚拟化&quot;&gt;&lt;a href=&quot;#一、CPU-虚拟化&quot; class=&quot;headerlink&quot; title=&quot;一、CPU 虚拟化&quot;&gt;&lt;/a&gt;一、CPU 虚拟化&lt;/h2&gt;&lt;h3 id=&quot;2-1-背景&quot;&gt;&lt;a href=&quot;#2-1-背景&quot; class=&quot;headerlink&quot; title=&quot;2.1 背景&quot;&gt;&lt;/a&gt;2.1 背景&lt;/h3&gt;&lt;p&gt;CPU 虚拟化范畴还挺多的，但是我们这里应该指的不包括不同 ISA 的虚拟化，而只是 CPU 的虚拟化，也就是虚拟出来的 CPU 和原本的 CPU 具有相同的 ISA 。&lt;/p&gt;
&lt;h3 id=&quot;2-2-Trap-amp-Emulate&quot;&gt;&lt;a href=&quot;#2-2-Trap-amp-Emulate&quot; class=&quot;headerlink&quot; title=&quot;2.2 Trap &amp;amp; Emulate&quot;&gt;&lt;/a&gt;2.2 Trap &amp;amp; Emulate&lt;/h3&gt;&lt;p&gt;为了虚拟化出多个 CPU，我们让虚拟的 OS 跑在用户态，也就是如下结构：&lt;/p&gt;</summary>
    
    
    
    <category term="计算机系统" scheme="https://thysrael.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="计算机系统" scheme="https://thysrael.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="S9复习" scheme="https://thysrael.github.io/tags/S9%E5%A4%8D%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>计算机系统-文件系统</title>
    <link href="https://thysrael.github.io/posts/15ec58e/"/>
    <id>https://thysrael.github.io/posts/15ec58e/</id>
    <published>2025-01-02T09:33:50.000Z</published>
    <updated>2025-08-15T12:16:49.038Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、数据结构"><a href="#一、数据结构" class="headerlink" title="一、数据结构"></a>一、数据结构</h2><h3 id="1-1-Inode"><a href="#1-1-Inode" class="headerlink" title="1.1 Inode"></a>1.1 Inode</h3><h4 id="1-1-1-整体结构"><a href="#1-1-1-整体结构" class="headerlink" title="1.1.1 整体结构"></a>1.1.1 整体结构</h4><p>Inode FS 被分为了 5 个区域“</p><p><img src="/posts/15ec58e/image-20250102215509118.png" alt="image-20250102215509118" style="zoom:40%;"></p><ul><li>SuperBlock：存储着后面分区的元数据</li><li>Inode Bitmap：记录着 Inode 区的使用情况</li><li>Data Bitmap：记录着 Data 区的使用情况</li><li>Inodes：所有 Inode 的数组，使用 Inode Number 索引，每个 Inode 记录着 Data 的组织形式</li><li>Data Region：数据区</li></ul><h4 id="1-1-2-文件"><a href="#1-1-2-文件" class="headerlink" title="1.1.2 文件"></a>1.1.2 文件</h4><p>在 Inode FS 中，每个文件对应一个 Inode。</p><p>Inode 是一种与页表非常相像的数据结构，都是利用偏移量来查找对应的数据块位置，所不同的是，Inode 的翻译是不均匀的（偏移量越大，需要的翻译级数越多），而页表的翻译是均匀的（无论偏移量是多少，翻译的次数都相同）。</p><p><img src="/posts/15ec58e/image-20250102214457730.png" alt="image-20250102214457730" style="zoom: 40%;"></p><p>有一种解释是，页表翻译是硬件过程，不太灵活；而 inode 的翻译是软件过程，所以可以设计的很灵活。我是觉得之所以 inode 设计得不均匀，是因为文件的大小是不固定且偏小的，所以大部分小文件可以直接翻译或者只使用一级翻译来完成。</p><p>至于为什么页表翻译要用硬件，是因为内存访问是一个很快的事情，如果用软件实现那就太慢了；相反，因为外存的访存速度过慢，软件翻译 inode 的过程并不构成关键路径。</p><p>当外存访存速度提升时（比如说用非易失内存做外存），就会导致软件翻译的速度变慢，原本的方法就不再适用了。</p><p>除了记录拥有的数据块以外，Inode 中还记录着文件的属性。</p><h4 id="1-1-3-目录"><a href="#1-1-3-目录" class="headerlink" title="1.1.3 目录"></a>1.1.3 目录</h4><p>Inode FS 的目录项，是由文件名和文件 Inode Number 组成的。我们检索文件名，就可以得到 Inode Number，然后根据 Inode Number 去 Inode 表中检索出对应的 Inode ，就可以访问对应的数据块了：</p><p><img src="/posts/15ec58e/image-20250102214950045.png" alt="image-20250102214950045" style="zoom:40%;"></p><p><code>/</code> 的 Inode Number 为 1。</p><p>如果我们希望访问 <code>/programs/pong.c</code>，那么访问磁盘 block id 的顺序是 <code>1(/ inode) -&gt; 14 (/ data) -&gt; 7 -&gt; (program inode) -&gt; 23 (program data) -&gt; 9(pong inode) -&gt; 61 (pong data)</code>  。</p><h4 id="1-1-4-链接"><a href="#1-1-4-链接" class="headerlink" title="1.1.4 链接"></a>1.1.4 链接</h4><p>硬链接指的是两个目录项都指向同一个 Inode Number，而软链接则是创建一个文件，里面是指向文件的文件名。可以说，硬链接是文件的指针，而软链接是指针的指针。如下所示：</p><p><img src="/posts/15ec58e/image-20250102220255509.png" alt="image-20250102220255509" style="zoom:33%;"></p><p>硬链接的一个重要作用是在不拷贝文件的情况下备份文件，可以避免对于文件的误删除。软链接就不可以，因为软链接与本身的文件并不平权，原文件一旦删除，软链接也就失去作用了。</p><h3 id="1-2-FAT"><a href="#1-2-FAT" class="headerlink" title="1.2 FAT"></a>1.2 FAT</h3><h4 id="1-2-1-整体结构"><a href="#1-2-1-整体结构" class="headerlink" title="1.2.1 整体结构"></a>1.2.1 整体结构</h4><p>FAT 即 File Allocation Table。是一种 Free-List 结构。它总共有 3 个区域：</p><p><img src="/posts/15ec58e/image-20250102222430225.png" alt="image-20250102222430225"></p><ul><li>SuperBlock：对应图上的“保留区域”，也被称为 BPB（BIOS Parameter Block）。</li><li>FAT 表：记录着文件的链表元数据，本质是一个 <code>next</code> 数组。一共有 2 个相同的拷贝，互为备份。</li><li>数据区：FAT 的数据块也被叫作簇，即 Cluster 。</li></ul><h4 id="1-2-2-文件"><a href="#1-2-2-文件" class="headerlink" title="1.2.2 文件"></a>1.2.2 文件</h4><p>FAT 中每个文件的所有数据块组成一个链表，链表的 <code>next</code> 域记录在 FAT 表中。如下图所示：</p><p><img src="/posts/15ec58e/image-20250102223119987.png" alt="image-20250102223119987"></p><p>单独把 <code>next</code> 域分离出来组成 FAT 表，是因为这样可以提高访存效率。此外，空闲的簇也会在 FAT 表中组织成一个 free list 。</p><h4 id="1-2-3-目录"><a href="#1-2-3-目录" class="headerlink" title="1.2.3 目录"></a>1.2.3 目录</h4><p>FAT 目录项记录着文件的起始簇号，根据起始簇号查阅 FAT 表，就可以顺序的读出所有的数据块。</p><p>最关键的是，文件的元数据不是存在 FAT 中的，而是存在目录项中。</p><h4 id="1-2-4-链接"><a href="#1-2-4-链接" class="headerlink" title="1.2.4 链接"></a>1.2.4 链接</h4><p>FAT 系统并不支持硬链接，因为两个目录项就有两份文件的元数据，这样维护一致性就太困难了。</p><h4 id="1-2-5-与-Inode-对比"><a href="#1-2-5-与-Inode-对比" class="headerlink" title="1.2.5 与 Inode 对比"></a>1.2.5 与 Inode 对比</h4><p>Inode 的设计，采用了类似页表的方式来记录和组织磁盘块，这种方式有利于随机访问；而 FAT 用链表的方式组织磁盘块，有利于顺序访问。</p><p>我个人觉得 FAT 更容易损坏，因为链表的特性就是，一旦一个节点损坏，那么后续节点都无法访问了。这可能也是为啥 FAT 表有双备份的原因。</p><p><img src="/posts/15ec58e/image-20250102224448955.png" alt="image-20250102224448955" style="zoom:150%;"></p><hr><h2 id="二、Crash-Consistency"><a href="#二、Crash-Consistency" class="headerlink" title="二、Crash Consistency"></a>二、Crash Consistency</h2><h3 id="2-1-背景"><a href="#2-1-背景" class="headerlink" title="2.1 背景"></a>2.1 背景</h3><p>有些文件操作需要更新 data 和 metadata 两个部分，而如果在这中间发生了 Crash，可能会导致出现一致性问题，也就是 data 和 metadata 不匹配的情况。为了解决这个问题，人们开发了多种方法，下面我们会介绍一些。</p><h3 id="2-2-Journaling"><a href="#2-2-Journaling" class="headerlink" title="2.2 Journaling"></a>2.2 Journaling</h3><h4 id="2-2-1-介绍"><a href="#2-2-1-介绍" class="headerlink" title="2.2.1 介绍"></a>2.2.1 介绍</h4><p>日志（journaling）指的是先将修改写到别的地方（journal），然后将修改进行原子性的提交（commit），最后再按照日志里的内容修改文件系统。</p><p><img src="/posts/15ec58e/image-20250102225924491.png" alt="image-20250102225924491" style="zoom:40%;"></p><p>按照这种设计，如果在 journal 阶段发生 crash，那么操作只是失败了，而原本的数据依然在文件系统中完好无损。commit 阶段是原子操作，不会被 crash。而如果在 overwrite 阶段发生 crash，那么文件系统的数据会被破坏，但是我们可以根据 journal 恢复损坏的部分。</p><p>Journaling 最大的问题是所有的数据都需要写两次，这样开销是不可接受的。所以我们退而求其次，我们只对 metadata 进行 journal 。也就是先写入 Data，然后再对 MetaData 进行 journaling ，最终效果如图。</p><p><img src="/posts/15ec58e/journal2.gif" alt="journal2" style="zoom:33%;"></p><h4 id="2-2-2-Journal-Order"><a href="#2-2-2-Journal-Order" class="headerlink" title="2.2.2 Journal Order"></a>2.2.2 Journal Order</h4><p>而在实际生产中，并不是只有 disk 这一层存在的，我们会在内存中构建一个 disk cache 用于提高访问 disk 的延迟。但是这种方式会导致我们写入 disk 的时候会存在乱序现象，也就是 A 先存入 disk cache，B 后存入 disk cache，但是 B 先从 cache 中写回，而 A 后写回，则在 disk 的角度，看到的是先 B 后 A，与在应用角度看到的先 A 后 B 是矛盾的。</p><p>而 Journaling 是依靠顺序的（order），这体现在，Data 和 MetaData Journal 的写入需要在 Journal Commit 之前，而 Journal Commit 需要在 MetaData 真正写入之前。为了确保顺序，我们使用了 flush 操作，最终效果如图：</p><p><img src="/posts/15ec58e/journal3.gif" alt="journal3" style="zoom:33%;"></p><p>但是 flush 操作又是极其影响性能的一个操作，所以我们一般不 flush，任由有可能出现的不一致性发生。</p><p>OptFS 是一种学界提出的解决 flush 低效的 idea，在上文中，主要有两个地方需要维护时序。OptFS 使用 checksum 技术来保证 Commit 一定在 Data 和 MetaData Journal 的写入之后发生，使用 Delay Write（似乎是一个硬件修改），来保证 MetaData 真正写入发生在前三者之后。</p><h3 id="2-3-Shadow-Paging"><a href="#2-3-Shadow-Paging" class="headerlink" title="2.3 Shadow Paging"></a>2.3 Shadow Paging</h3><p>还有一种叫作 Shadow Paging 的方式，也叫作 Copy-on-Write，指的是当涉及到写入文件系统的时候，并不直接 in-place write（overwrite）原本的文件，而是拷贝一个新的文件并写入，写入后，让目录项从原来的文件指向这个新的文件。</p><p><img src="/posts/15ec58e/image-20250104210055159.png" alt="image-20250104210055159" style="zoom:40%;"></p><p>Journaling 是先将修改写到日志中，然后再从日志中誊抄到真正的文件系统中，而 Shadow Paging 也是不先修改原本的文件，写到另一个地方去，但是并不需要再写一遍，不过它需要复制整个文件，而日志法，可能只需要记录 diff 部分，所以性能孰优孰劣，也并不好说。</p><p>Short-Circuit Shadow Paging 是一种学界提出的优化 Shadow Paging 的方法，简单来说就是利用原子变量来进行 in-place 操作，这样就避免了对整个文件的拷贝。</p><p><img src="/posts/15ec58e/image-20250104211213687.png" alt="image-20250104211213687" style="zoom:40%;"></p><hr><h2 id="三、NVMFS"><a href="#三、NVMFS" class="headerlink" title="三、NVMFS"></a>三、NVMFS</h2><h3 id="3-1-NVM"><a href="#3-1-NVM" class="headerlink" title="3.1 NVM"></a>3.1 NVM</h3><p>NVM 即 Non Volatile Memory，非易失性存储。这个概念我觉得应该要囊括磁盘这种传统外存，和现在新型的“非易失性内存”：</p><p><img src="/posts/15ec58e/image-20250104212311015.png" alt="image-20250104212311015" style="zoom:50%;"></p><p>在授课中，我们用 NVM 表示“非易失性内存”。NVMFS 就是基于非易失性内存开发的文件系统。</p><p><img src="/posts/15ec58e/image-20250104212755464.png" alt="image-20250104212755464" style="zoom:50%;"></p><p>NVM 的优点在于不再需要复杂的软件栈，因为与传统外存相比，我们使用访存指令就可以实现数据的访问；地址索引的方式，也不需要我们设计过于复杂的数据结构。而 NVM 的缺点在于，它的价格比传统外存贵，而性能又比传统内存差，性价比不高。</p><h3 id="3-2-挑战"><a href="#3-2-挑战" class="headerlink" title="3.2 挑战"></a>3.2 挑战</h3><p>NVMFS 的有一个挑战是，现在 cache 不再是由软件负责了（disk cache），而是由硬件 cache 负责，这就导致 NVMFS 很多乱序情况都更难处理（因为不如软件好操控）。</p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、数据结构&quot;&gt;&lt;a href=&quot;#一、数据结构&quot; class=&quot;headerlink&quot; title=&quot;一、数据结构&quot;&gt;&lt;/a&gt;一、数据结构&lt;/h2&gt;&lt;h3 id=&quot;1-1-Inode&quot;&gt;&lt;a href=&quot;#1-1-Inode&quot; class=&quot;headerlink&quot; title=&quot;1.1 Inode&quot;&gt;&lt;/a&gt;1.1 Inode&lt;/h3&gt;&lt;h4 id=&quot;1-1-1-整体结构&quot;&gt;&lt;a href=&quot;#1-1-1-整体结构&quot; class=&quot;headerlink&quot; title=&quot;1.1.1 整体结构&quot;&gt;&lt;/a&gt;1.1.1 整体结构&lt;/h4&gt;&lt;p&gt;Inode FS 被分为了 5 个区域“&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/posts/15ec58e/image-20250102215509118.png&quot; alt=&quot;image-20250102215509118&quot; style=&quot;zoom:40%;&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="计算机系统" scheme="https://thysrael.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="计算机系统" scheme="https://thysrael.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="S9复习" scheme="https://thysrael.github.io/tags/S9%E5%A4%8D%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>计算机系统-总论</title>
    <link href="https://thysrael.github.io/posts/cd771bfa/"/>
    <id>https://thysrael.github.io/posts/cd771bfa/</id>
    <published>2025-01-02T09:33:34.000Z</published>
    <updated>2025-08-15T12:16:49.037Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>那是 2023 年的夏天，楠神走出门，看向焦急等待的杰哥和我，问我们：</p><p>“你们知道“系统”和“体系结构”的区别吗？”</p></blockquote><h2 id="一、总论"><a href="#一、总论" class="headerlink" title="一、总论"></a>一、总论</h2><p>计算机系统这个系列，是我作为一名方向是 system 的研究生的，基于 IPADS 实验室开设的“计算机系统原理”等课程，整理而成的，并不保证正确性，因为 system 实在是浩如烟海，而我又太菜了。</p><p>在这篇博文里，我想谈谈我心目中的 system 是什么，这并不是 IPADS 课程的观点。</p><hr><h2 id="二、定义"><a href="#二、定义" class="headerlink" title="二、定义"></a>二、定义</h2><p>给 system 下一个定义，是我一直想干的事情。Wiki 百科和 ScienceDirect 都把 Compute System 定义为“一个由硬件、软件、数据组成的系统”。我觉得这个定义并不是很好，因为它是一句正确的废话，这个定义并不能指导科研。</p><p>还有一种方式，是将 system 定义为一套方法论和需求的集合。比如说在系统中常采用的方式是权衡、抽象、缓存、备份、并行和隔离等，而需求如下：</p><p><img src="/posts/cd771bfa/image-20250102194609112.png" alt="image-20250102194609112" style="zoom: 33%;"></p><p>这并不是全部的需求，但是好消息是 system researcher 经常在这个表中删除和增加条目。这种方式我觉得虽然和 system research 更加贴合，但是有些过于零散和变化，并没有一个核心的东西。</p><p>我想了很久，我现在觉得（也就是可能未来就改了），系统的定义是：</p><blockquote><p>在<strong>有限资源</strong>的封闭系统内，通过<strong>权衡（tradeoff）</strong>的方式，来达到我们的目的。</p></blockquote><p>对于这个定义，有如下细节：</p><ul><li>有限资源：系统并不能修改算法，因为算法可以将 $O(2^{n})$ 的方法优化成 $O(n)$ 的方法，这相当于凭空创造了资源；同样的，系统也不能修改硬件，不能优化 cache 的方式就是扩大 cache 容量，提高吞吐的方式是多买几个 GPU，这都是在系统中增加资源的方式。</li><li>权衡（tradeoff）：正因为资源是有限的，所以为了增强某项指标，就必须损害另一项指标。更进一步，为了更好的权衡，我们有诸多方法：<ul><li>牺牲一些我们不在乎的指标，增强一些我们看重的指标：其核心在于，寻找和发现那些我们并不在意的指标。</li><li>扩大系统范围：即使在当前系统中无法权衡，也可以通过将系统扩大的方式，包容进更多的资源，来进行权衡。这些资源可以是用户、硬件、算法、时间等（是的，这里违背定义的第一点了）。</li></ul></li></ul><p>在给出系统定义后，我还想在这里记录记录一下“抽象 abstract”，它不是系统的本质定义（封闭系统里的权衡），它只是多样复杂性与简单易用性的一种权衡。但是我正是出于对 abstract 和 complexity 的迷恋，而选择了 system 的方向。这种迷恋在我接触计算机之前就存在了，我小时候，是那种在熄灯后会一骨碌爬起来，恶狠狠地盯着窗帘思考这背后有什么的小屁孩。</p><p>我念研究生时，旧的时代已经过去，而新的时代还没有来临，希望它等等我。</p><p><img src="/posts/cd771bfa/image-20250102204434915.png" alt="image-20250102204434915" style="zoom:40%;"></p><hr><h2 id="三、意志"><a href="#三、意志" class="headerlink" title="三、意志"></a>三、意志</h2><p>虽然很不想承认，但是不得不承认，system 并不是自由发展的，它的发展深刻受到了社会需求和底层硬件的影响，总的来看，还是社会需求。</p><p>在最开始的时候，那时候的计算机还非常不人性化，冷冰冰的，人们研究的是操作系统内核和编程语言。</p><p>随着互联网时代的到来，人们研究的是并行、分布式、虚拟化、数据库。</p><p>而手机的普及，使得人们的研究焦点变成了安全、低功耗和异构计算。</p><p>现在 AI 时代来了，系统又会出现什么样的特征呢？这不取决于系统本身，这取决于 AI 。</p><hr>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;那是 2023 年的夏天，楠神走出门，看向焦急等待的杰哥和我，问我们：&lt;/p&gt;
&lt;p&gt;“你们知道“系统”和“体系结构”的区别吗？”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;一、总论&quot;&gt;&lt;a href=&quot;#一、总论&quot; class=&quot;headerlink&quot; title=&quot;一、总论&quot;&gt;&lt;/a&gt;一、总论&lt;/h2&gt;&lt;p&gt;计算机系统这个系列，是我作为一名方向是 system 的研究生的，基于 IPADS 实验室开设的“计算机系统原理”等课程，整理而成的，并不保证正确性，因为 system 实在是浩如烟海，而我又太菜了。&lt;/p&gt;
&lt;p&gt;在这篇博文里，我想谈谈我心目中的 system 是什么，这并不是 IPADS 课程的观点。&lt;/p&gt;
&lt;hr&gt;</summary>
    
    
    
    <category term="计算机系统" scheme="https://thysrael.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="计算机系统" scheme="https://thysrael.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="S9复习" scheme="https://thysrael.github.io/tags/S9%E5%A4%8D%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>吃喝玩乐-三周年</title>
    <link href="https://thysrael.github.io/posts/9925eca3/"/>
    <id>https://thysrael.github.io/posts/9925eca3/</id>
    <published>2024-12-18T09:55:40.000Z</published>
    <updated>2025-08-15T12:16:47.840Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、总论"><a href="#一、总论" class="headerlink" title="一、总论"></a>一、总论</h2><p>今天是 2024 年 12 月 18 日，距离我在北航新主楼 F534 的夜晚写下这个博客的 About 板块已经过去了 3 年时间，时间过得真是太快了。</p><p>这个博客能够坚持 3 年时间，最重要的原因是有人（当然我希望小姑娘多一些）去看我的博客，博客的读者是我更新的最大动力。感谢读者们的支持和反馈，没有你们就没有“钟鼓楼”。</p><p>当时我在博客里写了“我没有报六级，也没有报冬奥会志愿者，没有小姑娘需要陪”，三年后，我居然也还是“没有报六级，也没有报冬奥会志愿者，没有小姑娘需要陪”的状态，也算是不忘初心了，乐。</p><h2 id="二、回顾"><a href="#二、回顾" class="headerlink" title="二、回顾"></a>二、回顾</h2><p>回想起来，我窝在 F534 通宵写祭祖博客的日子还历历在目。那个时候 F534 还没有被“安全检查”，是北航的一个通宵好地方，很多二系兄弟在那里做实验，打打闹闹、互相欢谑的声音是最好的解压剂；那里还有很多“住在实验室”里的人，我每次看到角落里的饭盆、折叠床和小被子，都觉得这地方比我宿舍还有生活气息，我觉得就算丧尸爆发，F534 也可以靠这些物资成为末世之光，不过这个幻想在安全检查后破灭了；当然也有不是那么开心的事情，那里有可能会刷新出可恶的情侣，他们不但互相啃来啃去的，四条腿混在一起我都分不清谁是谁的。他们甚至还会抽空泡个面条，大冬天的腾起一个宏大的雾柱，这对于当时形单影只的我是一个巨大的刺激。</p><p>在我写完祭祖博客以后，我认识了很多很好的朋友，也当上了祭祖助教，可以说是春风得意了。如果你那时候就认识我，你或许可以看到我在北航的校园里，骑着那辆特别漂亮的邮差二八大杠，摇头晃脑地去图书馆写博客。我这段时间写了基本上将所有我想写的东西都写了个遍，我那段时间简直入魔了。现在我想起来我和我 OO 助教拍胸脯保证的要写的那些博客，都感觉非常羞耻，我那个时候想过写“IDEA 的快捷键”，但是直到现在，我其实都没有搞懂过 Java 项目的管理工具，我当时是怎么有自信纠结这种无聊的细节的？奥，我想起来了六系 21 级水群刚成立的时候，我在群里半推半让、暗戳戳地安利我自己的博客的时候的搞笑嘴脸，从外人角度看上去，应该还挺猖狂的吧。</p><p>再后来就到了大三下学期，我接了三个活儿：罗杰软工、操作系统比赛、保研。那段时间真的是啊，罗杰软工榨干了所有我的写博客的动力，当然其他事情其实也扎破了我为我自己吹起的幻象泡泡。那个学期我几乎没有更新我的博客，后面也没有补上。我对于大三下学期，我觉得是我做错了很多事情，我不过就是一个幼稚的孩子，喜欢提着别人的领子去问“我对没有对？你错没有错？”。再深入的思考我也没有勇气再进行了，我不知道最后的那个结果我是不是可以接受（这么看我比大一结束的时候还怂）。</p><p>后来我进了新的实验室，到现在也是这样，新实验室的有很多有趣的知识，任务也很紧（主要原因是我太菜了，本科四年光玩了），很少有时间能坐下来写博客了。而且新的知识相比于授课知识，也变得更加零碎无体系化，我将这些知识记录到 <a href="https://thysrael.github.io/Roam-Site/">roam</a> 里面，我也不确定这是一种形式上的进化，还是一种心灰意懒的妥协。</p><p>奥对了，后来那辆二八大杠我再也不骑了，那辆车的链条很久没有膏过油了，我再也骑不动了。我之前还喜欢在匿名提问箱里写东西，后来我收到了一个提问，他说他看完了我的所有回答，说我是一个虚伪的人。我不知道怎么回答这个提问，所以也不再用提问箱了。其他的事情，我也没有思考出什么确定的结论来，瑷。</p><h2 id="三、未来"><a href="#三、未来" class="headerlink" title="三、未来"></a>三、未来</h2><p>上交这边的课真的很有意思，无论是分布式和并行计算相关的课程，还是 Firmware 的课程，甚至是自然辩证法，经常是上完课后恨不得一拍大腿，说“原来是这样子的，我之前真是井底之蛙呀！”。我记了很多笔记，希望有时间能够整理好发到博客上，真的超级有趣！自然辩证法相关的东西已经被写到 roam 上了，但是其他的，我更希望是以正式博文的形式表达出来，但是这样难度很高。</p><p>另外这个学期我补充了很多西方的历史，把很多之前在脑子中零散的概念都梳理出来了，感觉以后吹逼小故事可以更加真实了，要是也有时间总结出来就好了。</p><p>另外我还希望写一些关于《金瓶梅》的东西，但是它真的好难读啊，每天下班后脑子晕晕的，根本读不进去呀！！！</p><h2 id="四、其他"><a href="#四、其他" class="headerlink" title="四、其他"></a>四、其他</h2><p>我有想过停更的，一直以来支持我写博客的动力都是有人看我的博客，但是，似乎今后再也没有人会看我写的东西了，我现在都不知道我在做什么，怎么能指望读者会知道呢？</p><p>但是我看到最刚毅的人使用了迂回的方式，最聪明的人选择了无聊，最真诚的人让人生厌。我觉得事情不应该是这样的，这个世界上，一定会有人，也应当有人，选择一条路走到黑，选择痛苦而不是无聊，而真诚，也应当有好的回报。所以我还是希望写下去，写到这样的人看到我的博客。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、总论&quot;&gt;&lt;a href=&quot;#一、总论&quot; class=&quot;headerlink&quot; title=&quot;一、总论&quot;&gt;&lt;/a&gt;一、总论&lt;/h2&gt;&lt;p&gt;今天是 2024 年 12 月 18 日，距离我在北航新主楼 F534 的夜晚写下这个博客的 About 板块已经过去了 3 年时间，时间过得真是太快了。&lt;/p&gt;
&lt;p&gt;这个博客能够坚持 3 年时间，最重要的原因是有人（当然我希望小姑娘多一些）去看我的博客，博客的读者是我更新的最大动力。感谢读者们的支持和反馈，没有你们就没有“钟鼓楼”。&lt;/p&gt;
&lt;p&gt;当时我在博客里写了“我没有报六级，也没有报冬奥会志愿者，没有小姑娘需要陪”，三年后，我居然也还是“没有报六级，也没有报冬奥会志愿者，没有小姑娘需要陪”的状态，也算是不忘初心了，乐。&lt;/p&gt;
&lt;h2 id=&quot;二、回顾&quot;&gt;&lt;a href=&quot;#二、回顾&quot; class=&quot;headerlink&quot; title=&quot;二、回顾&quot;&gt;&lt;/a&gt;二、回顾&lt;/h2&gt;</summary>
    
    
    
    <category term="吃喝玩乐" scheme="https://thysrael.github.io/categories/%E5%90%83%E5%96%9D%E7%8E%A9%E4%B9%90/"/>
    
    
    <category term="吃喝玩乐" scheme="https://thysrael.github.io/tags/%E5%90%83%E5%96%9D%E7%8E%A9%E4%B9%90/"/>
    
    <category term="S9课上" scheme="https://thysrael.github.io/tags/S9%E8%AF%BE%E4%B8%8A/"/>
    
  </entry>
  
  <entry>
    <title>沟通交流-学术写作</title>
    <link href="https://thysrael.github.io/posts/2d78b508/"/>
    <id>https://thysrael.github.io/posts/2d78b508/</id>
    <published>2024-11-28T02:07:14.000Z</published>
    <updated>2025-08-15T12:16:48.893Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>这本书是对《Science Research Writing For Non-Native Speakers of English》的总结梳理。这本书分为多个章节，每个章节对应一个论文写作里的部分。在每个章节内部，又有如下几个部分：</p><ol><li>介绍一下这个章节在整体文章中的作用</li><li>展示一篇例文</li><li>介绍一些基础的英语语法和词汇</li><li>对例文结构进行分析（分解成小组件），也就是他说的 model</li><li>对 model 进行一些心法层面的阐述，也就是他说的 key</li><li>按照 model 和 key 介绍一些固定词汇、句式和搭配，也就是他说的 vocabulary</li><li>最后让你自己写一个文章</li></ol><p>很多东西都是实践性质的，并非专业知识本身。所以如果总结的话，其实可以按照 model 的形式来组织 vocabulary ，其他的东西（比如例文、基础语法、动手实践）都可以省略，结构清晰。</p><p>因为时间问题，所以我会逐步更新这篇博文。</p><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p>这篇文章将一片论文分成了 5 个部分：</p><p><img src="/posts/2d78b508/shape.png" alt="shape"></p><ul><li>Abstract 用于提供一个对文章的总结</li><li>Introduction 初步介绍问题，帮助原本陌生的读者对问题的认识更加具象和熟悉</li><li>Methodology 用于描述自己是如何进行这项研究的</li><li>Results 用于描述研究的现象和结构</li><li>Conclusion/Discussion 用于升华主题，让具象问题变得抽象普适</li></ul><p>而对于计算机会议论文来说，在章节方面会有一定程度的细化。Introduction 部分会包括：</p><ul><li>Background: 介绍背景知识</li><li>Motivation: 介绍研究动机</li></ul><p>Methodology 部分会包括：</p><ul><li>Insight: 完成设计的核心思想</li><li>Design: 设计本身</li><li>Implementation: 具体的实现</li></ul><p>Results 部分会包括：</p><ul><li>如果一个新技术，那么需要指明技术的应用场景 Use Case ；如果是原有技术改进，那么需要指明 Baseline </li><li>Evaluation: 对设计的评估</li></ul><p>Conclusion/Discussion 部分会包括：</p><ul><li>Discussion: 负责将研究升华，提供一些更加定性和抽象的描述</li><li>Related Work: 用于和现有工作对比</li><li>Conclusion: 对上文的总结回顾，起行文上的收束作用（而 Discussion 则承担设计上的发散升华作用）。</li></ul><p>如果有机会，我希望按照更加符合计算机会议的方式重新组织一下这个模板。</p><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><h3 id="Revisit-the-Research-Aim-Exisiting-Research"><a href="#Revisit-the-Research-Aim-Exisiting-Research" class="headerlink" title="Revisit the Research Aim / Exisiting Research"></a>Revisit the Research Aim / Exisiting Research</h3><p>不要直接描述自己的实验结果，这样过于唐突了，要想办法把读者和后面的实验联系起来，比较有效的方法就是回顾前文或者已有的其他人的工作，这些都是对实验的一种背景介绍，一种铺垫。</p><p>对前文的回顾：</p><blockquote><p>as discussed previously, …<br>as mentioned earlier/before, ..<br>as outlined in the introduction, …</p></blockquote><p>对实验目的的回顾：</p><blockquote><p>in order to …, we examined …<br>it is important to reiterate that …<br>our aim/purpose/intention was to …<br>since/because …, we investigated …<br>to investigate …, we needed to …<br>the main purpose of this work was …<br>In this work, we sought to …</p></blockquote><p>对现有其他实验的回顾：</p><blockquote><p>as reported, …<br>it is known from the literature that …<br>the aforementioned theory/aim/prediction …<br>in earlier studies …</p></blockquote><p>对结果的预期：</p><blockquote><p>we reasoned/predicted that …<br>it was predicted that …</p></blockquote><h3 id="General-Overview-of-Results"><a href="#General-Overview-of-Results" class="headerlink" title="General Overview of Results"></a>General Overview of Results</h3><p>在介绍具体的实验之前，应当先给读者一个整体印象，这样才能避免读者陷入“流水帐式阅读”。整体印象应当包括我们的实验设置、实验目的、最终的实现效果。</p><p>对实验的总结概括：</p><blockquote><p>in this section, we compare/evaluate/present …<br>the results are divided into two parts as follows:</p></blockquote><p>对结果的总结概括：</p><blockquote><p>generally speaking, …<br>in general, …<br>in most/all cases, …<br>in the main, …<br>it is appparent that in all/most/the majority of cases, …<br>it is evident from the results that …<br>on the whole, …<br>the overall response was …<br>using the method described above, we obtained …</p></blockquote><h3 id="Invitation-to-View-Results"><a href="#Invitation-to-View-Results" class="headerlink" title="Invitation to View Results"></a>Invitation to View Results</h3><p>应当主动引导读者去看图或者看表，而不是只画图，而在正文里绝口不提。</p><p>对结果的被动引用：</p><blockquote><p>(see Fig)<br>according to Fig<br>as detailed/evident/illustrated/indicated/listed/shown from/in Fig<br>as can be seen/found/identified/observed from/in Fig<br>comparing Fig.1 and Fig.4 shows that …<br>displayed in Fig<br>evidence for this is in Fig<br>inspection of Fig indicates …<br>be given/represented/visible in Fig<br>in Fig we compare/present ….<br>results are given in Fig</p></blockquote><p>对结果的主动引用</p><blockquote><p>Fig contains/corresponds/demostrates/displays/gives/illustates/lists/plots/presents/provides/reports/represents/reveals/shows/summaries</p></blockquote><p>在引用结果时，某张图或者某张表的粒度可能过粗，可以更细一些，指向图中的某个具体数据：</p><blockquote><p>the data in Fig<br>the rate in Table<br>the results of Fig</p></blockquote><h3 id="Special-Key-Results-in-Detail"><a href="#Special-Key-Results-in-Detail" class="headerlink" title="Special/Key Results in Detail"></a>Special/Key Results in Detail</h3><p>讲究的是客观描述与主观判断的结合。</p><h4 id="Objective-Description"><a href="#Objective-Description" class="headerlink" title="Objective Description"></a>Objective Description</h4><p>这些词应当加上具体的数据来修饰，这样才能更有说服力和客观。比如说</p><blockquote><p>2% increase</p></blockquote><p>增加：</p><blockquote><p>accelerate<br>expand<br>increase<br>be higher/highest<br>peak<br>precede<br>rise</p></blockquote><p>减少：</p><blockquote><p>decline<br>decrease<br>delay<br>drop<br>fall<br>be lower/lowest<br>reduce</p></blockquote><p>变化：</p><blockquote><p>change<br>vary<br>be different<br>produce</p></blockquote><p>不变：</p><blockquote><p>be constant/unaffected/unchanged<br>remain constant/the same<br>level off</p></blockquote><p>存在：</p><blockquote><p>exist<br>find<br>range from<br>be found/seen<br>occur</p></blockquote><p>对比：</p><blockquote><p>be equal/indentical/uniform<br>match</p></blockquote><h4 id="Subjective-Description"><a href="#Subjective-Description" class="headerlink" title="Subjective Description"></a>Subjective Description</h4><p>数量评价：</p><blockquote><p>abundant<br>adequate<br>inadequate<br>minimal<br>negligible<br>imperceptible<br>few<br>brief<br>sufficient<br>scarce<br>substantial<br>immense</p></blockquote><p>程度评价：</p><blockquote><p>almost<br>largely<br>likelihood<br>more or less<br>somewhat<br>most<br>mild<br>virtual<br>considerable<br>general</p></blockquote><p>图表评价：</p><blockquote><p>clear<br>measurable<br>sharp<br>smooth<br>steep<br>sudden</p></blockquote><p>符合预期/不符合预期：</p><blockquote><p>acceptable<br>appreciable<br>appropriate<br>unexpected<br>unusual</p></blockquote><p>非常好/差：</p><blockquote><p>dramatic<br>drastic<br>essential<br>excellent<br>extensive<br>important<br>marked<br>noticeable<br>overwhelming<br>poor<br>remarkable<br>satisfactory<br>serious<br>severe<br>significant<br>simple<br>striking<br>strong<br>suitable<br>surprising<br>radical<br>rapid<br>valuable</p></blockquote><p>比较：</p><blockquote><p>comparable<br>consistent<br>distinct<br>equivalent<br>excessive<br>exceptional<br>extreme<br>fair<br>obvious<br>only<br>resembling<br>similar<br>dominant</p></blockquote><p>名词：</p><blockquote><p>tendency<br>the majority of<br>main</p></blockquote><h3 id="Comparison-with-Other-Results"><a href="#Comparison-with-Other-Results" class="headerlink" title="Comparison with Other Results"></a>Comparison with Other Results</h3><p>和其他已有成果对比是非常必要的，baseline 必须好好选取，才能增加说服力。</p><p>印证/推翻：</p><blockquote><p>as anticipated, …<br>as expected, …<br>as predicted by …<br>as reported by …<br>confirm<br>corroborate<br>disprove<br>inconsistent with<br>concur with<br>inline with<br>be in good agreement<br>prove<br>refute<br>reinforce<br>support<br>validate<br>verify</p></blockquote><p>优劣：</p><blockquote><p>compare well with<br>be better than</p></blockquote><p>相似性：</p><blockquote><p>consistent with<br>contrary to<br>match<br>be identical<br>be similar/dissimilar to<br>be parallel to<br>be unlike<br>correlate</p></blockquote><h3 id="Problems-with-Results"><a href="#Problems-with-Results" class="headerlink" title="Problems with Results"></a>Problems with Results</h3><p>似乎这个会被写入 future work 而不是 evaluation 中。</p><p>问题：</p><blockquote><p>immaterial<br>incompelte<br>infinitesimal<br>insignificant<br>less than ideal/perfect<br>a minor deficit/limitation</p></blockquote><p>转折：</p><blockquote><p>despite this<br>however<br>nevertheless</p></blockquote><p>开脱：</p><blockquote><p>at a preliminary attempt<br>neligible<br>not always/completely reliable/accurate/ideal/identical/clear/perfect/precise/significant<br>of no/little consequence/significance<br>only<br>reasonable results were obtain<br>room for improvement<br>slightly<br>a slight mismatch/limitation<br>somewhat<br>technicality<br>unimportant</p></blockquote><p>原因：</p><blockquote><p>may/could/might have been<br>beyond the scope of this study<br>be not the focus of this paper<br>be not within the scope of this paper<br>caused by<br>difficult to<br>due to<br>hard to control<br>inevitable<br>it should be noted that …<br>be not attempted/examined/expored in this study<br>possible sources of error<br>unavoidable<br>unexpected<br>unfortunately<br>unpredictable<br>unworkable<br>unavailable</p></blockquote><p>解决办法：</p><blockquote><p>futher work is planned<br>futher work should …<br>future work will<br>in future, care should be taken<br>in future, it is advised that</p></blockquote><h3 id="Possible-Implications-on-Results"><a href="#Possible-Implications-on-Results" class="headerlink" title="Possible Implications on Results"></a>Possible Implications on Results</h3><p>感觉似乎过于侧重 possible 了，有些让人感到虚弱了，不应该出现在这里。不应当成为一个必要的结构，而是应当成为一种行文的小修饰。</p><blockquote><p>apparently<br>could be due to / explained by / attributed to / interpreted as / seen as<br>could account for<br>evidently<br>imply that<br>indicate that<br>in some circumstances<br>be owing to / associated with / likely / linked to / related to<br>it appears that<br>it could be concluded/infered/speculated/assumed that …<br>it is conceivable …<br>it is evident<br>it is logical that<br>it is thought/believed that<br>plausible<br>suggesting<br>likely<br>may/might/perhaps<br>possibly/possiblity<br>potentially<br>presumably<br>probably<br>provide compelling evidence<br>tend to / tendency</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h2&gt;&lt;p&gt;这本书是对《Science Research Writing For Non-Native Speakers of English》的总结梳理。这本书分为多个章节，每个章节对应一个论文写作里的部分。在每个章节内部，又有如下几个部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;介绍一下这个章节在整体文章中的作用&lt;/li&gt;
&lt;li&gt;展示一篇例文&lt;/li&gt;
&lt;li&gt;介绍一些基础的英语语法和词汇&lt;/li&gt;
&lt;li&gt;对例文结构进行分析（分解成小组件），也就是他说的 model&lt;/li&gt;
&lt;li&gt;对 model 进行一些心法层面的阐述，也就是他说的 key&lt;/li&gt;
&lt;li&gt;按照 model 和 key 介绍一些固定词汇、句式和搭配，也就是他说的 vocabulary&lt;/li&gt;
&lt;li&gt;最后让你自己写一个文章&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;很多东西都是实践性质的，并非专业知识本身。所以如果总结的话，其实可以按照 model 的形式来组织 vocabulary ，其他的东西（比如例文、基础语法、动手实践）都可以省略，结构清晰。&lt;/p&gt;
&lt;p&gt;因为时间问题，所以我会逐步更新这篇博文。&lt;/p&gt;</summary>
    
    
    
    <category term="沟通交流" scheme="https://thysrael.github.io/categories/%E6%B2%9F%E9%80%9A%E4%BA%A4%E6%B5%81/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="S9课上" scheme="https://thysrael.github.io/tags/S9%E8%AF%BE%E4%B8%8A/"/>
    
    <category term="沟通交流" scheme="https://thysrael.github.io/tags/%E6%B2%9F%E9%80%9A%E4%BA%A4%E6%B5%81/"/>
    
  </entry>
  
  <entry>
    <title>并行计算-并行原语</title>
    <link href="https://thysrael.github.io/posts/cf617ad0/"/>
    <id>https://thysrael.github.io/posts/cf617ad0/</id>
    <published>2024-09-29T08:42:45.000Z</published>
    <updated>2025-08-15T12:16:48.804Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、总论"><a href="#一、总论" class="headerlink" title="一、总论"></a>一、总论</h2><p>在并行编程中，除了“互斥”这个原语外（一般是采用“锁”来实现），还存在“同步（synchronous）”这个原语，这个原语指的是“各个事件按照特定顺序执行”的需求。比如说在生产者消费者模型中，必须要让生产者先生产，消费者才可以进行消费，这就是一种同步行为，是没有办法仅仅依靠锁来实现的。</p><p>当涉及互斥时，涉及到的术语是 <code>lock, unlock, mutex</code> ，而涉及到同步是术语是 <code>wait, signal, notify, barrier</code> 等。之前我只重视了互斥的学习，而对于同步语义，则非常忽视。</p><hr><h2 id="二、互斥"><a href="#二、互斥" class="headerlink" title="二、互斥"></a>二、互斥</h2><p>上锁是维护互斥性的方式，只有拿到锁的线程，可以访问关键区域。</p><h3 id="2-1-自旋锁"><a href="#2-1-自旋锁" class="headerlink" title="2.1 自旋锁"></a>2.1 自旋锁</h3><p>自旋锁（Spinlock）是最为朴素的锁，它的形式是这样的：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token operator">!</span>condition<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// test lock</span>condition <span class="token operator">=</span> false<span class="token punctuation">;</span> <span class="token comment">// lock</span><span class="token comment">// do some critical thing...</span>condition <span class="token operator">=</span> true<span class="token punctuation">;</span> <span class="token comment">// unlock</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>只要不满足 <code>condition</code>，那么就会一直停留在 <code>while</code> 语句中执行。所谓的“自旋”，指的就是“自我重复循环”的意思。</p><h3 id="2-2-互斥锁"><a href="#2-2-互斥锁" class="headerlink" title="2.2 互斥锁"></a>2.2 互斥锁</h3><p>互斥锁（mutex，mutual exclusive）的形式如下：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token operator">!</span>condition<span class="token punctuation">)</span> <span class="token function">yield</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// test lock</span>condition <span class="token operator">=</span> false<span class="token punctuation">;</span> <span class="token comment">// lock</span><span class="token comment">// do some critical thing...</span>condition <span class="token operator">=</span> true<span class="token punctuation">;</span> <span class="token comment">// unlock</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>一旦条件检验不通过，自旋锁会立刻进行下一次条件检验，而互斥锁则会 <code>yield</code>，将执行权让给其他线程。自旋锁的设计，是在自旋的过程中依然占据资源，其优势在于并不会引入额外的上下文切换开销，当自旋时间不多的时候（也就是关键区比较短），那么用自旋锁比较合适。而如果关键区比较长，切换上下文开销小于资源占用的开销，那么就用互斥锁更为合适。</p><h3 id="2-3-CAS"><a href="#2-3-CAS" class="headerlink" title="2.3 CAS"></a>2.3 CAS</h3><p>上述的锁的实现都是“伪代码”，如果是 C 代码的话，是会存在问题的。考虑这样一个情形，此时有 A 和 B 都在等待 <code>condition</code> 发生变化，一旦 <code>condition</code> 变成 <code>true</code>，A 从 <code>while</code> 中离开，然后在“ A 设置 <code>condition = false</code> 来阻止其他的线程访问”这个时刻之前，突然调度器将 A 挂起，将 B 执行，此时 <code>conditon</code> 已然是 <code>true</code>，所以 B 也可以进入关键区，此时有两个线程在关键区，那么就发生了错误。</p><p>从上述描述中可以看出，发生错误的核心在于“检测 condition”和“设置 condition”这两个行为是没有绑定在一起的，一旦上下文切换发生在二者之间，就会导致发生错误。我们可以在硬件层面上将这两个行为统一成一个“原子行为”，一个常见的实现就是 CAS（Compare And Swap），其伪代码如下：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">int</span> <span class="token function">CompareAndSwap</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>ptr<span class="token punctuation">,</span> <span class="token keyword">int</span> expected<span class="token punctuation">,</span> <span class="token keyword">int</span> new<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">int</span> old <span class="token operator">=</span> <span class="token operator">*</span>ptr<span class="token punctuation">;</span>  <span class="token keyword">if</span><span class="token punctuation">(</span>old <span class="token operator">==</span> expected<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token operator">*</span>ptr <span class="token operator">=</span> new<span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token keyword">return</span> old<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到这个行为基本上就是检验旧值是否符合预期，如果符合预期就将旧值修改为新值，否则保持不变。此时就可以轻易实现一个自旋锁：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token function">lock</span><span class="token punctuation">(</span><span class="token class-name">lock_t</span> <span class="token operator">*</span>lock<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">while</span><span class="token punctuation">(</span><span class="token function">CompareAndSwap</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>lock<span class="token operator">-&gt;</span>condition<span class="token punctuation">,</span> true<span class="token punctuation">,</span> false<span class="token punctuation">)</span> <span class="token operator">==</span> false<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">void</span> <span class="token function">unlock</span><span class="token punctuation">(</span><span class="token class-name">lock_t</span> <span class="token operator">*</span>lock<span class="token punctuation">)</span> <span class="token punctuation">{</span>  lock<span class="token operator">-&gt;</span>condition <span class="token operator">=</span> true<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>突然想起来，<code>lock/unlock</code> 之间的关键区，也可以看作是原子性的，没有任何其他的指令可以插手这个区域。锁机制可以看作是对 CAS 原子性的一种拓展，原先只有一条指令是原子性的，现在是一个区域内的所有指令都是原子性的了。</p><p>我们设计关键区的时候，除了“共享”外，还可以从“不被打断”的角度去设计。 </p><hr><h2 id="三、同步"><a href="#三、同步" class="headerlink" title="三、同步"></a>三、同步</h2><h3 id="3-1-条件变量"><a href="#3-1-条件变量" class="headerlink" title="3.1 条件变量"></a>3.1 条件变量</h3><p>可以看到上述描述的互斥原语和锁机制，往往是发生在身份相同的线程中的，它们往往执行同一段代码，履行相同的职责，所以需要互斥机制来保证独立性。不过线程并不只有“竞争者”这一个身份，还有可能是”协作者“，此时他们就需要”同步“机制来确保他们的协同性。</p><p>同步机制比较简单的一个版本就是“先 <code>2</code> 后 <code>1</code>”，其中 <code>1</code> 和 <code>2</code> 是两个不同的线程，如果仅有锁机制，我们没法保证执行的顺序问题。但是如果当 <code>1</code> 先执行的时候，让它先 <code>wait</code> 一下 <code>2</code> ，直到 <code>2</code> 执行完了以后 <code>signal</code> 提醒一下它，它再加入就绪队列。其中 <code>1</code> 的“等待室”，就被称为条件变量（Condition Variable）。</p><p>基于这种思想，我们有了第一版代码：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">f1</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>arg<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token function">pthread_cond_wait</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cond<span class="token punctuation">,</span> <span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"I am f1\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">f2</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>arg<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"I am f2\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">pthread_cond_signal</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cond<span class="token punctuation">)</span>；<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>需要注意此时的 <code>cond_wait</code> 和 mutex 的 <code>yield</code> 不同，<code>yield</code> 是将线程加入到 OS 的待调度队列中，如果队列中没有其他线程了，那么等待锁的线程还是会反复被调用，而 <code>cond_wait</code> 是一个独立的等待队列，如果不被 <code>signal/notify</code> ，那么就永远不会被调度。这就导致在同步的应用中，常常出现有些线程在等待室里“醒不过来”的情况。</p><p>然后我们就会发现一个问题，就是如果 <code>2</code> 先执行完成呢？那么 <code>1</code> 就会一直 <code>wait</code> 下去，因为 <code>signal</code> 信号早就执行完了，这个问题被称为“唤醒丢失”。让我们再回顾需求，会发现其实 <code>1</code> 只有在 <code>2</code> 还没有执行的时候，才需要 <code>wait</code> ，如果本来就是 <code>2</code> 先执行，那么就无须 <code>wait</code> 了，我们可以用一个共享变量来指示是否线程 <code>1</code> 已经执行完了，于是我们得到了第二版：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">f1</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>arg<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token keyword">if</span> <span class="token punctuation">(</span>condition <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token function">pthread_cond_wait</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cond<span class="token punctuation">,</span> <span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"I am f1\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">f2</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>arg<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"I am f2\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>condition <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span><span class="token function">pthread_cond_signal</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cond<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但是这就有一个问题，就是 <code>condition</code> 作为共享变量，有可能出现“共同访问”的问题，比如先调度 <code>1</code> 时完成了对于 <code>condition == 0</code> 的检查，然后切换到了 <code>2</code>，并完成了 <code>signal</code>，然后再切换到 <code>1</code> 来执行 <code>wait</code>，那么就收不到信号了。那么此时就需要用锁来实现原子性，要保证对 <code>condition</code> 的访问和 <code>wait/signal</code> 是绑定在一起的，于是我们得到了第三版：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token class-name">pthread_cond_t</span> cond<span class="token punctuation">;</span><span class="token class-name">pthread_mutex_t</span> mutex<span class="token punctuation">;</span><span class="token keyword">int</span> condition <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">f1</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>arg<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token function">pthread_mutex_lock</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">if</span> <span class="token punctuation">(</span>condition <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token function">pthread_cond_wait</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cond<span class="token punctuation">,</span> <span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token function">pthread_mutex_unlock</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"I am f1\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">f2</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>arg<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"I am f2\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">pthread_mutex_lock</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span>condition <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span><span class="token function">pthread_cond_signal</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cond<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">pthread_mutex_unlock</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>由此可见即使在原本的实际中并不涉及共享内存（<code>1</code> 和 <code>2</code> 都只打印信息，并不访问共享内存），仅是处于同步的需求，条件变量也必须要和锁紧密配合。这就是在 POSIX 的条件变量的 API 中有锁的原因。</p><p>上述简单的例子已经结束了，但是条件变量依然还存在一个问题，也就是“虚假唤醒”。这个问题涉及到了条件变量的实现机制，线程在 <code>wait</code> 的时候，会将锁释放掉，当被其他线程 <code>signal</code> 的时候，它不是立刻执行，而是被放到了 OS 的待调度队列中，当调度到他的时候，他要再去拿锁然后执行，如果没有拿到锁，那么还会被重新插入到 OS 的待调度队列中等待（相当于隐式 <code>yield</code> 了）。</p><p>这种机制就存在一个问题了，就是在线程被 <code>signal</code> 唤醒后插入到待调度队列中，到真正拿到锁开始执行的这段时间内，有可能有其他线程修改了 <code>condition</code> 这样的条件，致使从语义上来说，线程应该继续 <code>wait</code>，而因为 <code>if</code> 的原因，使得线程逃离 <code>wait</code>，开始执行。所以我们最后要做的修改就是将 <code>if</code> 改成 <code>while</code>，如下所示：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">f1</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>arg<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token function">pthread_mutex_lock</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">while</span> <span class="token punctuation">(</span>condition <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token function">pthread_cond_wait</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>cond<span class="token punctuation">,</span> <span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token function">pthread_mutex_unlock</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>mutex<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"I am f1\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>从这个意义上来看，所谓的“signal 唤醒”，对于被唤醒的进程，并不能保证现在的唤醒符合“可执行”的条件了，而只是“可能可执行”，需要进一步的检查。</p><h3 id="3-2-信号量"><a href="#3-2-信号量" class="headerlink" title="3.2 信号量"></a>3.2 信号量</h3><p>不可否认，条件变量是丑陋的，他必须配合锁，而且还要搭配 <code>while</code> 才能使用。究其根本，是因为它具有“唤醒丢失”和“虚假唤醒”的问题。</p><p>“唤醒丢失”是因为条件变量本身不具有状态导致的，必须用一个共享变量来指导同步，如果我们将一个共享变量封装到其中呢？那我们是不是就不用显式的面对锁的问题了。而反正我们都将共享变量封装到其中了，与之相关的控制语句 <code>while</code> 也封装进去，也不是什么困难的事情了。于是我们就得到了信号量（Semaphore）。</p><p>信号量的本质是一个计数器 counter，它具有 <code>P</code> （<code>wait</code>）和 <code>V</code> （<code>post</code>）两种操作，<code>P</code> 会减少 counter 的值，如果 <code>counter == 0</code>，那么就会让发起 <code>P</code> 操作的线程进入“等待室”；<code>V</code> 会增加 counter 的值，如果 <code>counter &gt; 0</code>，那么就会唤醒等待室中的线程。</p><p>可以看到基本上信号量就是将原本的 <code>condition</code> 转换成了 <code>counter</code> 并封装进了自身内部。其实现如下：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token function">sem_wait</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">while</span><span class="token punctuation">(</span><span class="token function">CompareAndSwap</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>flag<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        s<span class="token punctuation">.</span>count<span class="token operator">--</span><span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>count <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token comment">/* 该线程进入 s.queue 队列 */</span>                <span class="token comment">/* 阻塞该线程（还需将 s.flag 设置为 0，阻塞和赋值需要是一个原子操作） */</span>        <span class="token punctuation">}</span>        s<span class="token punctuation">.</span>flag <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token function">sem_post</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">while</span><span class="token punctuation">(</span><span class="token function">CompareAndSwap</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>flag<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        s<span class="token punctuation">.</span>count<span class="token operator">++</span><span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>count <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token comment">/* 从s.queue 队列中移出线程 p */</span>                <span class="token comment">/* 线程 p 进入就绪队列 */</span>        <span class="token punctuation">}</span>        s<span class="token punctuation">.</span>flag <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>信号量是 System V 提出的机制，它足够强大，以至于仅凭这一个机制，就可以实现互斥和同步两种原语。</p><p>当信号量初始值为 <code>1</code> 的时候，他可以用作互斥，如下所示：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token class-name">sem_t</span> m<span class="token punctuation">;</span><span class="token function">sem_init</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>m<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">sem_wait</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 临界区</span><span class="token function">sem_post</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>而当信号量初始值为 <code>0</code> 时，可以用于同步，这是因为此时就必须先 <code>post</code> 后 <code>wait</code> 才可以避免阻塞：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">f1</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>arg<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token function">sem_wait</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"I am f1\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token function">f2</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>arg<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"I am f2\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">sem_post</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到信号量非常简洁美妙。</p><hr><h2 id="四、生产者消费者模型"><a href="#四、生产者消费者模型" class="headerlink" title="四、生产者消费者模型"></a>四、生产者消费者模型</h2><p>生产者消费者模型是非常经典的并行原语的应用。其中因为生产者和消费者会同时访问同一片共享区域，需要使用互斥机制；又因为当消费品为零或者满的时候，需要使消费者或者生产者 <code>wait</code> ，当条件满足时，又需要 <code>signal</code> 生产者和消费者，所以需要同步机制。</p><p>并不是所有的共享同一片内存，具有读写两方的模型都被叫作生产者消费者模型，生产者和消费者之间必须有同步机制来提高效率，这样才能叫作生产者消费者机制。同步机制是非常重要的，考虑生产者的效率是消费者的十倍，那么生产者必然很快就会填满缓冲区，随后生产者会重复拿锁进入缓冲区，并不干任何事情就离开，而消费者不容易拿到锁，机会被大量挤占，导致消费能力进一步降低。而有了同步机制，当产品填满缓冲区时，生产者就可以 <code>wait</code> 等待消费者唤醒了，这样更加高效。</p><p>生产者消费者模型有“阻塞队列”和“循环队列”两种形式，分别对应条件变量和信号量实现。循环队列的方式更优，因为阻塞队列是用一把锁保护整个共享区域，而实际上只要不是同时对于同一个商品读写，那么其实共享区域是允许同时存在一个生产者和一个消费者的，循环队列配合信号量可以很容易解决这个问题。</p><p>更加具体的描述和实现，可以在<a href="https://cloud.tencent.com/developer/article/2352249">这里</a>找到。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、总论&quot;&gt;&lt;a href=&quot;#一、总论&quot; class=&quot;headerlink&quot; title=&quot;一、总论&quot;&gt;&lt;/a&gt;一、总论&lt;/h2&gt;&lt;p&gt;在并行编程中，除了“互斥”这个原语外（一般是采用“锁”来实现），还存在“同步（synchronous）”这个原语，这个原语指的是“各个事件按照特定顺序执行”的需求。比如说在生产者消费者模型中，必须要让生产者先生产，消费者才可以进行消费，这就是一种同步行为，是没有办法仅仅依靠锁来实现的。&lt;/p&gt;
&lt;p&gt;当涉及互斥时，涉及到的术语是 &lt;code&gt;lock, unlock, mutex&lt;/code&gt; ，而涉及到同步是术语是 &lt;code&gt;wait, signal, notify, barrier&lt;/code&gt; 等。之前我只重视了互斥的学习，而对于同步语义，则非常忽视。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&quot;二、互斥&quot;&gt;&lt;a href=&quot;#二、互斥&quot; class=&quot;headerlink&quot; title=&quot;二、互斥&quot;&gt;&lt;/a&gt;二、互斥&lt;/h2&gt;</summary>
    
    
    
    <category term="并行计算" scheme="https://thysrael.github.io/categories/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/"/>
    
    
    <category term="直观理解" scheme="https://thysrael.github.io/tags/%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/"/>
    
    <category term="S9课上" scheme="https://thysrael.github.io/tags/S9%E8%AF%BE%E4%B8%8A/"/>
    
    <category term="并行计算" scheme="https://thysrael.github.io/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>海边拾贝-ExtMem</title>
    <link href="https://thysrael.github.io/posts/cbf91d56/"/>
    <id>https://thysrael.github.io/posts/cbf91d56/</id>
    <published>2024-08-26T12:31:23.000Z</published>
    <updated>2025-08-15T12:16:48.894Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文提出了一种用户态缺页异常处理框架，可以轻松适配不同的处理策略，适用于高并发环境。其亮点在于：</p><ul><li>框架的易用性：<ul><li>基于 Linux 的 Semi-Microkernel 设计</li><li>透明</li></ul></li><li>性能：<ul><li>采用了微内核和外核思想中的 upcall 设计</li><li>采用了先进的异步批处理 IO 后端 io_ring</li></ul></li></ul></blockquote><h2 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h2><h3 id="1-1-特化内存管理"><a href="#1-1-特化内存管理" class="headerlink" title="1.1 特化内存管理"></a>1.1 特化内存管理</h3><p>从软件层去看，目前内存密集型应用越来越多，如 TB 级的机器学习、大型图计算，内存数据库等。从硬件层去看，硬件新特性有很多，比如分离式内存、分层内存等。这些新的变化都对内存管理策略提出了新的挑战。</p><p>通用操作系统的内存管理策略并不适用于内存密集型应用，也不能针对性的利用硬件新特性。有研究表明最大的系统瓶颈是内存管理而不是设备带宽。</p><p>特化的内存管理策略（offload，prefetch，swap policy…）可以大大缓解这一现象。但是<strong>特化策略的普适性并不好</strong>。</p><h3 id="1-2-内核态内存管理"><a href="#1-2-内核态内存管理" class="headerlink" title="1.2 内核态内存管理"></a>1.2 内核态内存管理</h3><p>因为 Linux 内存管理模块十分基础、关键和复杂，所以在内核中开发、测试和部署一个新的内存管理策略开销非常大。大约 20 行代码即可描述的算法需要修改 20 个文件；测试开发需要 17 个月（和前面的不是同一个例子）；即使做出了，也很难被内核社区所接纳。</p><h3 id="1-3-用户内存管理框架"><a href="#1-3-用户内存管理框架" class="headerlink" title="1.3 用户内存管理框架"></a>1.3 用户内存管理框架</h3><p>“特化内存管理策略的有效性、不普适性和内核态内存策略的高昂开销”都在呼唤一个用户态的内存管理框架，也就是可以为多种内存管理策略提供支持的基础设施。</p><p>Linux 提供了 userfaultfd 机制来作为管理框架，用户基于此来实现用户态内存管理策略。框架的实现可以看作在进程中存在一个 manager thread，当一个 thread 发生 page fault 的时候，会通过基于 fd 的 IPC 方式（类似管道）给 manager thread 发信息报告自己缺失的地址等信息，manager thread 会根据相关信息进行处理。</p><p>本文认为这种方式并不适合高并发环境，采用 upcall 的方式和 ExoKernel 的理念去实现框架。</p><hr><h2 id="二、设计"><a href="#二、设计" class="headerlink" title="二、设计"></a>二、设计</h2><h3 id="2-1-upcall"><a href="#2-1-upcall" class="headerlink" title="2.1 upcall"></a>2.1 upcall</h3><p>Upcall 指的是从内核调用用户函数，可以看作是一种反向 syscall，常见于微内核系统，比如 chcore 中的 thread migration 机制。</p><p>传统的 userfaultfd 在高并发环境下存在延迟问题，这主要是由两方面原因组成：</p><p>一方面，线程的调度和切换开销很大，userfaultfd 下的 fault thread 和 MM thread 之间可能会插入多个其他无关线程（灰色虚线部分）：</p><p><img src="/posts/cbf91d56/userfaultsd.drawio.png" alt="userfaultsd.drawio"></p><p>而 upcall 可以由内核指定 MM thread 运行，并不需要调度：</p><p><img src="/posts/cbf91d56/extmem.drawio.png" alt="extmem.drawio"></p><p>另一方面，userfaultfd 的 MM thread 会串行处理 page fault，当多个线程都发生 page fault 的时候，会有排队现象：</p><p><img src="/posts/cbf91d56/userfaultfd1.drawio.png" alt="userfaultfd1.drawio"></p><p>但是利用 upcall 可以构造出 self-paging 机制，即 page fault handler 的本质是一个每个进程都有的库函数，发生 page fault 后内核会 upcall 进程自己的 handler 函数，这样多个 page fault handle 就可以并行了：</p><p><img src="/posts/cbf91d56/extmem2.drawio.png" alt="extmem2.drawio"></p><h3 id="2-2-io-uring"><a href="#2-2-io-uring" class="headerlink" title="2.2 io_uring"></a>2.2 io_uring</h3><p>内存管理可以分成前后端：前端负责处理 page fault 请求，分配页面完成映射；后端负责设备 I/O。</p><p>ExtMem 对于后端只要求 Direct I/O（也就是绕过 Linux 系统的 page cache），并没有对后端的同步和异步做出限制，ExtMem 自己使用了最为先进的 io_uring 机制。</p><p>之所以要强调这一点，是因为在后面的测试中，采用相同策略的 Linux 内核和 ExtMem 相对比，ExtMem 更占优势，它给出的解释是 ExtMem 在 evict 的代码更少，但是我觉得可能 io_uring 也发挥了一定的作用。</p><p>总得来说，io_uring 是 Linux 提供的一个先进的，异步的，非常适合批处理的 IO 接口：</p><p><img src="/posts/cbf91d56/io_uring.png" alt="img"></p><p>Linux 内部的 IO 使用的是中断驱动模式（应该是，不保真），而 io_uring 可以使用轮询模式。在高性能设备上，IO 的开销是小于上下文切换的开销的，所以轮询模式更优。</p><p><img src="/posts/cbf91d56/benchmark-1-1724747043453-9.png" alt="img"></p><hr><h2 id="三、实现"><a href="#三、实现" class="headerlink" title="三、实现"></a>三、实现</h2><h3 id="3-1-三层设计"><a href="#3-1-三层设计" class="headerlink" title="3.1 三层设计"></a>3.1 三层设计</h3><p>在设计上，该框架分为 3 层：</p><ul><li>core：和内核交互，实现监视虚拟地址，完成映射，IO 等基础功能</li><li>observability：提供对内存“冷热”等属性的信息</li><li>policy：提供实现具体策略所需要的 API。</li></ul><h3 id="3-2-链接与拦截"><a href="#3-2-链接与拦截" class="headerlink" title="3.2 链接与拦截"></a>3.2 链接与拦截</h3><p>为了用户的透明性（只 <code>mmap()</code> 等内存管理函数不需要修改），ExtMem 通过改变链接器的 <code>LD_PRELOAD</code> 变量实现了对于原有库函数的覆盖，通过使用 Intel libsyscall_intercept 技术实现了对于系统调用的覆盖。</p><h3 id="3-3-改写-UserFaultFD，SIGBUS"><a href="#3-3-改写-UserFaultFD，SIGBUS" class="headerlink" title="3.3 改写 UserFaultFD，SIGBUS"></a>3.3 改写 UserFaultFD，SIGBUS</h3><p>upcall 并不是 Linux 的原生机制，所以需要修改 Linux 内核支持 upcall：</p><p>一方面，ExtMem 复用了 Linux 信号机制中的 SIGBUS 信号，因为信号机制可以看作内核调用用户 handler，和 upcall 的语义近似。但是信号对于 handler 可重入性和线程安全的要求较高，为了功能的正常高效运行，ExtMem 削弱了一些原本的约束。</p><p>一方面，ExtMem 修改了 userfaultfd，使其不再通过基于 fd  的 IPC 通信，而是通过信号通信。</p><hr><h2 id="四、评估"><a href="#四、评估" class="headerlink" title="四、评估"></a>四、评估</h2><h3 id="4-1-评估环境"><a href="#4-1-评估环境" class="headerlink" title="4.1 评估环境"></a>4.1 评估环境</h3><p>如表所示：</p><div class="table-container"><table><thead><tr><th>条目</th><th>数据</th></tr></thead><tbody><tr><td>CPU</td><td>2.30GHz 的 Intel Xeon 5218 处理器</td></tr><tr><td>核心</td><td>16 个核心，每个核心 32 个硬件线程</td></tr><tr><td>内存</td><td>198GB 的 DDR4 内存</td></tr><tr><td>外存</td><td>读取速率为 2700 MB/s 的 NVMe SSD</td></tr><tr><td>操作系统</td><td>Linux 5.15</td></tr></tbody></table></div><h3 id="4-2-单次延迟"><a href="#4-2-单次延迟" class="headerlink" title="4.2 单次延迟"></a>4.2 单次延迟</h3><p>处理单个 page fault 的延迟如下：</p><p><img src="/posts/cbf91d56/image-20240827164626572.png" alt="image-20240827164626572"></p><p>其中 Upcall 指的是进行过性能优化的 SIGBUS 方法。</p><p>可以看到 UFFD 的方式在高并发环境下表现不良。而 ExtMem 则更好。</p><h3 id="4-3-相同策略吞吐"><a href="#4-3-相同策略吞吐" class="headerlink" title="4.3 相同策略吞吐"></a>4.3 相同策略吞吐</h3><p>他们在 ExtMem 上实现了和 Linux 相同的 2Q-LRU 逐出策略并进行测试。</p><p>使用 <code>mmap</code>  microbenchmark 去测试吞吐量，将 RAM 限制到 8G 来触发 page fault。</p><p>它测试了随机访存和顺序访存两种 pattern 下的吞吐</p><p><img src="/posts/cbf91d56/image-20240827165459110.png" alt="image-20240827165459110"></p><p>可以看到 ExtMem 都是优于 Linux，它论文中解释原因为 evict 的代码更简洁：</p><blockquote><p>The EXTMEM implementation evicts pages more quickly than Linux does, because its eviction code path is simpler, thereby explaining its performance advantage</p></blockquote><h3 id="4-4-预取"><a href="#4-4-预取" class="headerlink" title="4.4 预取"></a>4.4 预取</h3><p>在使用了预取策略后，我们评估 ExtMem 保留工作集的能力：</p><p><img src="/posts/cbf91d56/image-20240827170114740.png" alt="image-20240827170114740"></p><h3 id="4-5-CSR"><a href="#4-5-CSR" class="headerlink" title="4.5 CSR"></a>4.5 CSR</h3><p>压缩稀疏行（Compressed Sparse Row，CSR）是一种广泛用于内存图分析的数据结构。为使用 CSR 的应用开发一种新的内存管理策略：”将关键数据尽可能保存在内存中，并且利用一个滑动窗口的思想来指导数据的读入和逐出“，被称为 ”PR“。</p><p>运行 Twitter dataset using GAP benchmark suite 效果对比如下：</p><p><img src="/posts/cbf91d56/image-20240827170458158.png" alt="image-20240827170458158"></p><hr><h2 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h2><p>本文设计了一个用户态的内存管理策略框架，采用 upcall 机制来优化其在高并发环境下的表现，并且使用了一些工程技术来使得这个框架的易用性很好。</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;本文提出了一种用户态缺页异常处理框架，可以轻松适配不同的处理策略，适用于高并发环境。其亮点在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;框架的易用性：&lt;ul&gt;
&lt;li&gt;基于 Linux 的 Semi-Microkernel 设计&lt;/li&gt;
&lt;li&gt;透明&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;性能：&lt;ul&gt;
&lt;li&gt;采用了微内核和外核思想中的 upcall 设计&lt;/li&gt;
&lt;li&gt;采用了先进的异步批处理 IO 后端 io_ring&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;一、背景&quot;&gt;&lt;a href=&quot;#一、背景&quot; class=&quot;headerlink&quot; title=&quot;一、背景&quot;&gt;&lt;/a&gt;一、背景&lt;/h2&gt;&lt;h3 id=&quot;1-1-特化内存管理&quot;&gt;&lt;a href=&quot;#1-1-特化内存管理&quot; class=&quot;headerlink&quot; title=&quot;1.1 特化内存管理&quot;&gt;&lt;/a&gt;1.1 特化内存管理&lt;/h3&gt;&lt;p&gt;从软件层去看，目前内存密集型应用越来越多，如 TB 级的机器学习、大型图计算，内存数据库等。从硬件层去看，硬件新特性有很多，比如分离式内存、分层内存等。这些新的变化都对内存管理策略提出了新的挑战。&lt;/p&gt;
&lt;p&gt;通用操作系统的内存管理策略并不适用于内存密集型应用，也不能针对性的利用硬件新特性。有研究表明最大的系统瓶颈是内存管理而不是设备带宽。&lt;/p&gt;</summary>
    
    
    
    <category term="海边拾贝" scheme="https://thysrael.github.io/categories/%E6%B5%B7%E8%BE%B9%E6%8B%BE%E8%B4%9D/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="S8假期" scheme="https://thysrael.github.io/tags/S8%E5%81%87%E6%9C%9F/"/>
    
    <category term="海边拾贝" scheme="https://thysrael.github.io/tags/%E6%B5%B7%E8%BE%B9%E6%8B%BE%E8%B4%9D/"/>
    
  </entry>
  
  <entry>
    <title>面向对象-设计模式</title>
    <link href="https://thysrael.github.io/posts/94e7864c/"/>
    <id>https://thysrael.github.io/posts/94e7864c/</id>
    <published>2024-08-22T06:29:00.000Z</published>
    <updated>2025-08-15T12:16:49.123Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、总论"><a href="#一、总论" class="headerlink" title="一、总论"></a>一、总论</h2><p>设计模式是一个工程问题，它不能为某个问题提供具体的答案，它只能让答案写得好看一些。</p><p>更进一步地说，设计模式是用于解决代码复杂度高（不是算法复杂度）的问题，这会引发难以阅读，难以维护等伴生问题。当代码量小，复杂度低，没有什么维护需求的时候（比如说科研代码），其实是没有必要采用规范的设计模式的。</p><p>我个人学习设计模式，并不是为了写代码（因为我写的代码就是科研代码），而是为了更好的阅读代码，因为大型工程代码都会或多或少遵循设计模式的思路。</p><p>很多设计模式解决的复杂度问题，是客观存在的，认识这些问题有助于设计出更加简洁健壮的架构；但是有些问题可能只是类似 Java 等语言表述能力不够所导致的，不用太较真。</p><hr><h2 id="二、设计原则"><a href="#二、设计原则" class="headerlink" title="二、设计原则"></a>二、设计原则</h2><p>设计原则的目的同样是降低代码的复杂度。它可以看作是设计模式的“基本原理”，每个设计模式都或多或少贯彻了这些原则。</p><p>我们会介绍一些这些原则的具体内容，并简单描述一下这些原则是如何发挥作用的。总的来说，它们都是在描述“一个好的抽象”或者说“一个好的接口”，应该具有哪些性质（简洁、稳定、精妙、短小）。</p><h3 id="2-1-单一职责原则"><a href="#2-1-单一职责原则" class="headerlink" title="2.1 单一职责原则"></a>2.1 单一职责原则</h3><p>单一职责原则（Single Responsibility Principle）指的是每一个类仅负责一项职责，当然如果更普适一些的表述，是每一个代码模块（OOP 中的类，某个函数，某个库）只负责一项职责。</p><p>这是因为当代码模块以“功能”为单位划分的时候，就符合了“高内聚，低耦合”的思想，每个模块其实以一个抽象职责的实现。代码开发者通过付出“冥思苦想提炼抽象”的代价，获得了“模块化”的优势。</p><p>当我们说“六大原则”的时候，其实是将单一职责原则剔除的，是因为这个原则在语义表述上，一点也不“单一职责”，它的思想</p><h3 id="2-2-开闭原则"><a href="#2-2-开闭原则" class="headerlink" title="2.2 开闭原则"></a>2.2 开闭原则</h3><p>开闭原则（Open Close Principle）指的是代码需要保证对于拓展开发，而对于修改关闭。说白了，就是只能增加功能，不能删除和修改功能。</p><p>代码开发者通过付出“维护一个可能更大且更冗余的代码量”的代价，获得了“向后兼容性”的优势。如何尽量规避这种代价呢？那就需要在设计之初，就尽可能避免设计出一些稳定性不强、可发展性不强的接口，避免日后为了维持这个接口而付出过大的代价。</p><h3 id="2-3-里氏代换原则"><a href="#2-3-里氏代换原则" class="headerlink" title="2.3 里氏代换原则"></a>2.3 里氏代换原则</h3><p>里氏代换原则（Liskov Substitution Principle, LSP）指的是任何基类可以出现的地方，子类一定可以出现。也就是说，基类和子类是“接口-实现”的关系。</p><p>里氏规则明确了接口和实现的分离关系，这样无论实现怎么变化（多种接口），接口都可以保持稳定。</p><p>里氏规则要求写出来的代码遵循这样的一种原则“如果鸟（基类）是会飞的，鸵鸟是一种鸟，那么鸵鸟就应该会飞”。而不幸的是，鸵鸟真的不会飞。所以基类（其实就是接口）的实际人员，就要避免给接口设计出像“飞”这样的非普适功能，或者避免将“鸵鸟”加入“鸟类”。</p><h3 id="2-4-依赖倒置原则"><a href="#2-4-依赖倒置原则" class="headerlink" title="2.4 依赖倒置原则"></a>2.4 依赖倒置原则</h3><p>所谓的依赖倒置，就是一个代码模块，是它的接口决定了它如何实现，而不是它的实现决定了它的接口。实现依赖接口，而非反过来。</p><p>这是因为实现细节具有多变性，而接口需要相对稳定。</p><h3 id="2-5-接口隔离原则"><a href="#2-5-接口隔离原则" class="headerlink" title="2.5 接口隔离原则"></a>2.5 接口隔离原则</h3><p>接口隔离原则（Interface Segregation Principle）指的是接口之间的功能都要彼此隔离而不是耦合在一起（其实也是单一职责原则的一种体现）。这是因为耦合对于维护是不利的，耦合会让依赖增多。</p><h3 id="2-6-最小知道原则"><a href="#2-6-最小知道原则" class="headerlink" title="2.6 最小知道原则"></a>2.6 最小知道原则</h3><p>最小知道原则（Demeter Principle）指的是一个接口应该与尽量少的其他接口发生相互作用。也是减少依赖的方式。</p><h3 id="2-7-合成复用原则"><a href="#2-7-合成复用原则" class="headerlink" title="2.7 合成复用原则"></a>2.7 合成复用原则</h3><p>合成复用原则（Composite Reuse Principle）指的是要尽量使用组合的方式来拓展功能，而不是采用继承的方式拓展功能。因为继承方式在某种意义上，是将基类形成了一种接口，而有些基类并没有经过良好的设计（它实现的时候是别人的子类），这种继承会引入性质不优良的接口。</p><p>而组合只是拓展了功能，并没有引入新的抽象。</p><hr><h2 id="三、设计模式"><a href="#三、设计模式" class="headerlink" title="三、设计模式"></a>三、设计模式</h2><p>正如前所述，设计模式是针对特定场景来优化代码复杂度的方案，也就是哪里复杂了，哪里才需要设计模式。设计模式可以分成“创建型，结构型，行为型”三类，分别对应一个模块在创建时、静态结构上、动态运行逻辑上产生复杂度时的应对方案。</p><h3 id="3-1-创建型模式"><a href="#3-1-创建型模式" class="headerlink" title="3.1 创建型模式"></a>3.1 创建型模式</h3><h4 id="3-1-1-工厂方法"><a href="#3-1-1-工厂方法" class="headerlink" title="3.1.1 工厂方法"></a>3.1.1 工厂方法</h4><p>工厂方法解决的问题是，对于一个普通的对象创建，我们一般直接调用构造器方法，而这种方式有时的表达能力是不够强的。</p><p>比如说对于很多常量，我们并不需要每次都创建一个新的对象，我们可以共享对象，反正没人可以修改这些共享对象。但是只要一调用构造器，那么就会产生一个新的对象。再比如，我们希望采用批处理的形式构造对象，那么使用构造器就没有办法做到。</p><p>为了实现这些更多的语义，一个比较自然的想法就是在创建对象的上下文中加上一些代码，但是因为对象的创建可能弥散在各个地方，这些代码也会被复制很多份，就很复杂。所以更好的方法就是定义一个“工厂方法”，将这些语义集成进去，就更好维护了。</p><p>我觉得工厂方法是唯一值得介绍的创建型方法，因为只有它在将复杂的构造代码提炼出一个新的抽象。其他模式都可以看作是在工厂方法上做出的改进。</p><h4 id="3-1-2-抽象工厂"><a href="#3-1-2-抽象工厂" class="headerlink" title="3.1.2 抽象工厂"></a>3.1.2 抽象工厂</h4><p>也就是存在多个工厂，这些工厂有一个共同的父类“抽象工厂”，这样我们就可以用不同的工厂（相当于具体的实现）来实现不同的构造策略。</p><h4 id="3-1-3-生成器"><a href="#3-1-3-生成器" class="headerlink" title="3.1.3 生成器"></a>3.1.3 生成器</h4><p>它指的是将构造过程拆分成多个步骤，每个步骤使用一个工厂方法。这种方法的好处除了可以让代码模块更加小以外，也更加灵活了。我们可以通过组合不同的工厂，来满足比较复杂的构造需求。</p><p>比如说对于“两轮车，三轮车，四轮车”的生产，我们可以简单的构造“两轮车工厂，三轮车工厂，四轮车工厂”。当然我们也可以只维护“车壳工厂”和“车轮工厂”两个工厂来满足这种复杂的构造需求。</p><p>生成器本质是对于构造功能的解耦和自由组合。</p><h4 id="3-1-4-原型"><a href="#3-1-4-原型" class="headerlink" title="3.1.4 原型"></a>3.1.4 原型</h4><p>当我们存在复制一个对象的需求的时候，其实是有两种思路的，方案 1 ：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">A</span> <span class="token punctuation">{</span>    <span class="token keyword">int</span> x<span class="token punctuation">;</span>    <span class="token keyword">int</span> y<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">;</span>A a<span class="token punctuation">,</span> b<span class="token punctuation">;</span><span class="token comment">// copy a to b</span>b<span class="token punctuation">.</span>x <span class="token operator">=</span> a<span class="token punctuation">.</span>x<span class="token punctuation">;</span>b<span class="token punctuation">.</span>y <span class="token operator">=</span> a<span class="token punctuation">.</span>y<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这种方案是有复制需求的一方在完成复制过程。</p><p>方案 2 :</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">A</span> <span class="token punctuation">{</span>    <span class="token keyword">int</span> x<span class="token punctuation">;</span>    <span class="token keyword">int</span> y<span class="token punctuation">;</span>    <span class="token keyword">class</span> <span class="token class-name">A</span> <span class="token function">clone</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        A b<span class="token punctuation">;</span>        b<span class="token punctuation">.</span>x <span class="token operator">=</span> <span class="token keyword">this</span><span class="token operator">-&gt;</span>x<span class="token punctuation">;</span>        b<span class="token punctuation">.</span>y <span class="token operator">=</span> <span class="token keyword">this</span><span class="token operator">-&gt;</span>y<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span>A a<span class="token punctuation">;</span>A b <span class="token operator">=</span> a<span class="token punctuation">.</span><span class="token function">clone</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这种方案是有复制需求的一方只是调用 <code>clone</code> 方法，具体的方式是交给原型来做的。</p><p>当这种复制操作比较多的时候，显然第二种方式就比较好了；此外，当被复制的一方有私有数据时，也是第二种方式比较好。</p><h4 id="3-1-5-单例"><a href="#3-1-5-单例" class="headerlink" title="3.1.5 单例"></a>3.1.5 单例</h4><p>就是全局只有一个对象的情况，其实是和 Java 具体的语法联系比较紧密了，没有什么设计上的借鉴价值。</p><h3 id="3-2-结构型模式"><a href="#3-2-结构型模式" class="headerlink" title="3.2 结构型模式"></a>3.2 结构型模式</h3><h4 id="3-2-1-适配器"><a href="#3-2-1-适配器" class="headerlink" title="3.2.1 适配器"></a>3.2.1 适配器</h4><p>适配器模式是 Adapter，也称 Wrapper，是指如果一个接口需要 B 接口，但是待传入的对象却是 A 接口，怎么办？</p><p>那么就在 A 外面套一层满足 B 接口的适配器就可以了。</p><h4 id="3-2-2-桥接"><a href="#3-2-2-桥接" class="headerlink" title="3.2.2 桥接"></a>3.2.2 桥接</h4><p>其实这个模式很简单，它就是我们理解的“组合”，也就是每个部分只负责一些小的互相独立的功能，利用多个独立功能来组合完成复杂功能。</p><p>但是我很喜欢 Bridge 的概念，桥似乎在计算机术语中，描述的就是一种将多个功能模块组合在一起的概念，比如说芯片中的南桥和北桥芯片，网络中的桥接模式。</p><p><img src="/posts/94e7864c/bridge.png" alt="桥接设计模式"></p><p>它更像是一种“中间人”或者“平台”的概念，与汉语中的“连接和沟通两地”的概念有些出入。</p><h4 id="3-2-3-组合"><a href="#3-2-3-组合" class="headerlink" title="3.2.3 组合"></a>3.2.3 组合</h4><p>这里说的组合并不是和“继承”有对立关系的那个“组合”，而是一种树形结构，并且采用了递归处理：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">interface</span> <span class="token class-name">Node</span> <span class="token punctuation">{</span>    <span class="token keyword">private</span> <span class="token class-name">String</span> name<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Node</span><span class="token punctuation">&gt;</span></span> list <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">toXml</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token class-name">String</span> start <span class="token operator">=</span> <span class="token string">"&lt;"</span> <span class="token operator">+</span> name <span class="token operator">+</span> <span class="token string">"&gt;\n"</span><span class="token punctuation">;</span>        <span class="token class-name">String</span> end <span class="token operator">=</span> <span class="token string">"&lt;/"</span> <span class="token operator">+</span> name <span class="token operator">+</span> <span class="token string">"&gt;\n"</span><span class="token punctuation">;</span>        <span class="token class-name">StringJoiner</span> sj <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StringJoiner</span><span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> start<span class="token punctuation">,</span> end<span class="token punctuation">)</span><span class="token punctuation">;</span>        list<span class="token punctuation">.</span><span class="token function">forEach</span><span class="token punctuation">(</span>node <span class="token operator">-&gt;</span> <span class="token punctuation">{</span>            sj<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>node<span class="token punctuation">.</span><span class="token function">toXml</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> sj<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>总的来说就是树形结构的那些优点呗，局部的，递归的。</p><h4 id="3-2-4-装饰器"><a href="#3-2-4-装饰器" class="headerlink" title="3.2.4 装饰器"></a>3.2.4 装饰器</h4><p>装饰器（Decorator）模式，是一种在运行期动态给某个对象的实例增加功能的方法。</p><p>从实践角度来说，一些功能可能并不适合集成到类内部。比如说对某个类的“机械打印方法”，就是打印这个类的所有数据域（用于 debug）。这种方法显然不适合在类内部实现，不然每个类都要有这样的一个愚蠢的方法了。</p><p>所以我们可以将这个打印功能单独抽离出来，然后加到（装饰）所需要的类上，至于加的方法是基类、元编程还是什么其他手段，这就因实现而定了。</p><h4 id="3-2-5-外观"><a href="#3-2-5-外观" class="headerlink" title="3.2.5 外观"></a>3.2.5 外观</h4><p>外观模式，即 Facade ，它指的是：如果客户端要跟许多子系统打交道，那么客户端需要了解各个子系统的接口，比较麻烦。如果有一个统一的“中介”，让客户端只跟中介打交道，中介再去跟各个子系统打交道，对客户端来说就比较简单。</p><h4 id="3-2-6-享员"><a href="#3-2-6-享员" class="headerlink" title="3.2.6 享员"></a>3.2.6 享员</h4><p>享元（Flyweight）的核心思想很简单：如果一个对象实例一经创建就不可变，那么反复创建相同的实例就没有必要，直接向调用方返回一个共享的实例就行，这样即节省内存，又可以减少创建对象的过程，提高运行速度。</p><h4 id="3-2-7-代理"><a href="#3-2-7-代理" class="headerlink" title="3.2.7 代理"></a>3.2.7 代理</h4><p>代理模式，即 Proxy 。它和 Adapter 模式很类似，它们都是在原有类上在封装一层。</p><p>我个人觉得区别是，Adapter 是为了让功能可以正常使用，而 Proxy 视为了拓展功能的使用。比如说工厂方法就可以看作是构造方法的一种代理。</p><hr><h3 id="3-3-行为型模式"><a href="#3-3-行为型模式" class="headerlink" title="3.3 行为型模式"></a>3.3 行为型模式</h3><h4 id="3-3-1-责任链"><a href="#3-3-1-责任链" class="headerlink" title="3.3.1 责任链"></a>3.3.1 责任链</h4><p>行为型模式都是为了解决复杂的业务流而提出的。责任链的概念有些类似于流水线，每个人只负责处理一小部分业务逻辑。我个人感觉其实它更像是一堆筛网的集合，液体从中流过，滤出去了不同的东西。</p><p>这种模式下，增添一个筛网或者调整筛网的顺序，都是非常容易的，我甚至品出了流处理的精神。</p><h4 id="3-3-2-命令模式"><a href="#3-3-2-命令模式" class="headerlink" title="3.3.2 命令模式"></a>3.3.2 命令模式</h4><p>这说的是，对于每个操作，我们都让他们继承自一个叫做 <code>Command</code> 的基类，这样我们就可以对于这些操作进行统一的管理，比如我们可以 <code>undo, redo</code> 这些操作，至于我们为什么要对于这些操作进行统一的管理，可能这就是具体的情景要求了（比如一个编辑器中这种操作很常见）。</p><p>我个人觉得这种思想其实有些类似于“事务”或者“函数式”的思想了，将一段可执行代码当成一个类来操作。</p><h4 id="3-3-3-解释器"><a href="#3-3-3-解释器" class="headerlink" title="3.3.3 解释器"></a>3.3.3 解释器</h4><p>其实就是对于一些特定的问题，通用的编程语言会存在冗余繁复等问题，所以可以开发 DSL 来描述业务。解释器说的就是 DSL 的方法。</p><p>那么 DSL 的解释器的开发和维护难度呢？我觉得肯定是比不开发要难的，那我们为什么还需要 DSL 呢？我觉得是因为业务逻辑本身十分复杂且有规律，所以我们将原本的“业务逻辑复杂度”拆分成了“DSL 代码复杂度 + DSL 解释器复杂度”两个部分，或许这种拆分要比之前的复杂度要低。</p><h4 id="3-3-4-迭代器"><a href="#3-3-4-迭代器" class="headerlink" title="3.3.4 迭代器"></a>3.3.4 迭代器</h4><p>迭代器在 C++ Primer 中已经讨论滥了，它忽略了不同数据结构之间的差异，让我们可以以统一的方式遍历不同数据结构中的元素。也就是说，这是一种对于“迭代”这个操作的统一抽象。</p><h4 id="3-3-5-中介"><a href="#3-3-5-中介" class="headerlink" title="3.3.5 中介"></a>3.3.5 中介</h4><p>中介模式（Mediator）是通过引入一个中介对象，把多边关系变成多个双边关系，从而简化系统组件的交互耦合度。</p><p>说穿了，中介就是一个全局看板。</p><h4 id="3-3-6-备忘录"><a href="#3-3-6-备忘录" class="headerlink" title="3.3.6 备忘录"></a>3.3.6 备忘录</h4><p>备忘录模式（Memento），主要用于捕获一个对象的内部状态，以便在将来的某个时候恢复此状态。</p><p>我是觉得它和“原型”差不多。</p><h4 id="3-3-7-观察者"><a href="#3-3-7-观察者" class="headerlink" title="3.3.7 观察者"></a>3.3.7 观察者</h4><p>我觉得就是发布-订阅模式，是一种一对多的通知机制，使得双方无需关心对方，只关心通知本身。</p><h4 id="3-3-8-状态"><a href="#3-3-8-状态" class="headerlink" title="3.3.8 状态"></a>3.3.8 状态</h4><p>状态模式类似于状态机的理念，也就是根据状态产生不同的行为。</p><p>在具体的代码实现中，有一个 <code>State</code> 基类，它定义了一个 <code>process()</code> 纯虚方法，不同的状态继承这个基类并覆盖了 <code>process</code> 方法。</p><h4 id="3-3-9-策略"><a href="#3-3-9-策略" class="headerlink" title="3.3.9 策略"></a>3.3.9 策略</h4><p>策略模式：Strategy，是指，定义一组算法，并把其封装到一个对象中。然后在运行时，可以灵活的使用其中的一个算法。</p><h4 id="3-3-10-模板方法"><a href="#3-3-10-模板方法" class="headerlink" title="3.3.10 模板方法"></a>3.3.10 模板方法</h4><p>模板方法（Template Method）是一个比较简单的模式。它的主要思想是，定义一个操作的一系列步骤，对于某些暂时确定不下来的步骤，就留给子类去实现好了，这样不同的子类就可以定义出不同的步骤。</p><p>因此，模板方法的核心在于定义一个“骨架”。</p><h4 id="3-3-11-访问者"><a href="#3-3-11-访问者" class="headerlink" title="3.3.11 访问者"></a>3.3.11 访问者</h4><p>访问者模式（Visitor）是一种操作一组对象的操作，它的目的是不改变对象的定义，但允许新增不同的访问者，来定义新的操作。</p><p>有一说一非常复杂，我看懂了，但是我觉得没有什么特殊的。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、总论&quot;&gt;&lt;a href=&quot;#一、总论&quot; class=&quot;headerlink&quot; title=&quot;一、总论&quot;&gt;&lt;/a&gt;一、总论&lt;/h2&gt;&lt;p&gt;设计模式是一个工程问题，它不能为某个问题提供具体的答案，它只能让答案写得好看一些。&lt;/p&gt;
&lt;p&gt;更进一步地说，设计模式是用于解决代码复杂度高（不是算法复杂度）的问题，这会引发难以阅读，难以维护等伴生问题。当代码量小，复杂度低，没有什么维护需求的时候（比如说科研代码），其实是没有必要采用规范的设计模式的。&lt;/p&gt;
&lt;p&gt;我个人学习设计模式，并不是为了写代码（因为我写的代码就是科研代码），而是为了更好的阅读代码，因为大型工程代码都会或多或少遵循设计模式的思路。&lt;/p&gt;
&lt;p&gt;很多设计模式解决的复杂度问题，是客观存在的，认识这些问题有助于设计出更加简洁健壮的架构；但是有些问题可能只是类似 Java 等语言表述能力不够所导致的，不用太较真。&lt;/p&gt;</summary>
    
    
    
    <category term="面向对象" scheme="https://thysrael.github.io/categories/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"/>
    
    
    <category term="直观理解" scheme="https://thysrael.github.io/tags/%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/"/>
    
    <category term="面向对象" scheme="https://thysrael.github.io/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"/>
    
    <category term="S8 假期" scheme="https://thysrael.github.io/tags/S8-%E5%81%87%E6%9C%9F/"/>
    
  </entry>
  
  <entry>
    <title>计算机组成-乱序</title>
    <link href="https://thysrael.github.io/posts/af364ce6/"/>
    <id>https://thysrael.github.io/posts/af364ce6/</id>
    <published>2024-08-10T11:50:16.000Z</published>
    <updated>2025-08-15T12:16:49.056Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、总论"><a href="#一、总论" class="headerlink" title="一、总论"></a>一、总论</h2><p>乱序指的是指令并不按照顺序执行，所以这个概念比较接近软件编程中的“异步”概念（强调对于顺序时序的破坏）。而我之前似乎一直把它和“并行”挂钩（强调对于共享资源的争用）。这种认识倒也不算是错误，目前学了一圈下来，感觉其实和两个概念都有关系。</p><p>在顺序模型下，指令是一条条阻塞执行的，必须前一条指令执行完，才能执行后一条指令。那么如果前一条指令非常花时间，那么后一条指令就只能阻塞等待。这个问题是用流水线解决不了的。流水线中的指令也需要顺序执行。而乱序执行就打破了这种顺序执行的阻塞性，使得前序和后序指令可以并行执行。</p><hr><h2 id="二、冒险（hazard）"><a href="#二、冒险（hazard）" class="headerlink" title="二、冒险（hazard）"></a>二、冒险（hazard）</h2><p>我们希望 CPU 按照理想情况运行，那么什么是理想情况？对于单个处理器核心，当：</p><script type="math/tex; mode=display">指令执行速度 = 时钟频率 \times 流水线深度 \times 数据通路条目</script><p>时就是理想情况了。而在现实生活中，常常因为多种现实因素使得指令的执行速度减慢，这些现实因素被称为“冲突（hazard）”。具体有 3  种：</p><ul><li>结构冲突（structure）：指的是对于功能单元的竞争情况，比如两个指令都需要 ALU，而只有一个 ALU，那么这两条指令就只能串行。</li><li>分支冲突（branch）：指的是因为分支而导致的指令流中断，比如突然发现正在执行的指令属于不会被执行的分支，那么这些指令都需要撤销。</li><li>数据冲突（data）：指令需要的数据还没有被前一条指令计算出来，那么就会导致阻塞。</li></ul><p>CPU 种有很多功能单元（也可以看作计算资源），我们希望让他们都运转起来，不要闲置或者做无用功。但是每条指令并不会“同时”使用这些资源，比如对于一条指令的执行，只要取出指令后，就不需要再从 I-Cache 中读值了，当这条指令让 ALU 进行运算的时候，Fetch，Decode，Write Back 这些单元是闲置的。所以我们发明了流水线技术，将功能单元划分到不同的流水级，每个流水级都运行一条指令，这样就可以并行利用不同的资源。但是这样还不够，因为可能一个阶段里还有很多个功能单元，比如说 Execute Stage 里就有整数计算单元，浮点数计算单元，访存单元等，这些单元想要满载运转，就不能再采用流水线技术了，因为这些资源并不是每条指令都会用到，如果我们将 Execute Stage 拆分成 Calculate Stage 和 Memory Stage ，那么 Memory Stage 的资源就会在执行计算指令时被闲置，而 Calculate Stage 的资源则会在执行访存指令时被闲置，所以我们可以采用乱序的方式，让一个流水级中包含多条指令，比如 Execute Stage 就可以同时包含一条计算指令和一条访存指令，这样资源就可以得到更充分的利用。</p><p>总得来说，我们可以利用流水线技术和乱序技术对 CPU 内的资源进行不同维度的并行操作：</p><p><img src="/posts/af364ce6/cpu.png" alt="cpu"></p><p>从这个角度看，流水线深度并不是越深越好，因为被时序分割的资源，并不会在每条指令上得到充分利用，反而是乱序的方式，更能充分利用资源。</p><p>总得来说，我们对于明显有依赖关系的资源，会采用流水线的方式来并行，比如说取指单元和译码单元的流水线处理；而对于没有依赖关系的资源，我们会采用乱序的方式并行，比如访存单元和计算单元的乱序。更进一步辩证地看，在同一级流水线中，一定存在没有依赖关系的资源，那么就是可以乱序的；在</p><hr><h2 id="三、算法"><a href="#三、算法" class="headerlink" title="三、算法"></a>三、算法</h2><p>我觉得我自己之所以谈到更加高级的 CPU 特性，比如说乱序、分支预测谈虎色变，是因为我在心里认为在硬件上是没有办法实现过于复杂的算法的。但是这种观点是很不精确的，硬件和算法的复杂程度没有必然联系，不过确实在硬件上实现的算法会有一些硬件特征。</p><p>首先是在 CPU 中是没有内存的，所以也就没有地址。这里很容易产生一个误导，就是同样没有指针。这是不对的，算法需要的并不是一个具体的指针，它只需要一个“指向某个数据的变量”即可，所以没有指针，也可以用整型索引代替。这有点像算法竞赛在实现链表，树之类的数据结构的时候，都不会使用指针，而是提前开一个大数组，然后用索引来指向其中的元素的思想。</p><p>然后是在 CPU 中没有像高级语言的“无限”概念的，任何资源都是有数量限制的。不仅是资源的数量有限制，资源的规模也有限制，比如说一个整数寄存器，就是 32 位，如果希望表达一个更大的数，那么就没有办法了。不过这种限制其实很好解决，只需要阻塞 CPU 直到相关资源富裕就可以了，常见的问题有空闲物理寄存器数目不够，指令编号溢出，队列溢出等。</p><p>还有一种解决资源有限的方法，是将资源的状态都保存到内存中，不过这种方法在微体系结构中用得不多（时间开销太大），但是在编译器开发中很常见。</p><p>最后是 CPU 上的算法的局部性很强，而且是只有一遍的，我们只能看到 CPU 上运行的这几条指令，或者还有一些 buffer 指令，而且只能看见一次。这就导致很多全局算法我们是没有办法直观实现的，但是我们可以采用一种像“流”或者是“滑动窗口”的思想去从局部推断全局。</p><p>总得来说，CPU 的性质使得它在描述算法或者数据结构的时候，会呈现一种朴素的，有限的、狭隘的特征，但是基本上没有算法是用 CPU 无法表示的（复杂的森林和图都是可以的），所以当我们去看 CPU 上的特征时，应当从它笨拙的表达中，看出其背后的精妙算法。</p><hr><h2 id="四、假冒险"><a href="#四、假冒险" class="headerlink" title="四、假冒险"></a>四、假冒险</h2><p>这里讨论的真假冒险都是数据冒险的一种，其实就是对于数据依赖关系的讨论。出现数据冒险问题，是优于前序指令（一个装逼的说法，就是在汇编中位置靠前的指令）晚于后序指令提交造成。</p><p>所谓的真冒险，就是“写后读”（Read After Write，RAW），吐槽一句，可以发现在中文这个词是先写后读，而在英文中变成了下先 R 后 W，刚好是反过来的，后面我只用英文。至于为什么它是真冒险，是因为只有前序指令写入了这个数据，后序指令才能读入新的值。</p><pre class="line-numbers language-asm" data-language="asm"><code class="language-asm">write r0read r0 # commit first, error<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>与之相对的，有 WAR 和 WAW 两种假冒险。对于 WAR 而言，先序指令读，后序指令写，我们担心的是，后序指令先提交的情况，但是如果后序指令没有提交到原本的寄存器中呢，那么就不存在问题了，换句话说，如果有无限个寄存器（类似于无限个变量），那么谁还为了省一些寄存器，而去覆盖一个可能还会被读的寄存器。</p><pre class="line-numbers language-asm" data-language="asm"><code class="language-asm">read r0write r0 # commit first, error### good ###read r0write r1 # commit first, correct<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>至于如何让寄存器变成无限个，那其实就又很多种办法了，大不了阻塞 CPU 嘛。当然在实际应用中，我们会通过重命名的手段，在内存中维护一个从逻辑寄存器到实际寄存器的映射关系，来使得不会发生依赖现象，这就是寄存器重命名。</p><p>而寄存器重命名算法，在原理上和编译器的寄存器分配算法的需求是一样的，唯一的区别在于编译器的逻辑寄存器不够了，那么就会往栈上存，而 CPU 的物理寄存器不够了，就会阻塞 CPU。当然了，像图着色或者线性扫描这种方法是没法用到 CPU 上，CPU 一般就是维护一个空闲寄存器队列就够了。</p><hr><h2 id="五、计分板"><a href="#五、计分板" class="headerlink" title="五、计分板"></a>五、计分板</h2><blockquote><p>从任何意义上说，寄存器就是内存的一个过客。</p></blockquote><p>如果我们拨开 ISA 的复杂性的迷雾，就会发现 CPU 的核心在于“读入内存，计算，写入内存”的图灵机模式，其中的计算步骤，其实就是构建一个计算的 DAG 图（有向无环图），其结构如下：</p><p><img src="/posts/af364ce6/dag.drawio.png" alt="dag.drawio"></p><p>寄存器的作用就是存储这些 DAG 图的中间节点。这里面的 <code>(1), (2), (3)</code> 可能就分别对应某个寄存器。</p><p>所谓的计分板，就是描述这幅图的数据结构，他的每个条目就是图上的一个点</p><div class="table-container"><table><thead><tr><th>ID</th><th>ready</th><th>child</th></tr></thead><tbody><tr><td>(1)</td><td>false</td><td>a, b</td></tr><tr><td>(2)</td><td>false</td><td>(1), a</td></tr><tr><td>(3)</td><td>true</td><td>b, d</td></tr></tbody></table></div><p>那么为什么要保留这样的一个结构，因为这个结构非常方便查看是否允许并行并处理相关的数据依赖。</p><p>比如在计分板上，我们就知道 <code>(2)</code> 这条指令还没有办法进行计算，因为 <code>(1)</code> 还没有算完，但是 <code>(3)</code> 已经可以算了，也就是 <code>(1), (3)</code> 可以并行计算，而 <code>(2)</code> 不可以。我们还可以看出 <code>(1), (3)</code> 都依赖 <code>b</code> 这个节点。而且这里的 ID 可以理解成一种逻辑寄存器，我们可以将其分配给物理寄存器。</p><p>总之计分板就是这样的一个全局看板结构，基于 DAG 图的方式来协调乱序并行。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、总论&quot;&gt;&lt;a href=&quot;#一、总论&quot; class=&quot;headerlink&quot; title=&quot;一、总论&quot;&gt;&lt;/a&gt;一、总论&lt;/h2&gt;&lt;p&gt;乱序指的是指令并不按照顺序执行，所以这个概念比较接近软件编程中的“异步”概念（强调对于顺序时序的破坏）。而我之前似乎一直把它和“并行”挂钩（强调对于共享资源的争用）。这种认识倒也不算是错误，目前学了一圈下来，感觉其实和两个概念都有关系。&lt;/p&gt;
&lt;p&gt;在顺序模型下，指令是一条条阻塞执行的，必须前一条指令执行完，才能执行后一条指令。那么如果前一条指令非常花时间，那么后一条指令就只能阻塞等待。这个问题是用流水线解决不了的。流水线中的指令也需要顺序执行。而乱序执行就打破了这种顺序执行的阻塞性，使得前序和后序指令可以并行执行。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&quot;二、冒险（hazard）&quot;&gt;&lt;a href=&quot;#二、冒险（hazard）&quot; class=&quot;headerlink&quot; title=&quot;二、冒险（hazard）&quot;&gt;&lt;/a&gt;二、冒险（hazard）&lt;/h2&gt;</summary>
    
    
    
    <category term="计算机组成" scheme="https://thysrael.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/"/>
    
    
    <category term="直观理解" scheme="https://thysrael.github.io/tags/%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/"/>
    
    <category term="S8假期" scheme="https://thysrael.github.io/tags/S8%E5%81%87%E6%9C%9F/"/>
    
    <category term="计算机组成" scheme="https://thysrael.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/"/>
    
  </entry>
  
  <entry>
    <title>海边拾贝-VeriSMo</title>
    <link href="https://thysrael.github.io/posts/71c079c7/"/>
    <id>https://thysrael.github.io/posts/71c079c7/</id>
    <published>2024-07-29T01:25:40.000Z</published>
    <updated>2025-08-15T12:16:48.932Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/posts/71c079c7/1600x900_1591431860952_2048x1152_logo.jpg" alt="A RaiPlay learning il Verismo e i suoi autori - RAI Ufficio Stampa"></p><p>VeriSMo 的可信基只包括硬件和它自己（VM），剔除了对于 Hypervisor 的信任。传统的 VM 的安全服务是由 Hypervisor 负责的，如果认为 Hypervisor 是不可信的，那么就不能由它来提供安全服务。AMD 提供了新的安全架构 SEV-SNP，它为在 VM 中独立实现安全服务提供了支持，VeriSMO 就利用了这个硬件特性。</p><p>除了利用新的硬件安全特性外，VeriSMo 在开发时完成了形式化验证来确保安全性。VeriSMo 的开发语言是 Rust，已经确保了部分的内存安全性（也就是 Rust Checker 承担了部分形式化验证的任务），距离完全的形式化验证还有两个挑战：</p><ol><li>因为 Hypervisor 不可信任，所以 Hypervisor 可以打断 VM 的执行并修改硬件状态，这种并行无法简单验证。</li><li>开发 VeriSMo 需要使用 Unsafe Rust，Rust Checker 无法验证这种情况。</li></ol><p>为了解决挑战 1，VeriSMo 将验证拆分成了 2 层，上层为机器模型层（Machine Model），用 model verify 专门约束 Hypervisor 的行为，下层为实现层（Implement），用于解决排除了 Hypervisor 干扰后的 VeriSMo 本身的验证问题。</p><p>为了解决挑战 2，VeriSMo 引入并拓展了 Verus 来对 Unsafe 的情况进行验证，Verus 是 Rust 的一个库，可以看作它强化了原本的 Checker 功能；</p><h2 id="一、技术背景"><a href="#一、技术背景" class="headerlink" title="一、技术背景"></a>一、技术背景</h2><p>这个项目使用了大量的第三方技术和理论（多到和我用技术背景水字数的毕设差不多比例了）。</p><h3 id="1-1-理论"><a href="#1-1-理论" class="headerlink" title="1.1 理论"></a>1.1 理论</h3><p>reference：</p><p><a href="https://blog.lucode.net/theory/PV-HoareLogic.html">程序验证技术——霍尔逻辑 - 撸代码 - LuCode.net</a></p><h4 id="1-1-1-验证逻辑"><a href="#1-1-1-验证逻辑" class="headerlink" title="1.1.1 验证逻辑"></a>1.1.1 验证逻辑</h4><p>在验证逻辑方面并没有“显式”使用，只需要明确它们都涉及了 Rust Borrower Checker 和 Verus 的基础理论。其中尤其是线性逻辑，是可以支持并行程序内部的验证的，所以 VeriSMo 作为一个并行程序，形式化验证并没有理论上的难度，只是在实现上存在难度。</p><h4 id="1-1-2-验证等级"><a href="#1-1-2-验证等级" class="headerlink" title="1.1.2 验证等级"></a>1.1.2 验证等级</h4><p>形式化验证有两个等级：模型（Model）级别和实现（Implement）级别。其中实现级别的验证就是直观的对于具体的代码的形式化验证。而模型级别的验证是验证抽象模型，而不是具体的代码实现。这些模型通常通过状态机、流程图或其他形式化描述来表示。</p><p>在本项目中，验证分为两层，其中对于机器层的验证，就是模型级的，对于 VeriSMo 本身的验证，是实现级的。</p><h3 id="1-2-硬件"><a href="#1-2-硬件" class="headerlink" title="1.2 硬件"></a>1.2 硬件</h3><p>reference：</p><p><a href="https://dl.acm.org/doi/fullHtml/10.1145/3623392">Hardware VM Isolation in the Cloud</a></p><p><a href="https://blog.csdn.net/qq_43543209/article/details/135652011">【TEE】【AMD SEV内存加密】 白皮书-CSDN博客</a></p><p>硬件特性有很多，其核心在于将原本由 Hypervisor 负责的安全功能全部提供给 VM 。</p><h4 id="1-2-1-加密内存"><a href="#1-2-1-加密内存" class="headerlink" title="1.2.1 加密内存"></a>1.2.1 加密内存</h4><p>SME（Secure Memory Encrypted）：写入内存时利用硬件生成的 VM-specific key 对数据加密，读取内存是对数据解密。VM 可以通过 PTE 中的 <code>C-bit</code> 对物理页进行选择性加密。</p><p><img src="/posts/71c079c7/pic1.PNG" alt="pic1"></p><p>SEV-SNP 引入了反向映射表（RMP，Reverse Map Table）。之所以称之为反向映射表，是因为在传统的 VM 地址翻译中，映射方向是：</p><blockquote><p>gVA =&gt; gPA（guest 物理地址） =&gt; sPA（系统物理地址）</p></blockquote><p>而 RMP 中记录的是：</p><blockquote><p>sPA =&gt; {gPA, valid_bit, ASID}</p></blockquote><p>与传统方向相反。</p><p>RMP 的设计主要是为了使得物理内存真的分配给了特定的 VM，恶意的 Hypervisor 无法欺骗 VM 。当 Hypervisor 给 VM 分配内存时，需要使用特定的 <code>rmpupdate</code> 指令，VM 需要使用 <code>rmpvalid</code> 指令确认此次分配符合自己的要求。一旦分配完成后，Hypervisor 就无法再写入该内存页面了。后续 VM 可以使用 <code>rmpupdate</code> 来调整权限或者映射关系。</p><p>采用反向映射的方式，在地址翻译的时候增添一次映射来核对 GPA （GPA 是否真的对应特定的 SPA）和 ASID （VM 是否真的是特定的 VM）来确保“恶意 Hypervisor 无法尝试将页面映射到 Guest 地址空间中的错误位置”。</p><p><img src="/posts/71c079c7/pic2.png" alt="pic2"></p><h4 id="1-2-2-上下文加密"><a href="#1-2-2-上下文加密" class="headerlink" title="1.2.2 上下文加密"></a>1.2.2 上下文加密</h4><p>ES（Encrypted state）：在 VM 内陷到 Hypervisor 的时候，CPU 的状态会被加密保存到 VM Saving Area (VMSA) 。</p><h4 id="1-2-3-安全中断"><a href="#1-2-3-安全中断" class="headerlink" title="1.2.3 安全中断"></a>1.2.3 安全中断</h4><p>当限制中断（restricted）被启用时，Hypervisor 只能注入一种叫作 #HV 的中断，当 #HV 中断到达某个 VMPL 时，该 VMPL 的 VM 代码可以参考 #HV 门铃页来检查中断类型，而不是直接跳转到任意的中断处理程序。</p><p>共享门铃页（Shared Doorbell Page）是一个内存页面，被 Hypervisor 和 VM 的不同权限级别共享，用于传递中断和事件通知的信息。当 Hypervisor 发生注入某个特定类型的中断的时候，可以先修改门铃页来记录要触发的中断类型，然后给 VM 注入 #HV 中断，VM 收到 #HV 中断后会查看门铃页里的中断类型，进而做出相应处理。而不是直接被 Hypervisor 改变程序流。</p><p>VeriSMo 启用了 restricted-mode，减少了 Hypervisor 中断注入攻击的攻击面。</p><h4 id="1-2-4-虚拟机特权等级"><a href="#1-2-4-虚拟机特权等级" class="headerlink" title="1.2.4 虚拟机特权等级"></a>1.2.4 虚拟机特权等级</h4><p>在经历了内存加密和寄存器加密后，其实特权等级模型已经发生了变换。传统的特权等级模型下，高特权级可以随意访问低特权级的资源，随意影响低特权级软件的程序流（中断）；但是在 AMD SEV 中，即使是高特权级也无法访问一些低特权级的资源。</p><p><img src="/posts/71c079c7/pic3.png" alt="pic3"></p><p>更进一步，SEV-SNP 提供了 VMPL（虚拟机特权级别）的功能。该功能允许进行额外的安全控制，以保护 guest 内部的内存免受同一 guest 中其他代码的影响。每个 guest 最多可以有四个 VMPL，其中 VMPL0 权限最高，VMPL3 权限最低。分配给 guest 的每个内存页面可能具有基于 VMPL 的不同权限。 VMPL0 始终具有对 guest 地址空间中每个页面的完全访问权限，但它可能会将某些页面配置为不可在 VMPL1 上访问，或者可能允许只读访问。</p><p>VeriSMo 就是一个运行在 VMPL0 上的软件，而 Guest OS 运行在 VMPL3（只要不是 VMPL0 就行）上，这样可以避免不受信任的 Guest OS 的攻击。VMPL0 除了可以管理</p><h3 id="1-3-软件"><a href="#1-3-软件" class="headerlink" title="1.3 软件"></a>1.3 软件</h3><p>reference：</p><p><a href="https://verus-lang.github.io/verus/guide/">Verus Tutorial and Reference</a></p><h4 id="1-3-1-Rust-Checker"><a href="#1-3-1-Rust-Checker" class="headerlink" title="1.3.1 Rust Checker"></a>1.3.1 Rust Checker</h4><p>Rust 的所有权系统和类型系统确保了一定的安全性，但是 Unsafe Rust 可能会导致 bug 或者安全性问题。</p><h4 id="1-3-2-Verus"><a href="#1-3-2-Verus" class="headerlink" title="1.3.2 Verus"></a>1.3.2 Verus</h4><p>Verus 是一个为 Rust 设计的形式化验证工具，它看上去就像一个被拓展了语法的 Rust。</p><pre class="line-numbers language-Rust" data-language="Rust"><code class="language-Rust">verus! {fn octuple(x1: i8) -&gt; (x8: i8)    requires        -16 &lt;= x1 &lt; 16,    ensures        x8 == 8 * x1,{    let x2 = x1 + x1;    let x4 = x2 + x2;    x4 + x4}fn main() {    let n = octuple(10);    assert(n == 80);}} // verus!<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以注意到相比于普通的 Rust，多加了 <code>requires, ensures, invarient</code> 等关键词，这些是形式化验证的“方法”。本项目不仅实现了一个经过验证的模块，还将验证方法都用 rust 或者说 verus 实现了。</p><hr><h2 id="二、设计"><a href="#二、设计" class="headerlink" title="二、设计"></a>二、设计</h2><h3 id="2-1-威胁模型"><a href="#2-1-威胁模型" class="headerlink" title="2.1 威胁模型"></a>2.1 威胁模型</h3><p>VeriSMo 的可信基只包括硬件和它自己（运行在 VMPL0 上的 VeriSMo），它既不信任 Hypervisor，也不信任运行在 VMPL3 的 Guest OS。</p><p><img src="/posts/71c079c7/pic4.png" alt="pic4"></p><p>VeriSMo 在这样的模型下，要完成唤醒 CPU，管理 Guest 内存，确保 Guest OS 的完整性，运行时测量等功能。</p><p><img src="/posts/71c079c7/pic5.png" alt=""></p><h3 id="2-2-验证目标"><a href="#2-2-验证目标" class="headerlink" title="2.2 验证目标"></a>2.2 验证目标</h3><p>我们希望用形式化验证的方式确定 3 个属性：</p><ul><li>功能正确性：VeriSMo 可以无 bug 地满足安全服务所需要的功能。</li><li>信息流安全：程序在任何情况下都不应通过内存操作或低安全级别变量的值泄露与高安全级别变量相关的信息。</li><li>VM 的机密性和可信性：Hypervisor 和 VMPL3 都不可以读取 VMPL0 的私有内存。Hypervisor 不可以读取 VM 的私有内存（应该是包括 VMPL0 和 VMPL3 的私有内存）。</li></ul><p>总的来说有两个目标，一个是内存安全，一个是信息流安全。文章比较大的篇幅集中于内存安全，而信息流安全的验证则和其他部分比较孤立，最后单独形成一个章节介绍。</p><h3 id="2-3-验证思路"><a href="#2-3-验证思路" class="headerlink" title="2.3 验证思路"></a>2.3 验证思路</h3><p>Hypervisor 会打断 VM 对资源形成并发操作，然而因为不信任 Hypervisor 的原因，我们无法直接验证 Hypervisor ，所以我们将验证分成了两层。第一层是 Machine Model Layer，采用建立一个硬件抽象机的方式进行模型级的验证，确保在给定 Hypervisor 约束后，它不会影响 VM 的机密性和完整性。第二层是 VeriSMo 内部实现的验证。</p><p><img src="/posts/71c079c7/1722216940888-14.png" alt="img"></p><p>我个人感觉形式化验证是可以验证并发程序的，此项目分成两层进行验证，有可能不是因为 Hypervisor 的并发很难验证，而是因为 Hypervisor 不在信任基内，导致我们没法直接验证，所以我们才采用了建模的方式进行抽象验证。</p><p>我个人感觉其实是将验证分为了两步：</p><ul><li>Machine-Model Layer：验证 AMD SEV-SNP 这套硬件机制没有问题</li><li>Implement Layer：验证 VeriSMo 对 AMD SEV-SNP 的使用没有问题</li></ul><hr><h2 id="三、内存安全验证"><a href="#三、内存安全验证" class="headerlink" title="三、内存安全验证"></a>三、内存安全验证</h2><h3 id="3-1-Machine-Model-层"><a href="#3-1-Machine-Model-层" class="headerlink" title="3.1 Machine-Model 层"></a>3.1 Machine-Model 层</h3><p>Machine Model 具有两个目标：</p><ul><li>Hypervisor 和 VMPL3 都不可以读取 VMPL0 的私有内存。</li><li>Hypervisor 不可以读取 VM 的私有内存（应该是包括 VMPL0 和 VMPL3 的私有内存）。</li></ul><p>更进一步地说，我们希望验证这个图片所展示的事实，即 HV 和 VM 具有一定的独立性：</p><p><img src="/posts/71c079c7/1722216970526-17.png" alt="img"></p><p>VERISMO 并没有一个 guest OS 那么庞大，所以 VERISMO 只对关键的内存和 cache 操作进行建模。</p><p>其更加具体地说，它的主线逻辑是这样的，它定义了 4 个对象：</p><ul><li>系统状态（Ψ）：整个系统</li><li>实体（e）：可能是 Hypervisor、VeriSMo，Guest OS </li><li>操作（op）：关键的内存和 cache 操作，比如更新页表之类的。</li><li>攻击模型（attack model）：Ψ 按照一定顺序经过多个 e 的多个 op 的一个序列</li></ul><p>如果 Ψ 初始化是正确的，所有的 op 都满足各自的前置条件和后置条件，验证 Ψ 经过 op 后依然安全（保证一定的不变式），那么按照类似数学归纳法的思想，经过多次 op 后 Ψ 依然安全。</p><p>那么检验的核心就在于 op 的约束条件（前置和后置）能否满足上述要求。这就需要结合硬件特性来推导出一些比较强的引理来。</p><p>关于 VM-Private 的内存，我们有：</p><ul><li>Ψ 下 CVM 私有内存 M 包含数据 D，经由 HV 操作后， Ψ’ 下 CVM 读取 M 得到数据 D 或读取失败。</li></ul><p>这是因为 RMP 规定如果该 M 不是 valid 的，那么 HV 是可以读取的，而如果是 valid 的，那么就不可以读取。</p><ul><li>Ψ 下 CVM 私有内存 M 包含机密 S，经由 HV 操作后， Ψ’ 下 HV 读取 M 得到 S 的密文。</li></ul><p>如果经过加密，那么读取到的一定是密文。</p><p>关于 VMPL0-Private 的内存，我们有：</p><ul><li>Ψ 下 VMPL0 私有内存 M 包含数据 D，经由 hypervisor 或 VMPL3 操作后， Ψ’ 下 VMPL0 读取 M 得到数据 D 或读取失败，VMPL3 不能读取 M。</li></ul><p>由引理 1，2 可以 HV 不可读取，又因为 RMP 中记录了每个 VMPL 的访问权限，VMPL3 没有访问权限。</p><p>关于地址翻译，我们有：</p><ul><li>Ψ 下 VMPL0 访问 gVA 翻译到 sPA，经由 HV 或 VMPL3 操作后，Ψ’ 下 VMPL0 访问 gVA 翻译到 sPA 或翻译失败。</li></ul><p>只有使用 VMPL0 的特殊指令才能更改页表，任何其他更改页表的行为都会导致报错。</p><ul><li>任何 Ψ 下，CVM 的 gVA 到 sPA 的映射是双射。</li></ul><p>因为 gPA 到 sPA 的映射是双射，只需要证明 gVA 到 gPA 是双射。具体的证明方法类似于“一开始是双射，而且每次操作都必须保证是双射的，所以最后是双射”的数学归纳法。</p><p>在有了这五条引理后，就可以交给形式化证明机来完成证明了。</p><h3 id="3-2-Implement-层"><a href="#3-2-Implement-层" class="headerlink" title="3.2 Implement 层"></a>3.2 Implement 层</h3><p>在实现层，验证上主要采用如下技术来实现形式化验证：</p><p><img src="/posts/71c079c7/1722216970526-18.png" alt="img"></p><p>其中 Rust 负责基础的所有权和读写检查，SNP Pointer 是一个用于验证的胖指针，里面对 SEV-SNP 机制进行了建模，胖指针的样子是这样的</p><pre class="line-numbers language-Rust" data-language="Rust"><code class="language-Rust">pub ghost struct SnpMemAttr{ rmp: RmpEntry, pte: PTAttr, is_pt: bool}pub ghost struct SnpPointsToData&lt;T&gt; {    addr: int, value: Option&lt;T&gt;,    swattr: SnpMemAttr, hwattr: SnpMemAttr,}pub tracked struct SnpPointsTo&lt;V&gt;{ _p: marker::PhantomData&lt;V&gt;, _ncopy: NoCopy }impl&lt;T&gt; SnpPointsTo&lt;T&gt;{ pub spec fn view(&amp;self) -&gt; SnpPointsToData&lt;T&gt;; }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>检验者可以根据胖指针内 <code>RmpEntry, addr</code> 等元素进行验证。如下所示：</p><pre class="line-numbers language-Rust" data-language="Rust"><code class="language-Rust">fn access_private(Tracked(mperm): Tracked&lt;&amp;SnpPointsTo&lt; u64&gt;&gt;)    requires      mperm@.wf_not_null_at(0x1000),      mperm@.is_vmpl0_private(){    let val1 = *borrow(0x1000, Tracked(mperm));    let val2 = *borrow(0x1000, Tracked(mperm));    assert(val2 == val1);    replace(0x1000, 0x1234, Tracked(mperm)); // Rust : change the unmutable val!    let _val3 = *borrow(0x2000, Tracked(mperm)); // Verus: borrow wrong addr!}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于 unsafe rust 操作，我们用 verus 来限制并验证其使用，比如 <code>rmpadjust</code> 指令，就有复杂的前置和后置条件（见 <a href="https://verus-lang.github.io/verus/guide/memory-safety.html">19.2. Memory safety is conditional on verification</a>）：</p><pre class="line-numbers language-Rust" data-language="Rust"><code class="language-Rust">pub fn rmpadjust(    vaddr: u64,    psize: u64,    attr: RmpAttr,    Tracked(mycore): Tracked&lt;&amp;SnpCore&gt;,    Tracked(newcore): Tracked&lt;Option&lt;CoreIdPerm&gt;&gt;,    Tracked(perm): Tracked&lt;&amp;mut SnpPointsToRaw&gt;,) -&gt; (ret: u64)    requires        old(perm)@.snp().requires_rmpadjust(vaddr as int, psize as int, attr@, newcore, old(perm)@),        mycore.coreid@.vmpl == 0,        attr.spec_vmpl() &gt; mycore.coreid@.vmpl,    ensures        old(perm)@.snp.rmpadjust_ret(perm@.snp, ret, vaddr as int, psize as int, attr@),        old(perm)@.range() === perm@.range(),        old(perm)@.snp_bytes === perm@.snp_bytes,{    let ret: u64;    unsafe {        asm!(".byte 0xf3,0x0f,0x01,0xfe",                in("rax") vaddr, in("rcx") psize, in("rdx") attr.value,                lateout("rax") ret,                options(nostack));    }    ret}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>PS: <code>@</code> 是 <code>.view()</code> 的缩写，见 <a href="https://verus-lang.github.io/verus/guide/reference-at-sign.html">4.1. Recursive spec functions, decreases, fuel</a></p></blockquote><p>其中 SNP Pointer 和与之配套的验证约束合称 Memory Permisson，因为这种 Permission 有时是需要共享的（因为内存需要共享），所以又引入了 Lock Permisson 来确保并发程序的正确性。</p><p><img src="/posts/71c079c7/1722216970526-19.png" alt="img"></p><p>VeriSMo 内存并发安全模型为：</p><ol><li>上锁的 VMPL0 私有内存（可信内存）可以任意访问；</li><li>如果其他实体（VMPL3 或者 HV）想共享给 VMPL0，要么上锁后拷贝给 VMPL0，要么修改映射关系后重新写入；</li><li>如果 VMPL0 需要共享给其他实体，可以上锁后直接修改映射关系。</li></ol><hr><h2 id="四、信息流安全验证"><a href="#四、信息流安全验证" class="headerlink" title="四、信息流安全验证"></a>四、信息流安全验证</h2><p>左图中，机密变量 high 被通过数据流泄露到公开变量 low。右图中，机密变量 high 通过控制流侧信道被泄露。</p><p><img src="/posts/71c079c7/1722216998108-26.png" alt="img"></p><p>具体的，本工作记录 VeriSMo 中每个变量的猜测空间（guess space, valset），猜测空间为全集的变量为机密变量，猜测空间为单元素集合的变量为公开变量，猜测空间随着计算操作传播。</p><p><img src="/posts/71c079c7/1722216998109-27.png" alt="img"></p><p>验证器确保：</p><ol><li>只有机密变量能用作密钥，</li><li>机密变量保存在 VMPL0 私有内存中</li><li>机密变量不能用于控制流判断、内存地址等可能导致侧信道泄露的用途。</li></ol><hr><h2 id="五、实现与评估"><a href="#五、实现与评估" class="headerlink" title="五、实现与评估"></a>五、实现与评估</h2><p>从实现层面来说，似乎锁设计比较新颖，锁的数目比较少，验证难度也比较低。</p><p>从实现性能看，与 Hecate 这种提供安全服务的 HV 相比，性能提高了 40%，因为不需要频繁内陷到 HV 中，这应该是所有的 Secure Module 都具有的性能优势。</p><p>而与其他的 Secure Module 相比（用 C 实现的 SMo 或者修改后 Linux 作为一个 SMo），在性能开销方面差别不大（Index 越高性能越好）</p><p><img src="/posts/71c079c7/1722217009985-32.png" alt="img"></p><p>从验证层面看，验证速度很快，大约 6 分钟就可以验证完两层模型。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/posts/71c079c7/1600x900_1591431860952_2048x1152_logo.jpg&quot; alt=&quot;A RaiPlay learning il Verismo e i suoi autori - RAI Ufficio Stampa&quot;&gt;&lt;/p&gt;
&lt;p&gt;VeriSMo 的可信基只包括硬件和它自己（VM），剔除了对于 Hypervisor 的信任。传统的 VM 的安全服务是由 Hypervisor 负责的，如果认为 Hypervisor 是不可信的，那么就不能由它来提供安全服务。AMD 提供了新的安全架构 SEV-SNP，它为在 VM 中独立实现安全服务提供了支持，VeriSMO 就利用了这个硬件特性。&lt;/p&gt;
&lt;p&gt;除了利用新的硬件安全特性外，VeriSMo 在开发时完成了形式化验证来确保安全性。VeriSMo 的开发语言是 Rust，已经确保了部分的内存安全性（也就是 Rust Checker 承担了部分形式化验证的任务），距离完全的形式化验证还有两个挑战：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;因为 Hypervisor 不可信任，所以 Hypervisor 可以打断 VM 的执行并修改硬件状态，这种并行无法简单验证。&lt;/li&gt;
&lt;li&gt;开发 VeriSMo 需要使用 Unsafe Rust，Rust Checker 无法验证这种情况。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为了解决挑战 1，VeriSMo 将验证拆分成了 2 层，上层为机器模型层（Machine Model），用 model verify 专门约束 Hypervisor 的行为，下层为实现层（Implement），用于解决排除了 Hypervisor 干扰后的 VeriSMo 本身的验证问题。&lt;/p&gt;</summary>
    
    
    
    <category term="海边拾贝" scheme="https://thysrael.github.io/categories/%E6%B5%B7%E8%BE%B9%E6%8B%BE%E8%B4%9D/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="S8假期" scheme="https://thysrael.github.io/tags/S8%E5%81%87%E6%9C%9F/"/>
    
    <category term="海边拾贝" scheme="https://thysrael.github.io/tags/%E6%B5%B7%E8%BE%B9%E6%8B%BE%E8%B4%9D/"/>
    
  </entry>
  
  <entry>
    <title>信息安全-基本概念</title>
    <link href="https://thysrael.github.io/posts/7efac32a/"/>
    <id>https://thysrael.github.io/posts/7efac32a/</id>
    <published>2024-07-10T12:51:28.000Z</published>
    <updated>2025-08-15T12:16:47.805Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、安全目标"><a href="#一、安全目标" class="headerlink" title="一、安全目标"></a>一、安全目标</h2><h3 id="1-1-总论"><a href="#1-1-总论" class="headerlink" title="1.1 总论"></a>1.1 总论</h3><p>系统安全有 3 个目标：</p><ul><li><strong>机密性（Confidentiality）</strong>：又称隐私性（Privacy），是指数据不能被未授权的主体窃取（即恶意读操作）。</li><li><strong>完整性（Integrity）</strong>：是指数据不能被未授权的主体篡改（即恶意写操作）。</li><li><strong>可用性（Availability）</strong>：是指数据能够被授权主体正常访问。</li></ul><p>合称 CIA 。</p><h3 id="1-2-机密性-Confidentiality"><a href="#1-2-机密性-Confidentiality" class="headerlink" title="1.2 机密性 (Confidentiality)"></a>1.2 机密性 (Confidentiality)</h3><h4 id="1-2-1-含义"><a href="#1-2-1-含义" class="headerlink" title="1.2.1 含义"></a>1.2.1 含义</h4><p>完整性是指保护数据不被未授权的主体篡改，确保数据的准确性、一致性和信任度。</p><h4 id="1-2-2-实现手段"><a href="#1-2-2-实现手段" class="headerlink" title="1.2.2 实现手段"></a>1.2.2 实现手段</h4><ul><li><strong>加密</strong>：对数据进行加密，只有持有正确解密密钥的主体才能读取数据。</li><li><strong>访问控制</strong>：通过访问控制列表（ACL）和权限设置来限制数据的访问。</li><li><strong>身份验证</strong>：确保数据只能由经过身份验证的用户或系统访问。</li></ul><h4 id="1-2-3-示例"><a href="#1-2-3-示例" class="headerlink" title="1.2.3 示例"></a>1.2.3 示例</h4><ul><li><strong>加密通信</strong>：使用 HTTPS 协议对网络通信进行加密，防止第三方窃取传输中的数据。</li><li><strong>数据加密存储</strong>：在文件系统或数据库中对敏感信息进行加密存储。</li><li><strong>访问控制</strong>：设定文件或数据库记录的访问权限，只允许具备相应权限的用户访问。</li></ul><h3 id="1-3-完整性-Integrity"><a href="#1-3-完整性-Integrity" class="headerlink" title="1.3 完整性 (Integrity)"></a>1.3 完整性 (Integrity)</h3><h4 id="1-3-1-含义"><a href="#1-3-1-含义" class="headerlink" title="1.3.1 含义"></a>1.3.1 含义</h4><p>完整性是指保护数据不被未授权的主体篡改，确保数据的准确性、一致性和信任度。</p><h4 id="1-3-2-实现手段"><a href="#1-3-2-实现手段" class="headerlink" title="1.3.2 实现手段"></a>1.3.2 实现手段</h4><ul><li><strong>校验和和哈希</strong>：使用校验和或哈希函数来生成数据的唯一摘要，接收方可以通过比较摘要来验证数据是否被篡改。</li><li><strong>数字签名</strong>：使用数字签名对数据进行签名，以确保数据在传输中的完整性和来源的可靠性。</li><li><strong>版本控制</strong>：使用版本控制系统记录数据的变更历史，防止未经授权的修改。</li></ul><h4 id="1-3-3-示例"><a href="#1-3-3-示例" class="headerlink" title="1.3.3 示例"></a>1.3.3 示例</h4><ul><li><strong>哈希校验</strong>：下载文件后检查文件的哈希值，确认其未被篡改。</li><li><strong>数字签名</strong>：邮件或文档使用数字签名，收件人可以验证其来源和内容的完整性。</li><li><strong>文件权限</strong>：设置敏感文件为只读，防止未经授权的用户进行修改。</li></ul><h3 id="1-4-可用性-Availability"><a href="#1-4-可用性-Availability" class="headerlink" title="1.4 可用性 (Availability)"></a>1.4 可用性 (Availability)</h3><h4 id="1-4-1-含义"><a href="#1-4-1-含义" class="headerlink" title="1.4.1 含义"></a>1.4.1 含义</h4><p>可用性是指确保数据和系统在需要时能够被授权的主体正常访问和使用。</p><h4 id="1-4-2-实现手段"><a href="#1-4-2-实现手段" class="headerlink" title="1.4.2 实现手段"></a>1.4.2 实现手段</h4><ul><li><strong>冗余和备份</strong>：通过数据冗余和定期备份来确保数据在特殊情况下（如硬件故障）仍然可用。</li><li><strong>容错和高可用架构</strong>：设计容错和高可用系统架构，使用负载均衡、多路径等技术，确保系统在故障情况下仍然能够提供服务。</li><li><strong>DoS/DDoS 保护</strong>：通过防火墙、入侵检测系统（IDS）和流量管理等手段防止拒绝服务（DoS）或分布式拒绝服务（DDoS）攻击。</li></ul><h4 id="1-4-3-示例"><a href="#1-4-3-示例" class="headerlink" title="1.4.3 示例"></a>1.4.3 示例</h4><ul><li><strong>云备份</strong>：定期将数据备份到云存储，确保在本地数据损坏时可以恢复。</li><li><strong>高可用性集群</strong>：使用高可用性集群和负载均衡器分配流量，确保一个节点出现故障时，其他节点可以继续提供服务。</li><li><strong>流量管理</strong>：部署防火墙和负载均衡器，防止由于流量异常导致的服务中断。</li></ul><h3 id="1-5-三者的区别"><a href="#1-5-三者的区别" class="headerlink" title="1.5 三者的区别"></a>1.5 三者的区别</h3><ul><li><strong>机密性 vs. 完整性</strong>：机密性关注的是防止数据被窃取，而完整性关注的是数据未经授权被篡改。机密性主要解决“谁能看到”的问题，而完整性解决的是“它是否被改变”的问题。</li><li><strong>完整性 vs. 可用性</strong>：完整性确保数据的准确和一致性，而可用性确保数据和系统在需要时是可访问的。完整性保证数据未受未经授权的修改，可用性保证在正确时间提供正确的服务。</li><li><strong>机密性 vs. 可用性</strong>：在某些情况下，机密性和可用性可能需要权衡。例如，高度加密的数据可能需要更多的计算资源解密，从而影响系统的可用性。机密性和可用性关注的是不同的方面，前者注重安全访问，后者注重无障碍访问。</li></ul><hr><h2 id="二、访问控制"><a href="#二、访问控制" class="headerlink" title="二、访问控制"></a>二、访问控制</h2><h3 id="2-1-总论"><a href="#2-1-总论" class="headerlink" title="2.1 总论"></a>2.1 总论</h3><p>访问控制（Access Control）是按照访问主体的身份（Identity）来限制其访问对象的一种方法。它由两个基本过程组成，即：</p><ul><li>认证（Authentication）：验证某个发起访问请求的主体的身份。</li><li>授权（Authorization）：授予某个身份一定的权限以访问特定的对象。</li></ul><p>访问控制是这样的一件事，资源的请求方被称为主体，认证干的事情是确定你真的是这个主题，而不是一个人化妆了伪造出来的人，换句话说，认证干的是“主体 =&gt; 身份”的工作；授权则干得是“身份 =&gt; 权限”的工作，需要强调，授权并不只局限于“赋予”某个身份一定的权限，他还包括这个权限的正确执行，违法权限的行为的发现。</p><p><img src="/posts/7efac32a/image-20240711145910684.png" alt="image-20240711145910684"></p><p>打给比方，认证就是“火眼金睛”，而“授权”则是天条和天兵。</p><h3 id="2-2-认证"><a href="#2-2-认证" class="headerlink" title="2.2 认证"></a>2.2 认证</h3><p>认证过程旨在建立发起请求的主体与系统中某个 ID 之间的绑定关系。例如，用户登录操作系统时，首先要选择用户名（即 ID），然后输入密码或口令完成登录过程。</p><p>认证过程中,判断某一个主体身份的方法主要有三种：</p><ul><li>你知道什么（Something you know）：例如密码/口令（password）、手势密码、某个问题的答案等。</li><li>你有什么（Something you have）：例如 USB-key、密码器等实物；电子令牌（token）</li><li>你是什么（Something you are）：例如指纹、虹膜、步态、键盘输入习惯等，属于人的一部分。</li></ul><p>总的来说，由上到下主体和身份（ID）的相关性在增强，进而安全性就在增强。主体知道的东西很容易被窃取，比如一个用生日做的密码，即使不是主体，也很容猜到。而主体的指纹，就没那么容易搞到了。</p><p>Token 和 Password 都用于身份验证但用途和特性不同。Password 是用户在登录时输入的静态字符组合，用于初次验证身份。而 Token 则是在用户通过密码验证后，由服务器生成并发给客户端的动态凭证，用于在后续请求中证明身份。与 Password 不同，Token 通常有时效性，可以减少频繁传递 Password 的安全风险，并且适合分布式系统中的认证场景。</p><h3 id="2-3-授权"><a href="#2-3-授权" class="headerlink" title="2.3 授权"></a>2.3 授权</h3><p>授权，是判断某个主体是否有权限访问某个对象的过程。授权机制主要考虑以下三个问题：</p><ol><li><p><strong>用何种数据结构来表达主体与对象之间的权限关系</strong>：</p><p>确定如何存储和表示主体与对象之间的权限关系，如使用访问控制列表（ACL）、角色权限矩阵或权限表等。</p></li><li><p><strong>如何设置和修改这种权限关系</strong>：</p><p>确定权限的分配和调整机制，例如通过管理员手动配置、角色分配系统或自动化策略等。</p></li><li><p><strong>如何强制保证这种权限关系</strong>：</p><p>确保系统能够正确执行权限检查和访问控制，防止未经授权的访问。可以通过身份验证、访问控制检查和安全审计等手段来实现。</p></li></ol>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、安全目标&quot;&gt;&lt;a href=&quot;#一、安全目标&quot; class=&quot;headerlink&quot; title=&quot;一、安全目标&quot;&gt;&lt;/a&gt;一、安全目标&lt;/h2&gt;&lt;h3 id=&quot;1-1-总论&quot;&gt;&lt;a href=&quot;#1-1-总论&quot; class=&quot;headerlink&quot; title=&quot;1.1 总论&quot;&gt;&lt;/a&gt;1.1 总论&lt;/h3&gt;&lt;p&gt;系统安全有 3 个目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;机密性（Confidentiality）&lt;/strong&gt;：又称隐私性（Privacy），是指数据不能被未授权的主体窃取（即恶意读操作）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;完整性（Integrity）&lt;/strong&gt;：是指数据不能被未授权的主体篡改（即恶意写操作）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可用性（Availability）&lt;/strong&gt;：是指数据能够被授权主体正常访问。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;合称 CIA 。&lt;/p&gt;</summary>
    
    
    
    <category term="信息安全" scheme="https://thysrael.github.io/categories/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/"/>
    
    
    <category term="直观理解" scheme="https://thysrael.github.io/tags/%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/"/>
    
    <category term="信息安全" scheme="https://thysrael.github.io/tags/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/"/>
    
    <category term="S8假期" scheme="https://thysrael.github.io/tags/S8%E5%81%87%E6%9C%9F/"/>
    
  </entry>
  
  <entry>
    <title>沟通交流-旋氏语法</title>
    <link href="https://thysrael.github.io/posts/a039c29c/"/>
    <id>https://thysrael.github.io/posts/a039c29c/</id>
    <published>2024-06-24T01:58:10.000Z</published>
    <updated>2025-08-15T12:16:48.894Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、总论"><a href="#一、总论" class="headerlink" title="一、总论"></a>一、总论</h2><p>这篇文章是对于<a href="https://llwslc.github.io/grammar-club/">旋元佑语法俱乐部</a>的一个注释总结。行文思路基本上和这本电子书的章节保持一致。</p><p>语法是对于语言的规律总结，这类似于物理是对于客观世界的规律总结。不过应当注意到，即使掌握了语法，也并不能短时间内提高英语水平，因为在语法的指导下使用语言，同样是一个需要习惯和精进的过程。这就像掌握了物理定律和物理满分之间依然存在很大差距一样。</p><p>旋老师的语法和我中学学过的语法并不一样，旋老师倾向于建立一种“大一统”的理论来解释所有的语言现象，而中学语法则更加繁杂和缺少一致性。在加上我这次学习语法已经是大四，在逻辑思维上相比于中学已经有了很大的进步。所以总的来说，语法更加“讲理”了。</p><p>但是旋氏语法的缺点我个人感觉有两个，一个是因为过于“统一”，导致需要引入一堆与中学语法似是而非的概念，这些概念类似于物理学上的“波粒二象性”一样，对中学语法是一种挑战；并且因为旋老师是台湾人的缘故，所以在表达习惯和方式上也与大陆存在一定的差异（也就是他写的中文有点难看懂）。另一个是旋老师在建立了“统一”的理论后，并没有充分利用这些规律推导出中学语法甚至是其他中学语法难以推导的其他语言现象。</p><p>所以这篇文章会对原本的电子书进行一定的解释和应用。</p><hr><h2 id="二、简单句"><a href="#二、简单句" class="headerlink" title="二、简单句"></a>二、简单句</h2><h3 id="2-1-基本句型"><a href="#2-1-基本句型" class="headerlink" title="2.1 基本句型"></a>2.1 基本句型</h3><p>英语语法的研究单位是句子，而简单句（可以看作比较本源的一种句子）一共有  5 种句型，如下所示：</p><div class="table-container"><table><thead><tr><th>简记</th><th>解释</th><th>动词性质</th><th>举例</th></tr></thead><tbody><tr><td>S + V</td><td>主语 + 动词</td><td>不及物动词</td><td>die, smile</td></tr><tr><td>S + V + O</td><td>主语 + 动词 + 宾语</td><td>单宾语及物动词</td><td>kill, love, like</td></tr><tr><td>S + V + C</td><td>主语 + 动词 + 主语补语</td><td>系动词/连缀动词</td><td>be, seem, sound, feel, prove</td></tr><tr><td>S + V + O + O</td><td>主语 + 动词 + 直接宾语 + 间接宾语</td><td>双宾语及物动词</td><td>give, call,tell</td></tr><tr><td>S + V + O + C</td><td>主语 + 动词 + 宾语 + 宾语补语</td><td>宾语补语及物动词</td><td>find, consider, find</td></tr></tbody></table></div><p>其中简记符号是这样的：</p><div class="table-container"><table><thead><tr><th>符号</th><th>英文</th><th>全称</th></tr></thead><tbody><tr><td>S</td><td>Subject</td><td>主语</td></tr><tr><td>V</td><td>Verb</td><td>动词</td></tr><tr><td>O</td><td>Object</td><td>宾语</td></tr><tr><td>C</td><td>Complement</td><td>补语</td></tr></tbody></table></div><p>在这种分类下（其实这只是旋老师自己的分类，有些语法的分类要更加复杂），有许多有趣的特征：</p><p>可以看到这种对句子成分的分类法，取消了常见的“谓语，状语，表语”的语法成分。其中谓语的取消，应该是因为谓语的定义过于宏大。谓语的英文是 Predicate，也就是断言，所以我个人理解，断言加上断言的目标，也就是主语，那么就可以构成一个命题了，而命题基本上是句子存在的意义。我们说的每一句话，都是一个命题。如果认为句子中存在谓语，那么基本上其他的语法成分都会被囊括其中，其实是不利于细致探究的。而状语之所以没有，是因为它并不是句子的主干，而是句子的点缀，所以就没有细说。而传统意义上的表语，则大部分被划分到了补语范畴内，旋老师这么做是为了某种“简洁性”。</p><p>一个句子对应一个动词。也就是说，如果一个字符串里没有动词，那么就一定不是一个简单句，同理，如果一个字符串中有了两个动词，那么就一定不是一个简单句，而有可能是一个从句，或者简化从句，这是很有意思的一点，比如说例句：</p><blockquote><p>I hate programming.</p></blockquote><p>其中有 hate 和 program 两个动词，所以它并不是一个简单句，而是一个简化从句：</p><blockquote><p>I hate that I program.</p></blockquote><p>意识到句子与动词的一一对应关系，可以理解复杂的句子，因为动词很好数出来。</p><p>动词的性质决定了不同的句型。上文列出了五种句型，并不是可以随意搭配动词使用的。动词性质决定了句型，比如不及物动词，它的句型只能是“S + V”，不能是“S + V + C”。所以积累动词的性质，可以有助于我们识别句子的结构，当遇到一个不及物动词的时候，就不用去后文找补语或者宾语了。</p><h3 id="2-2-限定"><a href="#2-2-限定" class="headerlink" title="2.2 限定"></a>2.2 限定</h3><p>在介绍其他语法之前我想介绍一下限定（Finite），它指的是词语的一种属性。对于动词而言，简单句里的动词都是限定动词，这样的动词需要受到人称、时态、语态、助词（情态动词等）、语气的限制（Determiner），也就是承担了更多的句子表达更多信息的任务。我们可以从限定动词中获得更多的信息，在使用限定动词的时候，也需要注意更多限制。而非限定动词则不需要考虑那么多，一般只有 Ving，to V，Ven 这几种形式。非限定动词可以看作是从句简化后的结果。</p><p>基于“限定”的概念，引申出来“不定式”的概念，它特指“to V”结构。旋老师将不定时描述成了情态动词的退化，将在后面详述。</p><p>除了动词以外，名词也有限定词的说法，它指的是复数变化和冠词等内容。</p><h3 id="2-3-时态"><a href="#2-3-时态" class="headerlink" title="2.3 时态"></a>2.3 时态</h3><h4 id="2-3-1-分词"><a href="#2-3-1-分词" class="headerlink" title="2.3.1 分词"></a>2.3.1 分词</h4><p>在传统语法中，时态是非常复杂的，有如此多项：</p><ul><li>时间：过去，现在，未来</li><li>状态：简单，进行，完成</li><li>语态：主动，被动</li></ul><p>一般都是这三种内容的自由组合，比如说“过去完成时被动语态”。旋老师主张将进行时和被动语态看作一种“形容词”，这样</p><blockquote><p>I am reading.</p></blockquote><p>就变成了一种“S + V + C”的结构。这样的话，其实就取消了“主被动”的问题，并且减少了“状态”中的进行时。这种简化我觉得并不是很有意义，只是在形式上简化了语法，但是“进行”或者“被动”本身的含义并没有被化简掉。</p><p>这种思想其实并不是牵强附会，它可以看作是“分词 Participle”思想的延伸，分词既有动词的特性，也有形容词的特性，所以说它”分享”了两种词类的特点。分词有现在分词（Present Participle）和过去分词（Past Participle）两种，其实就是 Ving 和 Ved 这两种。它们原本是动词，分词化处理后具有了形容词词性，所以可以担任补语的职责。</p><h4 id="2-3-2-状态"><a href="#2-3-2-状态" class="headerlink" title="2.3.2 状态"></a>2.3.2 状态</h4><p>其中时间和语态的区分是比较容易的，难点还是状态的区分上。我感觉最好还是同时区分“简单、进行、完成”三种语态。其实从语义上来说，三者的区别是很明显的，其中普通式指的是“这句话只是为了说这句话”，也就是这句话就是一个纯粹的<strong>命题</strong>。其他两种状态都有一种“这句话是别的话的铺垫”的感觉，这是我觉得这三种状态最核心的区别，如下所示：</p><blockquote><p>I read this book. （我读这本书，平平淡淡的陈述句）</p><p>I am reading this book （我正在读这本书，强调“正在”要超过“读”，可能表明现在很忙）</p><p>I have read this book （我读过这本书了，强调“读过”要超过“读”，可能表明我了解这本书的知识了）</p></blockquote><p>当然在搞明白这点以后，其实并不足够。我个人感觉是因为状态的描述不仅需要依靠现在分词或者 have 这样的助动词来帮助，它们往往和时间概念联系在一起。这并不奇怪，因为当我们在说一个不是纯粹命题的句子（也就是普通式）的时候，我们往往还要说些其他的信息，而将不纯粹命题和其他信息联系在一起的媒介，就是时间。比如说：</p><blockquote><p>I was reading this book when he knocked my door. （他的敲门打扰了我“正读书”的行为）</p><p>I have read this book so that I will pass the exam easily. （因为我“读过”书了，所以通过考试对我轻轻松松） </p></blockquote><p>这些蕴藏在状态中的时间概念，如下图所示：</p><p><img src="/posts/a039c29c/time.png" alt=""></p><p>对于普通式来说，其时间观念的核心在于一个“<strong>有始有终的准确时间范围</strong>”，这是因为任何命题的成立都需要一个时间范围。比如：</p><blockquote><p>I read this book last week.</p></blockquote><p>这句话如果去掉了“last week”也不是不行，但是这只是一种“省略”，但是读书一定会发生在过去的一个准确的时间段。这种时间段有两个有趣的特性。一个就是前面提到的省略，确实可以省略，但是意思并不会变，与之形成对比就是其他两种状态，往往更需要显式的时间成分。另一个就是时间段的开始和结束时间可以到无限远，此时命题就变成了真理。</p><p>当时间段缩短到一个点的时候，就得到了进行时，这个很好理解。</p><p>而完成时更容易和普通式弄混，如前所述，完成时强调的不再是命题本身，而是命题之外的信息。所以命题发生的时间并不重要，命题产生影响的时间更重要。所以它在示意图中是一个单向箭头，箭头的起点是受到命题影响的时间，而不是命题发生的时间。比如：</p><blockquote><p>I have read this book.</p></blockquote><p>即使这句话使用了“现在”完成时，但是主人公并不是在现在读的书，而是在过去的某个时间节点读的书，只是“现在”要用上这本书的知识了。所以完成时和普通时的一个更加形而下的差别，就是完成时不能确定命题的开始时间和结束时间。</p><p>上面细化了状态的时间概念，但是是从一个比较抽象的、感性的层次去描述的，而实际上，抽象的时间概念依然会落实到具体的单词或者句子上，这些具体的单词或者句子，其实都很有标示性，这就像汉语中很难跳过“正在”或者“过”来描述进行时和完成时一样。故总结如下：</p><div class="table-container"><table><thead><tr><th>状态</th><th>短语</th></tr></thead><tbody><tr><td>普通式</td><td>in + 时间点，this/next month</td></tr><tr><td>进行式</td><td>whole + 时间段，when 从句，then</td></tr><tr><td>完成式</td><td>for + 时间段，since 从句，before 从句，by the time 从句</td></tr></tbody></table></div><h3 id="2-4-语气"><a href="#2-4-语气" class="headerlink" title="2.4 语气"></a>2.4 语气</h3><h4 id="2-4-1-助动词"><a href="#2-4-1-助动词" class="headerlink" title="2.4.1 助动词"></a>2.4.1 助动词</h4><p>在介绍语气前还需要介绍一下助动词（Auxiliary Verb），他们是一种类似于“名词，动词，副词”这样的独立词性。正如前面“限定”所介绍的，限定动词需要承担描述许多信息的职责，当 Ving，Ved 无法满足表达需要的时候，助动词就会出现来辅助限定动词的表达。助动词有如下几类：</p><ul><li>be</li><li>have</li><li>do</li><li>情态动词（modal）</li></ul><h4 id="2-4-2-真假"><a href="#2-4-2-真假" class="headerlink" title="2.4.2 真假"></a>2.4.2 真假</h4><p>语气其实也应该合在“时态”章节里介绍，他们都属于某种“限定”，只是我之前一直忽视，就单独拿出来讲了。语气解决的问题是不再让句子称为一个只是布尔值的情况，他让命题的真值更加连续：</p><blockquote><p>You may be right.</p></blockquote><p>这句话并不能说明”你是对的“，而只能说是可能正确。这种限定句子”真假“的语气，一共有 3 种：</p><ul><li>推测：表示对于命题的不确定（可能学名不叫这个，但是我觉得这个恰当）</li><li>虚拟：表示一种不可能的情况，用说反话的方式来表达意思</li><li>祈使：表示希望能成真，但尚未实现</li></ul><h4 id="2-4-3-推测"><a href="#2-4-3-推测" class="headerlink" title="2.4.3 推测"></a>2.4.3 推测</h4><p>推测语句表示的是一种”不确定“的语气，它需要加上情态动词（must、should、will/would、can/could、may/might 等）来完成。</p><blockquote><p>You are right. （你是对的。）</p><p>You may be right. （你可能是对的。）</p></blockquote><p>需要注意的是，would，could，might 虽然是 will，can，may 的过去时，但是我们并不能用它们表示”过去推测“，他们只是表示一种相对于现在时更加不确定的语气：</p><blockquote><p>The doctor thinks it <strong>can be</strong> AIDS. （医生认为可能是艾滋病。）</p><p>It <strong>could be</strong> anything—AIDS or a common cold. （还看不出来是什么病——可能是艾滋病，也可能是感冒。）</p></blockquote><p>这种现象导致按照过去的逻辑，推测语气是只有现在时的，没有时态变化的。因为在过去时所需要的 would/could/might 都被当成了一种“更小概率”的语义，而将来时所需要的 will，也被当成了一种“概率”的语义。</p><p>但是显然推测语气是需要和时态组合的，它们拓展了原本的规则，总结如下：</p><div class="table-container"><table><thead><tr><th>时态</th><th>用法</th><th>例子</th></tr></thead><tbody><tr><td>过去时</td><td>情态动词 + have + Ved</td><td>It <strong>may have rained</strong> a little last night.</td></tr><tr><td>现在时</td><td>情态动词 + V</td><td>It <strong>may rain</strong> any minute now.</td></tr><tr><td>将来时</td><td>情态动词 + V</td><td>It <strong>may rain</strong> tomorrow.</td></tr></tbody></table></div><p>总的来说就是用完成式表达过去时，而用普通式表达现在和将来。</p><h4 id="2-4-4-虚拟"><a href="#2-4-4-虚拟" class="headerlink" title="2.4.4 虚拟"></a>2.4.4 虚拟</h4><p>虚拟语气在描述一种“假如”语义，是一种复句语义，即“假如……，那么就……”。首先声明，这里说的“假如”，并不是全部的“条件句”，而是条件句的一类。有些条件句真的是在描述一种命题推导关系，比如说</p><blockquote><p>If you let go, the apple will fall.</p></blockquote><p>这是一个地球上的客观事实，只要你松手（条件），苹果就会掉落（结果），没有人限制你是否松手。但是还有一种条件句，它是一种“假如”的语气，也就是“假如，我说得是假如啊”，这是一个不可能发生的条件：</p><blockquote><p> If I were you, I wouldn’t do it. </p></blockquote><p>显然“我不是你”，所以条件并不成立。这是在说反话。还有一种翻译是“万一”：</p><blockquote><p>If an asteroid <strong>should hit</strong> the earth, man <strong>could die</strong> out.</p></blockquote><p>将其翻译成“万一小行星撞击地球了，那么人们可能就灭绝了”也是非常得体的。</p><p>在介绍具体的虚拟语气语法现象之前，我想先理清一下条件句的结构，其实只有两个部分，一个是条件句，一个是结论句。以此句举例：</p><blockquote><p> If I were you, I wouldn’t do it. </p></blockquote><p>其中“如果我是你”这是条件句，而“我不会做这件事”是结论句。那么为了达成这种“虚拟语气”，是条件句需要调整，还是结论句需要调整？答案是基本上都需要调整，或者严谨的说：<strong>无论条件句还是结论句是涉及了“虚拟，假如”的语义，那么就都需要变化，而条件句和结论句的变化方式是不同的</strong>。变化方式总结如下：</p><div class="table-container"><table><thead><tr><th>时态</th><th>条件句（从句）</th><th>结论句（主句）</th></tr></thead><tbody><tr><td>过去时</td><td>had + Ved</td><td>would/could /might + have + Ved</td></tr><tr><td>现在时</td><td>Ved（其中如果是 be 要变成 were）</td><td>would/could /might + V</td></tr><tr><td>将来时</td><td>should/were to + V</td><td>would/could /might + V</td></tr></tbody></table></div><p>在传统语法中，会归纳出“时态回退”现象，也就是“过去时变成过去完成时，现在时变成过去时，将来时情态动词变成 should”，可以看到这种规律即使用在条件句上，也会显得牵强，而用在结论句上，则是完全不符合。所以我主张直接记忆这个表格。</p><p>需要注意，在实际使用中，存在“时态错综”现象，也就是说，可以存在一个句子，具有过去时的条件句，而具有现在时的结论句，如下所示：</p><blockquote><p>If I <strong>had studied</strong> harder <strong>in school</strong>（过去）, I <strong>could qualify</strong> for the job <strong>now</strong>（现在）.</p></blockquote><p>此外，甚至“真假”也可以错综，也就是一个真实的条件句搭配一个虚拟语气的结论句，比如说：</p><blockquote><p>I <strong>could have contributed</strong> to the fund drive then（虚拟，我本来想捐钱但是并没有捐）, only that I <strong>didn’t have</strong> any money with me（真实，我真的没有带钱）.</p></blockquote><p>最后补充一下真实条件句的时态变化，其实只有一点，就是真实条件句一般都是“主将从现”的。这是因为如果条件发生在过去，那么结论一般已经发生了，那么就不构成这种“条件推导”关系了（硬币落下后再猜正反没有意义了，坍缩了）。而条件如果发生在将来，那么也没啥意义，因为对将来一无所知，我们能做的是就是根据现在的条件，判断未来发生的事情。</p><h4 id="2-4-5-祈使"><a href="#2-4-5-祈使" class="headerlink" title="2.4.5 祈使"></a>2.4.5 祈使</h4><p>祈使语气最简单了，就是直接用动词原型，然后省略主语。</p><p>还有一种间接祈使句，就是祈使句的命令方并非听着，而是第三者，这样就会呈现这样的例子：</p><blockquote><p>The court demands that the witness <strong>leave</strong> the courtroom. </p><p>There is a strong expectation among the public that someone <strong>take</strong> responsibility for the disaster.</p></blockquote><p>我很想积累这些固定用法，但是时间有些紧张。按照旋老师的说法，固定用法有很多，最重要的是看重祈使语气所强调的“望能成真，但尚未实现”。</p><h3 id="3-冠词"><a href="#3-冠词" class="headerlink" title="3. 冠词"></a>3. 冠词</h3><p>冠词 a(n) 可以视为 one 的弱化（reduction）结果。也就是说，a(n) 就代表 one 的意思，只是语气比较弱。</p><p>the 可视为 that 或 those 的弱化形式。而 that 或 those 是指示形容词，有明确的指示功能。所以定冠词 the 也可以用同样的角度来了解：凡是上下文中有明指或暗示时，也就是有“那个”的指示功能时，便要用定冠词 the。</p><hr><h2 id="三、复合句及其化简"><a href="#三、复合句及其化简" class="headerlink" title="三、复合句及其化简"></a>三、复合句及其化简</h2><p>TODO</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;一、总论&quot;&gt;&lt;a href=&quot;#一、总论&quot; class=&quot;headerlink&quot; title=&quot;一、总论&quot;&gt;&lt;/a&gt;一、总论&lt;/h2&gt;&lt;p&gt;这篇文章是对于&lt;a href=&quot;https://llwslc.github.io/grammar-club/&quot;&gt;旋元佑语法俱乐部&lt;/a&gt;的一个注释总结。行文思路基本上和这本电子书的章节保持一致。&lt;/p&gt;
&lt;p&gt;语法是对于语言的规律总结，这类似于物理是对于客观世界的规律总结。不过应当注意到，即使掌握了语法，也并不能短时间内提高英语水平，因为在语法的指导下使用语言，同样是一个需要习惯和精进的过程。这就像掌握了物理定律和物理满分之间依然存在很大差距一样。&lt;/p&gt;
&lt;p&gt;旋老师的语法和我中学学过的语法并不一样，旋老师倾向于建立一种“大一统”的理论来解释所有的语言现象，而中学语法则更加繁杂和缺少一致性。在加上我这次学习语法已经是大四，在逻辑思维上相比于中学已经有了很大的进步。所以总的来说，语法更加“讲理”了。&lt;/p&gt;
&lt;p&gt;但是旋氏语法的缺点我个人感觉有两个，一个是因为过于“统一”，导致需要引入一堆与中学语法似是而非的概念，这些概念类似于物理学上的“波粒二象性”一样，对中学语法是一种挑战；并且因为旋老师是台湾人的缘故，所以在表达习惯和方式上也与大陆存在一定的差异（也就是他写的中文有点难看懂）。另一个是旋老师在建立了“统一”的理论后，并没有充分利用这些规律推导出中学语法甚至是其他中学语法难以推导的其他语言现象。&lt;/p&gt;</summary>
    
    
    
    <category term="沟通交流" scheme="https://thysrael.github.io/categories/%E6%B2%9F%E9%80%9A%E4%BA%A4%E6%B5%81/"/>
    
    
    <category term="知识总结" scheme="https://thysrael.github.io/tags/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    <category term="S8课上" scheme="https://thysrael.github.io/tags/S8%E8%AF%BE%E4%B8%8A/"/>
    
    <category term="沟通交流" scheme="https://thysrael.github.io/tags/%E6%B2%9F%E9%80%9A%E4%BA%A4%E6%B5%81/"/>
    
  </entry>
  
  <entry>
    <title>吃喝玩乐-流浪天津</title>
    <link href="https://thysrael.github.io/posts/cb9fcc81/"/>
    <id>https://thysrael.github.io/posts/cb9fcc81/</id>
    <published>2024-06-20T12:11:21.000Z</published>
    <updated>2025-08-15T12:16:48.090Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>对于“死猪不怕开水烫”这句话，似乎每个人的理解是不同的：</p><p>有的人是“小太爷告诉你，咱得是猪，可不是那鸡鸭的便宜玩意儿”；</p><p>有的人是“跟嫩么说，别听前面的猪渍歪，介玩意儿就没带怕的”；</p><p>还有的人是“俺得用开水，不是开水可不瞻”。</p><p>但是很少有人想过”为什么我是死猪，为什么要用开水烫我“。</p></blockquote><h2 id="一、观感"><a href="#一、观感" class="headerlink" title="一、观感"></a>一、观感</h2><p>天津真的很像十年前的石家庄。我指的不是发展程度，而是市容市貌。在街上随处可见将背心挽到胸口的大爷，拿着火钳子捅咕炉子，炭火上是一两只烤鸡翅或者烤虾。旁边的饭店有踩着趿拉板儿的姐姐拎着水管往街上滋着黑水。一个个脸上都是泥渍和晒疮的小孩子，将砖头揉碎了倒到书包里，两三个人拥着一辆比人都高的华丽的变速自行车，向着挤满三轮的岔路口奔去。而石家庄，可能是因为我不常回家的缘故，早已昏沉沉地睡去。</p><p>这是西北角的景象，而在五大道，我见过了最新奇的建筑群，洋房子里长出了商户，丝毫没有嫁接或者“捏到一起”的感觉。秃头或者蓬蓬头的胖大妈从一个漂亮的西式木头窗后探出头，这如果不是发生在天津，又能发生在哪里？</p><p>来到天津以后，我才感觉到，似乎我的一部分是在天津的。这个地方没有小红书上说得那么俏皮或者幽默，而更像是我小时候读到的《神鞭》一样，这里的人为了某种传统的生活方式，而憋着一口气，他们迫不及待地向别人证明，更向自己证明，我们这么活没有错。</p><p>在华北平原上，人们惧怕没有“活儿”，因为没活儿才意味着真正的死去。</p><hr><h2 id="二、地理"><a href="#二、地理" class="headerlink" title="二、地理"></a>二、地理</h2><p>天津地理变化似乎有些剧烈，很多地区都在反复地划入河北，或者从河北划出（甚至建国后天津还成为过河北省的省会，甚至反复省会和直辖反复横跳）。关于天津建国后地理范围的具体变化，可以参考<a href="https://www.douyin.com/zhuanti/7283922349697697850">这里</a>。</p><p><img src="/posts/cb9fcc81/image-20240702110021985.png" alt="image-20240702110021985"></p><p>从历史角度分析，其实天津可以被分为两个“源”，一个是沿海的塘沽，另一个是不沿海，而是在海河三岔口附近的天津城。也就是上图东侧的部分和西侧的部分。这两个部分其实是承担了不同的城市职责。塘沽非常好理解，他临近渤海湾，是天然的海运港口。不好理解的是天津城，因为它不沿海，为什么要在内陆发展出这样的一个城市。</p><p><img src="/posts/cb9fcc81/v2-52a77dce617dbf748a04beba72673f2a_720w.webp" alt="img"></p><p>这有两个原因：自然原因和经济原因。自然原因是黄河改道与渤海海侵。现在的黄河是从山东入海，但是黄河泛滥的时候，会导致决堤更改河道，有的时候是会从天津入海的。黄河从天津入海携带的大量泥沙让天津形成了沿海的冲积平原，也就是塘沽地区，但是这片地区过于低洼，土质松软，很容易被渤海淹没，所以不适合建立大城市。而稍微靠近内陆的天津城。则没有这种担忧。</p><p><img src="/posts/cb9fcc81/703.png" alt="img"></p><p>经济原因是除了海运，天津城还承担了河运的职责。天津城位于海河、滹沱河和潞河的三岔口处，同时还有京杭大运河的的永济渠也在此处交汇，在这个位置围绕直沽修建天津城就很合理了。</p><p>到了近代，天津的行政规划不断扩大，原本的塘沽变成了滨海新区，而天津城逐渐成了一个卷心菜中菜心的部分，别周围的郊县包围，形成了“市内六区，四郊五县”的格局，其中：</p><ul><li>市内六区： 河北，南开，河东，红桥，河西，和平</li><li>四郊： 津南，北辰，东里，西青</li><li>五县： 蓟县，武清，宝坻，宁和，静海</li></ul><p>最后放一张现在天津的行政规划：</p><p><img src="/posts/cb9fcc81/18963.jpg" alt="天津市地图简图"></p><p>或者这张更形象一些：</p><p><img src="/posts/cb9fcc81/v2-b7476ae920318e6cae7159f9f314cf59_720w.webp" alt=""></p><p>而从旅游角度来说，天津的景点集中于市内六区（如果不去海边玩的话），其实是很小的一片地方，我在知乎找到这样一个评论形容市内六区，大概可以概括一下天津的风土人情：</p><blockquote><p>因为每个区人的来源不同，河东区是本土漕运人，南开区是城里人，红桥区是回族人，和平区是外地人，河西是庄家人，河北是铁路人。然后各个区领地意识很强，你也听说过天津媳妇不外嫁，跨区算外嫁吧。</p><p>市内六区打的不可开交，在他们眼里，郊区不配拥有姓名。“出了和平都是郊区”，别说四郊五县了，就连市内其他五区都看不上。</p><p>市里居民对于四郊五县人排斥 ，本质上是城市文明市民文化对于传统农业文明的一种排斥。</p><p>市里的和四郊五县本来就不是一个祖宗，市里的是江淮浙闽晋这五省移民后裔，主要从事工商业，是比较完整的市民社会模式。而四郊五县则是冀鲁民系后裔，主要从事农业，是传统的农业社会模式。</p><p>市区因为骨子里面是移民后代，家庭结构更加原子化，日常生活中更加遵守规则，而四郊五县是冀鲁农民后代，家庭关系更加紧密，更喜欢走人际关系。市区刀子嘴但是内心很包容，四郊五县看似嘴不如市区厉害，但是骨子里面更加排外。</p><p>像武清宝坻宁河汉沽蓟县四县一区是上世纪六七十年代划给天津的，这些地方之前一直是跟着北京或者唐山混的，对于天津没有什么认同感，反而对天津认同度高的沧州划给了河北省，德州归了山东省。</p></blockquote><p>这次旅行因为被学校 push 得太紧了，所以并没有好好逛天津的旅游景点，只是将想吃的天津美食吃了吃，所以下文只有关于美食的介绍，没有太多关于景点的介绍。</p><hr><h2 id="三、美食"><a href="#三、美食" class="headerlink" title="三、美食"></a>三、美食</h2><h3 id="3-1-昱德来"><a href="#3-1-昱德来" class="headerlink" title="3.1 昱德来"></a>3.1 昱德来</h3><p>昱德来并不是小红书或者知乎等攻略里推荐的天津传统菜馆，那些传统菜馆都在市内的东北侧，而我住在了鼓楼（也就是市中心），所以就找了宾馆附近的昱德来，发现味道还不错。这可能是因为天津菜非常传统，并没有很多的外地特色，不同的菜馆之间不会有明显差异导致的。</p><p>我最爱吃的是鸭卷，这可以说是我吃过最好吃的鸭子的烹饪方式。鸭子肉被撕成细丝，在保留肥美汁水的同时又避免了鸭肉柴硬的口感。鸭肉被鸡蛋皮和豆皮裹着下锅炸，要比北京烤鸭用荷叶饼或者面皮的方式融合得更好，更能保留鸭香。</p><p><img src="/posts/cb9fcc81/IMG20240616114751.jpg" alt=""></p><p>鲜虾茄盒是酸甜口的，做得中规中矩，并没有非常惊艳我。其实我一开始真的最想吃的就是这个，因为它有非常闪亮光泽的芡，看着就很下饭。实际吃上去吧，有点糊嗓子。</p><p><img src="/posts/cb9fcc81/IMG20240616114337.jpg" alt=""></p><p>我还吃了老爆三（也就是传统爆三样），确实处理得不错，没有什么脏器味儿或者腥膻味儿，但是依然不好吃。</p><h3 id="3-2-利德顺小老饭店"><a href="#3-2-利德顺小老饭店" class="headerlink" title="3.2 利德顺小老饭店"></a>3.2 利德顺小老饭店</h3><p>这家是我在西北角逛街时遇到的，是传统回民馆子，人非常火爆。我听旁边一个食客大哥说是天津非常好吃的一家传统菜馆，但是因为从不上美团或者大众点评，所以曝光率不是很高。</p><p>我个人感觉确实我吃到的菜品堪称惊艳！无论是从好吃的角度，还是从特色的角度来看。但是服务员真的好凶啊，我进了饭店也不领我去饭桌（人是真的多），好不容易坐下来也没人点菜，我去找前台就说让我等着。点菜的时候来了一个说着很重天津话的牛眼睛大爷，看我点了一个面筋，然后扯着嗓子嘟嘟囔囔（真的是这样，又大声又小声的）说太多油了，我吃不惯。把我吓得差点都直接不吃了。</p><p>虾仁独面筋真的超级好吃，面筋被完全浸泡在一个超绝的油里，那个油最少有白花椒油，菜籽油和椒麻油三种口感。面筋浸入在里面，又香又有嚼劲，而且油似乎有隔热的作用，当你将面筋吃进去的时候。面筋里被油阻隔的温度会在口腔里炸开，类似于在口腔里进行油泼面的淋油操作，那种蛋白质瞬间变性的口感，真的是绝了！这道菜就是我心中天津最好吃的菜！</p><p><img src="/posts/cb9fcc81/IMG20240616192134.jpg" alt=""></p><p>我去的时候就只有自己一个人，怕吃不完就点了这一份菜，但是白嘴吃似乎有些寡淡，就要了一个主食，一个服务员给我推荐了回头，我一看好贵啊，独面筋 40，这个东西也 40，但是我怕那个牛眼睛大爷又来，所以就点了：</p><p><img src="/posts/cb9fcc81/IMG20240616195952.jpg" alt=""></p><p>结果等了一个小时才上，这个东西其实要我说，非常有特色，而且不难吃，它类似于牛肉馅饼或者牛肉火烧，不同的是他的面没有刷的油更少，面皮更薄，烤制的时间更长。吃起来的口感更像是饼干而非饼，甚至让我有种吃比萨的错觉。</p><h3 id="3-3-西北角"><a href="#3-3-西北角" class="headerlink" title="3.3 西北角"></a>3.3 西北角</h3><p>西北角在旅游攻略上被传成了一个网红早餐街，我还以为会跟北京的南锣鼓巷一样，都是骗外地人的“塑料美食”呢。但是实际上这里确实非常生活化，东西也不贵，有很多居民区的大爷大妈都来这里吃。我来这里吃了两天，基本上把这面墙上的东西都吃了个遍：</p><p><img src="/posts/cb9fcc81/IMG20240617094212.jpg" alt=""></p><p>我早餐都是在利民餐厅吃的，主要是大夏天的，能有个能坐下吃饭还有空调的地方实在是太爽了：</p><p><img src="/posts/cb9fcc81/IMG20240617092951.jpg" alt=""></p><p>煎饼真的是太失望了，我听了那么久的天津相声，听了那么久天津人对于外地煎饼馃子的嘲弄，但是我自己吃的时候，真的味道是一样的，甚至天津的煎饼还更难以下咽。我小时候从书上看到过枣红色的油条，结果我转了很多的摊子，发现卖的都是黄色的油条，而且还很难吃（另外说一嘴，还是永和豆浆的油条最好吃，写得时候馋死我了），就像一个简单的面棍一样。</p><p><img src="/posts/cb9fcc81/IMG20240618091812.jpg" alt=""></p><p>嘎巴才倒是挺好吃的，嘎巴菜是面片片上面淋上麻酱腐乳和某种特制的黏糊糊的汤汁，是咸口的，我觉得挺香的，而且面片的口感哏啾啾的，不像煎饼那么浮囊。</p><p><img src="/posts/cb9fcc81/IMG20240617091139-17199124363434.jpg" alt=""></p><p>面茶跟嘎巴菜的味道差不多，真的像《俗世奇人》里描述的一样，先加半碗茶汤，再加一层芝麻，然后再加半碗茶汤，再撒一层芝麻。茶汤并不是固体，而更像是芝麻糊那样的固液交融的状态。我打算先攉拢攉拢再吃，但是旁边的天津大姨教给我不要搅和，而是要拿勺子溜着碗沿儿㧟着吃。</p><p><img src="/posts/cb9fcc81/IMG20240618092023.jpg" alt=""></p><p>卷圈的腐乳味、油渣味儿和豆芽菜的水汽味儿交织在一起，形成了一种神秘的味觉体验，这种味道甚至都有些刺鼻了（腐乳有点发酸）：</p><p><img src="/posts/cb9fcc81/IMG20240617102724.jpg" alt=""></p><p>在西北角还常见熟梨膏，但是其实和梨这种水果没啥关系，我查了查，据说是“熟哩”的音译。其做法上很类似陕西的镜糕，但是要更加难吃一些，酱料𫫇甜𫫇甜的，而糯米过于粉了，这可能是由于它并不是在一个像蒸锅一样的密闭容器，而是在一个小碗里制作的。</p><h3 id="3-4-起士林"><a href="#3-4-起士林" class="headerlink" title="3.4 起士林"></a>3.4 起士林</h3><p>非常有名的西餐馆，我觉得更难得是价格还算合理，而且服务员态度很好（感觉五大道这边市井气少一些，更加工业城市了一些）。可惜的是，这里的大列巴是要钱的（《师父》骗人！）：</p><p><img src="/posts/cb9fcc81/IMG20240618103345.jpg" alt=""></p><p>店内的装潢有一种中西混合的感觉，西式的主体和中式的繁复装饰：</p><p><img src="/posts/cb9fcc81/IMG20240618105955.jpg" alt=""></p><p>我在想耿良辰是不是原本比武赢了后就是要在这张楼梯口的大桌子上吃饭：</p><p><img src="/posts/cb9fcc81/IMG20240618110000.jpg" alt=""></p><p>这个吧台也很漂亮：</p><p><img src="/posts/cb9fcc81/IMG20240618110822.jpg" alt=""></p><p>坐下来窗外是一个外国风情的音乐厅：</p><p><img src="/posts/cb9fcc81/IMG20240618111449.jpg" alt=""></p><p>我看门口介绍说是德国餐厅，居然意外的好吃（什么刻板印象，我该死），红汤有很浓郁的酵香，而且还不酸𫫇：</p><p><img src="/posts/cb9fcc81/IMG20240618110549.jpg" alt=""></p><p>奶油芝士杂拌芝士量很足，拉丝很明显，各种肉类都很好吃：</p><p><img src="/posts/cb9fcc81/IMG20240618111729.jpg" alt=""></p><p>我平时并不喝酒，不知道是不是心理因素，我觉得这杯金汤力非常清冽，没有酸锈味儿：</p><p><img src="/posts/cb9fcc81/IMG20240618112918-17199229470811.jpg" style="zoom:25%;"></p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;对于“死猪不怕开水烫”这句话，似乎每个人的理解是不同的：&lt;/p&gt;
&lt;p&gt;有的人是“小太爷告诉你，咱得是猪，可不是那鸡鸭的便宜玩意儿”；&lt;/p&gt;
&lt;p&gt;有的人是“跟嫩么说，别听前面的猪渍歪，介玩意儿就没带怕的”；&lt;/p&gt;
&lt;p&gt;还有的人是“俺得用开水，不是开水可不瞻”。&lt;/p&gt;
&lt;p&gt;但是很少有人想过”为什么我是死猪，为什么要用开水烫我“。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;一、观感&quot;&gt;&lt;a href=&quot;#一、观感&quot; class=&quot;headerlink&quot; title=&quot;一、观感&quot;&gt;&lt;/a&gt;一、观感&lt;/h2&gt;&lt;p&gt;天津真的很像十年前的石家庄。我指的不是发展程度，而是市容市貌。在街上随处可见将背心挽到胸口的大爷，拿着火钳子捅咕炉子，炭火上是一两只烤鸡翅或者烤虾。旁边的饭店有踩着趿拉板儿的姐姐拎着水管往街上滋着黑水。一个个脸上都是泥渍和晒疮的小孩子，将砖头揉碎了倒到书包里，两三个人拥着一辆比人都高的华丽的变速自行车，向着挤满三轮的岔路口奔去。而石家庄，可能是因为我不常回家的缘故，早已昏沉沉地睡去。&lt;/p&gt;
&lt;p&gt;这是西北角的景象，而在五大道，我见过了最新奇的建筑群，洋房子里长出了商户，丝毫没有嫁接或者“捏到一起”的感觉。秃头或者蓬蓬头的胖大妈从一个漂亮的西式木头窗后探出头，这如果不是发生在天津，又能发生在哪里？&lt;/p&gt;
&lt;p&gt;来到天津以后，我才感觉到，似乎我的一部分是在天津的。这个地方没有小红书上说得那么俏皮或者幽默，而更像是我小时候读到的《神鞭》一样，这里的人为了某种传统的生活方式，而憋着一口气，他们迫不及待地向别人证明，更向自己证明，我们这么活没有错。&lt;/p&gt;</summary>
    
    
    
    <category term="吃喝玩乐" scheme="https://thysrael.github.io/categories/%E5%90%83%E5%96%9D%E7%8E%A9%E4%B9%90/"/>
    
    
    <category term="S8课上" scheme="https://thysrael.github.io/tags/S8%E8%AF%BE%E4%B8%8A/"/>
    
    <category term="吃喝玩乐" scheme="https://thysrael.github.io/tags/%E5%90%83%E5%96%9D%E7%8E%A9%E4%B9%90/"/>
    
    <category term="流浪天津" scheme="https://thysrael.github.io/tags/%E6%B5%81%E6%B5%AA%E5%A4%A9%E6%B4%A5/"/>
    
  </entry>
  
</feed>
